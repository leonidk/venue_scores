{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import fnmatch\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.read_hdf(\"papers.h5\", \"table\")\n",
    "Xauth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names = pickle.load(open(\"big_names.pkl\", \"rb\"))\n",
    "unique_confs = pickle.load(open(\"confs.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_idx = pickle.load(open(\"conf_idx.pkl\", \"rb\"))\n",
    "name_idx = pickle.load(open(\"name_idx.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areadict = {\n",
    "    \"icse\": [\"ICSE\", \"ICSE (1)\"],\n",
    "    \"fse\": [\"SIGSOFT FSE\", \"ESEC/SIGSOFT FSE\"],\n",
    "    \"usenixatc\": [\n",
    "        \"USENIX Annual Technical Conference\",\n",
    "        \"USENIX Annual Technical Conference, General Track\",\n",
    "    ],  # next tier\n",
    "    \"imc\": [\"IMC\", \"Internet Measurement Conference\"],\n",
    "    \"sigmetrics\": [\"SIGMETRICS\", \"SIGMETRICS/Performance\", \"POMACS\"],\n",
    "    \"mobicom\": [\"MobiCom\", \"MOBICOM\"],\n",
    "    \"rtas\": [\n",
    "        \"RTAS\",\n",
    "        \"IEEE Real-Time and Embedded Technology and Applications Symposium\",\n",
    "    ],\n",
    "    \"ccs\": [\"CCS\", \"ACM Conference on Computer and Communications Security\"],\n",
    "    \"oakland\": [\"IEEE Symposium on Security and Privacy\"],\n",
    "    \"usenixsec\": [\"USENIX Security Symposium\", \"USENIX Security\"],\n",
    "    \"pets\": [\"PoPETs\", \"Privacy Enhancing Technologies\"],\n",
    "    \"cav\": [\"CAV\", \"CAV (1)\", \"CAV (2)\"],\n",
    "    \"lics\": [\"LICS\", \"CSL-LICS\"],\n",
    "    \"nips\": [\"NIPS\", \"NeurIPS\"],\n",
    "    \"icml\": [\"ICML\", \"ICML (1)\", \"ICML (2)\", \"ICML (3)\"],\n",
    "    \"aaai\": [\"AAAI\", \"AAAI/IAAI\"],\n",
    "    \"ubicomp\": [\"UbiComp\", \"Ubicomp\", \"IMWUT\", \"Pervasive\"],\n",
    "    \"emnlp\": [\"EMNLP\", \"EMNLP-CoNLL\", \"HLT/EMNLP\"],\n",
    "    \"acl\": [\"ACL\", \"ACL (1)\", \"ACL (2)\", \"ACL/IJCNLP\", \"COLING-ACL\"],\n",
    "    \"naacl\": [\"NAACL\", \"HLT-NAACL\", \"NAACL-HLT\"],\n",
    "    \"cvpr\": [\"CVPR\", \"CVPR (1)\", \"CVPR (2)\"],\n",
    "    \"eccv\": [\n",
    "        \"ECCV\",\n",
    "        \"ECCV (1)\",\n",
    "        \"ECCV (2)\",\n",
    "        \"ECCV (3)\",\n",
    "        \"ECCV (4)\",\n",
    "        \"ECCV (5)\",\n",
    "        \"ECCV (6)\",\n",
    "        \"ECCV (7)\",\n",
    "        \"ECCV (8)\",\n",
    "        \"ECCV (9)\",\n",
    "        \"ECCV (10)\",\n",
    "        \"ECCV (11)\",\n",
    "        \"ECCV (12)\",\n",
    "        \"ECCV (13)\",\n",
    "        \"ECCV (14)\",\n",
    "        \"ECCV (15)\",\n",
    "        \"ECCV (16)\",\n",
    "    ],\n",
    "    \"icra\": [\"ICRA\", \"ICRA (1)\", \"ICRA (2)\"],\n",
    "    \"rss\": [\"Robotics: Science and Systems\"],\n",
    "    \"crypto\": [\"CRYPTO\", \"CRYPTO (1)\", \"CRYPTO (2)\", \"CRYPTO (3)\"],\n",
    "    \"eurocrypt\": [\"EUROCRYPT\", \"EUROCRYPT (1)\", \"EUROCRYPT (2)\", \"EUROCRYPT (3)\"],\n",
    "}\n",
    "inverse_area_dict = {}\n",
    "for k, v in areadict.items():\n",
    "    n = len(v)\n",
    "    for i in range(1, n):\n",
    "        inverse_area_dict[v[i]] = v[0]\n",
    "for k, v in inverse_area_dict.items():\n",
    "    if k in conf_idx and v in conf_idx:\n",
    "        conf_idx[k] = conf_idx[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ftfy\n",
    "# from unidecode import unidecode\n",
    "# for i in range(len(unique_names)):\n",
    "#    unique_names[i] = unidecode(ftfy.fix_encoding(unique_names[i]))\n",
    "#    name_idx[unique_names[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = papers.year.min()\n",
    "max_year = papers.year.max()\n",
    "span_years = max_year - min_year + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Xauth is None or (Xauth.shape[1] != span_years * unique_confs.shape[0]):\n",
    "    Xauth = scipy.sparse.dok_matrix(\n",
    "        (len(unique_names), span_years * unique_confs.shape[0])\n",
    "    )\n",
    "    xdict = {}\n",
    "    auth_years = np.ones((len(unique_names), 2)) * np.array([3000, 1000])\n",
    "    for row in papers.itertuples():\n",
    "        paper_year = row[10]\n",
    "        conf = row[2]\n",
    "        n = row[4]\n",
    "        authors = row[3]\n",
    "        j = span_years * conf_idx[conf] + (paper_year - min_year)\n",
    "        for a in authors:\n",
    "            i = name_idx[a]\n",
    "            xdict[(i, j)] = 1 / n + xdict.get((i, j), 0)\n",
    "            auth_years[i, 0] = min(auth_years[i, 0], paper_year)\n",
    "            auth_years[i, 1] = max(auth_years[i, 1], paper_year)\n",
    "    Xauth._update(xdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_affil = pd.read_csv(\"faculty-affiliations.csv\")\n",
    "\n",
    "\n",
    "def csv2dict_str_str(fname):\n",
    "    with open(fname, mode=\"r\") as infile:\n",
    "        rdr = csv.reader(infile)\n",
    "        d = {rows[0].strip(): rows[1].strip() for rows in rdr}\n",
    "    return d\n",
    "\n",
    "\n",
    "aliasdict = csv2dict_str_str(\"dblp-aliases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    clfs = [\n",
    "        pickle.load(open(\"faculty_indep.pkl\", \"rb\")),\n",
    "        pickle.load(open(\"nsf_indep2.pkl\", \"rb\")),\n",
    "        pickle.load(open(\"salary_indep.pkl\", \"rb\")),\n",
    "    ]\n",
    "    clfs = [\n",
    "        pickle.load(open(\"faculty_indep-fixed.pkl\", \"rb\")),\n",
    "        pickle.load(open(\"faculty_indep-fixed_5.pkl\", \"rb\")),\n",
    "        pickle.load(open(\"faculty_indep-fixed_16.pkl\", \"rb\")),\n",
    "        # pickle.load(open('nsf_fixed_total-log.pkl','rb')),\n",
    "        # pickle.load(open('nsf_fixed_total-nonlog.pkl','rb')),\n",
    "        # pickle.load(open('nsf_fixed_marginal-log.pkl','rb')),\n",
    "        # pickle.load(open('nsf_fixed_marginal-nonlog.pkl','rb')),\n",
    "        # pickle.load(open('salary-fixed-log.pkl','rb')),\n",
    "        # pickle.load(open('salary-fixed-nonlog.pkl','rb')),\n",
    "        pickle.load(open(\"nsf_fixed_marginal-log-names.pkl\", \"rb\")),\n",
    "        pickle.load(open(\"nsf_fixed_marginal-nonlog-names.pkl\", \"rb\")),\n",
    "        pickle.load(open(\"salary-fixed-log-names.pkl\", \"rb\")),\n",
    "        pickle.load(open(\"salary-fixed-nonlog-names.pkl\", \"rb\")),\n",
    "    ]\n",
    "clfs = [\n",
    "    pickle.load(open(\"faculty_indep-fixed.pkl\", \"rb\")),\n",
    "    pickle.load(open(\"faculty_indep-fixed_5.pkl\", \"rb\")),\n",
    "    pickle.load(open(\"faculty_indep-fixed_16.pkl\", \"rb\")),\n",
    "    # pickle.load(open('nsf_fixed_total-log.pkl','rb')),\n",
    "    pickle.load(open(\"nsf_fixed_total-log-names.pkl\", \"rb\")),\n",
    "    # pickle.load(open('salary-fixed-nonlog.pkl','rb')),\n",
    "    pickle.load(open(\"nsf_fixed_marginal-log-names.pkl\", \"rb\")),\n",
    "    # pickle.load(open('nsf_fixed_marginal-nonlog-names.pkl','rb')),\n",
    "    # pickle.load(open('salary-fixed-log-names.pkl','rb')),\n",
    "    pickle.load(open(\"salary-fixed-nonlog-names.pkl\", \"rb\")),\n",
    "]\n",
    "clfs = [np.squeeze(_) for _ in clfs]\n",
    "print([_.shape for _ in clfs])\n",
    "clp = 2000  # 7\n",
    "clfs2 = []\n",
    "for result_clf in clfs:\n",
    "    result_clf = result_clf.reshape((-1, span_years))\n",
    "\n",
    "    # plt.plot(result_clf.sum(0)/result_clf.sum(0).sum(),label='sum')\n",
    "    print(abs(result_clf.mean(0)).mean(), abs(result_clf.std(0)).mean())\n",
    "    # result_clf = np.minimum(30,np.maximum(result_clf,-30))\n",
    "    # result_clf = (result_clf)/result_clf.std(0)\n",
    "    result_clf = (result_clf - result_clf.mean(0)) / result_clf.std(0)\n",
    "    result_clf = result_clf.reshape((-1))\n",
    "    clfs2.append(result_clf)\n",
    "clfs = clfs2\n",
    "clfs = [np.minimum(clp, np.maximum(-clp, (c - c.mean()) / c.std())) for c in clfs]\n",
    "clfs = np.vstack(clfs)\n",
    "auth_years = pickle.load(open(\"auth_years.pkl\", \"rb\"))\n",
    "clf = np.mean(clfs, 0)\n",
    "\n",
    "# remove arXiv\n",
    "print(clf.shape[0], conf_idx[\"CoRR\"])\n",
    "non_arxiv = np.ones(clf.shape[0])\n",
    "for i in range(span_years):\n",
    "    non_arxiv[span_years * conf_idx[\"CoRR\"] + i] = 0\n",
    "clf = clf * non_arxiv\n",
    "clf_gold = np.copy(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_ord = np.argsort(np.squeeze(clf))\n",
    "#'Scientometrics','JCDL','NIPS',\n",
    "conf_choice = [\n",
    "    \"ICRA (1)\",\n",
    "    \"ICML (2)\",\n",
    "    \"SIGGRAPH\",\n",
    "    \"HRI\",\n",
    "    \"ECCV (8)\",\n",
    "    \"ECCV (1)\",\n",
    "    \"Comput. Graph. Forum\",\n",
    "    \"Shape Modeling International\",\n",
    "    \"Symposium on Geometry Processing\",\n",
    "    \"Computer Aided Geometric Design\",\n",
    "    \"I. J. Robotics Res.\",\n",
    "    \"CVPR\",\n",
    "    \"International Journal of Computer Vision\",\n",
    "    \"Robotics: Science and Systems\",\n",
    "    \"ICRA\",\n",
    "    \"WACV\",\n",
    "    \"ICML\",\n",
    "    \"AISTATS\",\n",
    "    \"CoRR\",\n",
    "    \"SIGGRAPH Asia\",\n",
    "    \"ECCV\",\n",
    "    \"ICCV\",\n",
    "    \"ISER\",\n",
    "    \"Humanoids\",\n",
    "    \"3DV\",\n",
    "    \"IROS\",\n",
    "    \"CoRL\",\n",
    "    \"Canadian Conference on AI\",\n",
    "    \"ACCV\",\n",
    "    \"Graphics Interface\",\n",
    "    \"CRV\",\n",
    "    \"BMVC\",\n",
    "]\n",
    "ri_confs = np.zeros(len(unique_confs) * span_years)\n",
    "ms = clf.mean()\n",
    "ss = clf.std()\n",
    "np.set_printoptions(precision=1)\n",
    "seen = {}\n",
    "for i in range(len(unique_confs) * span_years):\n",
    "    idx = conf_ord[-(i + 1)]\n",
    "    conf_name = unique_confs[idx // span_years]\n",
    "    conf_score = clf[idx]\n",
    "    if conf_name in conf_choice:\n",
    "        ri_confs[idx] = 1\n",
    "    if conf_name in conf_choice and conf_name not in seen:\n",
    "        vec = clfs[:, idx]\n",
    "        print(\n",
    "            \"{:20s}{}\\t{:.1f}\\t{}\".format(\n",
    "                conf_name[:20],\n",
    "                str(min_year + (idx % span_years)),\n",
    "                (conf_score - ms) / ss,\n",
    "                vec,\n",
    "            )\n",
    "        )\n",
    "        seen[conf_name] = 1\n",
    "ri_confs.shape, ri_confs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 50\n",
    "i = -1\n",
    "j = 0\n",
    "seen = {}\n",
    "while j < top_k:\n",
    "    i += 1\n",
    "    idx = conf_ord[-(i + 1)]\n",
    "    conf_name = unique_confs[idx // span_years]\n",
    "    if conf_name in seen:\n",
    "        continue\n",
    "    j += 1\n",
    "    conf_score = clf[idx]\n",
    "    seen[conf_name] = 1\n",
    "    print(\n",
    "        \"{:20s}\\t{}\\t\\t{:.3f}\\t{:.2f}\".format(\n",
    "            conf_name[:18],\n",
    "            min_year + (idx % span_years),\n",
    "            100 * conf_score,\n",
    "            (conf_score - ms) / ss,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for clf in [clf_gold]:\n",
    "    plt.figure()\n",
    "    conf_choice2 = [\n",
    "        \"SIGGRAPH\",\n",
    "        \"AAAI\",\n",
    "        \"NIPS\",\n",
    "        \"CVPR\",\n",
    "        \"ICRA\",\n",
    "        \"ICML\",\n",
    "        \"ICCV\",\n",
    "        \"ECCV\",\n",
    "        \"International Journal of Computer Vision\",\n",
    "        \"Robotics: Science and Systems\",\n",
    "    ]\n",
    "    # conf_choice2 = ['CVPR','ECCV','ICCV','International Journal of Computer Vision','Robotics: Science and Systems']\n",
    "    # conf_choice2 = ['SIGMOD Conference','VLDB','ICDT','KDD','ACM Trans. Inf. Syst.','PODS']\n",
    "    # conf_choice2 = ['ACL','EMNLP','EACL']\n",
    "\n",
    "    conf_choices = [\n",
    "        conf_choice2,\n",
    "        [\n",
    "            \"STOC\",\n",
    "            \"FOCS\",\n",
    "            \"SODA\",\n",
    "            \"EC\",\n",
    "            \"WINE\",\n",
    "            \"Electronic Colloquium on Computational Complexity (ECCC)\",\n",
    "        ],\n",
    "        [\"UAI\", \"AAAI\", \"IJCAI\", \"ICML\", \"NIPS\"],\n",
    "        [\n",
    "            \"ECCV\",\n",
    "            \"ICCV\",\n",
    "            \"CVPR\",\n",
    "            \"BMVC\",\n",
    "            \"CRV\",\n",
    "            \"International Journal of Computer Vision\",\n",
    "            \"3DV\",\n",
    "            \"WACV\",\n",
    "        ],\n",
    "        [\n",
    "            \"Robotics: Science and Systems\",\n",
    "            \"IROS\",\n",
    "            \"CoRL\",\n",
    "            \"WAFR\",\n",
    "            \"HRI\",\n",
    "            \"ISER\",\n",
    "            \"ICRA\",\n",
    "        ],\n",
    "        [\"SIGGRAPH\", \"SIGGRAPH Asia\", \"ACM Trans. Graph.\", \"Graphics Interface\"],\n",
    "    ]\n",
    "    # conf_choices = [['Robotics: Science and Systems','IROS','ICRA','CoRL','WAFR','HRI','ISER']]\n",
    "    for conf_choice2 in conf_choices:\n",
    "        plt.figure()\n",
    "        # conf_choice2 =\n",
    "        conf_choice3 = []\n",
    "        vs = clf.std()\n",
    "        for conf in conf_choice2:\n",
    "            idx = conf_idx[conf]\n",
    "            s = clf[\n",
    "                span_years * idx + 2015 - 1970\n",
    "            ]  # max(clf[span_years*idx:span_years*(idx+1)])\n",
    "            conf_choice3.append((s, conf))\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for s, conf in sorted(conf_choice3, reverse=True):\n",
    "            idx = conf_idx[conf]\n",
    "            _ = plt.plot(\n",
    "                np.arange(min_year, max_year + 1)[:-4],\n",
    "                (clf[span_years * idx : span_years * (idx + 1)] / vs)[:-4],\n",
    "                label=conf,\n",
    "                lw=5,\n",
    "            )\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"year\")\n",
    "        plt.ylabel(\"value\")\n",
    "        plt.legend()\n",
    "        # plt.show()\n",
    "\n",
    "    # plt.show()\n",
    "clf = clf_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.hist(clf, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "sigma = 3\n",
    "weights = []\n",
    "for i in range(span_years):\n",
    "    a = np.array([scipy.stats.norm.pdf((j - i) / sigma) for j in range(span_years)])\n",
    "    a[a < 0.05] = 0\n",
    "    weights.append(a / np.linalg.norm(a))\n",
    "_ = plt.plot(np.arange(span_years) + min_year, weights[2000 - min_year])\n",
    "plt.grid(True)\n",
    "# pairs_of_years = itertools.product(range(span_years),range(span_years))\n",
    "\n",
    "wdict = {}\n",
    "for i, j, k in itertools.product(\n",
    "    range(unique_confs.shape[0]), range(span_years), range(span_years)\n",
    "):\n",
    "    wdict[i * span_years + j, i * span_years + k] = weights[j][k]\n",
    "wsa = scipy.sparse.dok_matrix(\n",
    "    (span_years * unique_confs.shape[0], span_years * unique_confs.shape[0])\n",
    ")\n",
    "wsa._update(wdict)\n",
    "Xauth = scipy.sparse.csr_matrix(Xauth)\n",
    "wsa = scipy.sparse.csr_matrix(wsa)\n",
    "Xauth = Xauth @ wsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Xauth.dot(clf_gold)\n",
    "years_working = 1 + auth_years[:, 1] - auth_years[:, 0]\n",
    "value_scores = scores\n",
    "norm_scores = (value_scores) / years_working\n",
    "ri_filter_mat = scipy.sparse.diags(ri_confs)\n",
    "ri_scores = Xauth.dot(ri_filter_mat).dot(clf_gold)\n",
    "ri_norm_scores = ri_scores / years_working\n",
    "pub_num = Xauth.sum(1)\n",
    "total_scores = np.copy(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_cand = [\n",
    "    \"Pulkit Agrawal\",\n",
    "    \"Joydeep Biswas\",\n",
    "    \"Katherine L. Bouman\",\n",
    "    \"David Braun\",\n",
    "    \"Jia Deng\",\n",
    "    \"Naomi T. Fitter\",\n",
    "    \"David F. Fouhey\",\n",
    "    \"Saurabh Gupta\",\n",
    "    \"Judy Hoffman\",\n",
    "    \"Hanbyul Joo\",\n",
    "    \"Honglak Lee\",\n",
    "    \"Changliu Liu\",\n",
    "    \"Petter Nilsson\",\n",
    "    \"Matthew O'Toole\",\n",
    "    \"Alessandro Roncone\",\n",
    "    \"Alanson P. Sample\",\n",
    "    \"Manolis Savva\",\n",
    "    \"Adriana Schulz\",\n",
    "    \"Amy Tabb\",\n",
    "    \"Fatma Zeynep Temel\",\n",
    "    \"Long Wang\",\n",
    "    \"Cathy Wu\",\n",
    "    \"Ling-Qi Yan\",\n",
    "]\n",
    "print(\n",
    "    \"{:20s}\\t{:4s}\\t{:4s}\\t{:4s}\\t{}\\t{}\".format(\n",
    "        \"name\", \"rate\", \"total\", \"ri\", \"years\", \"pubs\"\n",
    "    )\n",
    ")\n",
    "for ns, name in sorted(\n",
    "    [(value_scores[name_idx[ni]], ni) for ni in prev_cand], reverse=True\n",
    "):\n",
    "    ni = name_idx[name]\n",
    "    print(\n",
    "        \"{:20s}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.0f}\\t{:.1f}\".format(\n",
    "            name,\n",
    "            norm_scores[ni],\n",
    "            value_scores[ni],\n",
    "            ri_scores[ni],\n",
    "            years_working[ni],\n",
    "            pub_num[ni, 0],\n",
    "        )\n",
    "    )\n",
    "print(\"\")\n",
    "curious_names = [\n",
    "    \"Xiaolong Wang 0004\",\n",
    "    \"Judy Hoffman\",\n",
    "    \"Paris Siminelakis\",\n",
    "    \"Roie Levin\",\n",
    "    \"Leonid Keselman\",\n",
    "    \"Rick Goldstein\",\n",
    "    \"Nicholas Rhinehart\",\n",
    "    \"Vincent Sitzmann\",\n",
    "    \"Siddharth Ancha\",\n",
    "    \"Xingyu Lin\",\n",
    "    \"Humphrey Hu\",\n",
    "    \"David F. Fouhey\",\n",
    "    \"Chelsea Finn\",\n",
    "    \"Dinesh Jayaraman\",\n",
    "    \"Wen Sun 0002\",\n",
    "    \"Lerrel Pinto\",\n",
    "    \"Justin Johnson\",\n",
    "    \"Amir Roshan Zamir\",\n",
    "    \"Dominik Peters\",\n",
    "    \"Jonathan T. Barron\",\n",
    "    \"Dorsa Sadigh\",\n",
    "    \"Derek Hoiem\",\n",
    "    \"Vaggos Chatziafratis\",\n",
    "    \"Brian Okorn\",\n",
    "    \"David Held\",\n",
    "]\n",
    "print(\n",
    "    \"{:20s}\\t{:4s}\\t{:4s}\\t{:4s}\\t{}\\t{}\".format(\n",
    "        \"name\", \"rate\", \"total\", \"ri\", \"years\", \"pubs\"\n",
    "    )\n",
    ")\n",
    "for _, name in sorted(\n",
    "    [(value_scores[name_idx[_]], _) for _ in curious_names], reverse=True\n",
    "):\n",
    "    ni = name_idx[name]\n",
    "    print(\n",
    "        \"{:20s}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{}\\t{:.1f}\".format(\n",
    "            name,\n",
    "            norm_scores[ni],\n",
    "            value_scores[ni],\n",
    "            ri_scores[ni],\n",
    "            years_working[ni],\n",
    "            pub_num[ni, 0],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_faculty = faculty_affil[\n",
    "    faculty_affil.affiliation == \"Carnegie Mellon University\"\n",
    "]  # Carnegie Mellon University\n",
    "uni_names = np.array(uni_faculty.name)\n",
    "uni_names = list(uni_names)\n",
    "cmu_scores = []\n",
    "ts = value_scores.std()\n",
    "# uni_names = [unique_names[i] for i in (np.argsort(scores)[::-1])[:150]]\n",
    "for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "    if name in name_idx:\n",
    "        # if ri_scores[name_idx[name]] < 2.5:\n",
    "        #    continue\n",
    "        score = value_scores[name_idx[name]]\n",
    "        idx = name_idx[name]\n",
    "        cmu_scores.append((total_scores[idx], name))\n",
    "    else:\n",
    "        pass\n",
    "        # print(name)\n",
    "for s, p in sorted(cmu_scores, reverse=True):\n",
    "    print(\"{:30s}\\t\\t{:.1f}\".format(p, s / ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for clp in [200]:#range(1,15,1):\n",
    "clp = 5\n",
    "clfs = [\n",
    "    pickle.load(open(\"faculty_indep-fixed.pkl\", \"rb\")),\n",
    "    pickle.load(open(\"faculty_indep-fixed_5.pkl\", \"rb\")),\n",
    "    pickle.load(open(\"faculty_indep-fixed_16.pkl\", \"rb\")),\n",
    "    pickle.load(open(\"nsf_fixed_total-log-names.pkl\", \"rb\")),\n",
    "    # pickle.load(open('salary-fixed-nonlog.pkl','rb')),\n",
    "    pickle.load(open(\"nsf_fixed_marginal-log-names.pkl\", \"rb\")),\n",
    "    # pickle.load(open('nsf_fixed_marginal-nonlog-names.pkl','rb')),\n",
    "    # pickle.load(open('salary-fixed-log-names.pkl','rb')),\n",
    "    pickle.load(open(\"salary-fixed-nonlog-names.pkl\", \"rb\")),\n",
    "]\n",
    "clfs = [np.squeeze(_) for _ in clfs]\n",
    "clp = 100\n",
    "clfs2 = []\n",
    "for result_clf in clfs:\n",
    "    result_clf = result_clf.reshape((-1, span_years))\n",
    "\n",
    "    # plt.plot(result_clf.sum(0)/result_clf.sum(0).sum(),label='sum')\n",
    "    print(abs(result_clf.mean(0)).mean(), abs(result_clf.std(0)).mean())\n",
    "    # result_clf = np.minimum(30,np.maximum(result_clf,-30))\n",
    "    # result_clf = (result_clf)/result_clf.std(0)\n",
    "    result_clf = (result_clf - result_clf.mean(0)) / result_clf.std(0)\n",
    "    result_clf = result_clf.reshape((-1))\n",
    "    clfs2.append(result_clf)\n",
    "clfs = clfs2\n",
    "clfs = [np.minimum(clp, np.maximum(-clp, (c - c.mean()) / c.std())) for c in clfs]\n",
    "clfs = np.vstack(clfs)\n",
    "auth_years = pickle.load(open(\"auth_years.pkl\", \"rb\"))\n",
    "clf_gold = np.mean(clfs, 0)\n",
    "\n",
    "clfs_test = np.vstack([clfs, clf_gold.reshape(1, -1)])\n",
    "for clfn, clf in enumerate(clfs_test):\n",
    "    total_scores = Xauth.dot(clf)\n",
    "    df_corr = pd.read_csv(\"correlation_cleaned.csv\")\n",
    "    df_corr = df_corr.drop(columns=[_ for _ in df_corr.columns if \"Unnamed\" in _])\n",
    "    df_corr = df_corr.drop(columns=[\"pms\", \"n_papers\"])\n",
    "    df_corr = df_corr.rename(\n",
    "        columns={\n",
    "            \"totals\": \"venue_score\",\n",
    "            \"csrp\": \"csr_pubs\",\n",
    "            \"csrpn\": \"csr_adj\",\n",
    "            \"gcite\": \"influence\",\n",
    "        }\n",
    "    )\n",
    "    pd.set_option(\"precision\", 2)\n",
    "    df_corr = df_corr[\n",
    "        [\n",
    "            \"name\",\n",
    "            \"papers\",\n",
    "            \"citations\",\n",
    "            \"h-index\",\n",
    "            \"i10\",\n",
    "            \"csr_pubs\",\n",
    "            \"csr_adj\",\n",
    "            \"venue_score\",\n",
    "            \"influence\",\n",
    "        ]\n",
    "    ]\n",
    "    df_corr = df_corr.dropna(\"index\")\n",
    "    df_corr.index = df_corr.name\n",
    "\n",
    "    ts = total_scores.std()\n",
    "    for name in df_corr.name:\n",
    "        if name in name_idx:\n",
    "            idx = name_idx[name]\n",
    "            df_corr.loc[name, \"venue_score\"] = total_scores[idx] / ts\n",
    "    print(\n",
    "        clp,\n",
    "        clfn,\n",
    "        df_corr.corr(\"spearman\").loc[\"influence\", \"venue_score\"],\n",
    "        df_corr.corr(\"kendall\").loc[\"influence\", \"venue_score\"],\n",
    "        df_corr.corr(\"spearman\").loc[\"h-index\", \"venue_score\"],\n",
    "    )\n",
    "    # if clfn == clfs_test.shape[-1]:\n",
    "df_corr.corr(\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr.corr(\"spearman\").loc[\"venue_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls *names*.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.shape[0] / span_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# different stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_mat = pickle.load(open(\"top_conf_embed.pkl\", \"rb\"))\n",
    "ind_mat = np.array(pickle.load(open(\"top_conf_ind.pkl\", \"rb\"))).reshape((-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_mat.shape\n",
    "full_to_sub = {}\n",
    "j = 0\n",
    "for i, v in enumerate(ind_mat):\n",
    "    if v:\n",
    "        full_to_sub[i] = j\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_mat.shape, len(full_to_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xauth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_mat = np.repeat(ind_mat, span_years).astype(np.float)\n",
    "rep_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmap = scipy.sparse.dok_matrix((Xauth.shape[1], vec_mat.shape[0]))\n",
    "xdict = {}\n",
    "print(xmap.shape)\n",
    "for i, v in enumerate(rep_mat):\n",
    "    if v:\n",
    "        xdict[(i, full_to_sub[i // span_years])] = 1\n",
    "xmap._update(xdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_all = Xauth.dot(xmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_all_mag = mapped_all.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    uni_faculty = faculty_affil[\n",
    "        faculty_affil.affiliation == \"Carnegie Mellon University\"\n",
    "    ]  # Carnegie Mellon University\n",
    "    uni_names = np.array(uni_faculty.name)\n",
    "    uni_names = list(uni_names)\n",
    "    pd.Series(uni_names).to_csv(\"cmu_faculty.csv\")\n",
    "else:\n",
    "    cmu_uni = pd.read_csv(\"cmu_faculty.csv\")\n",
    "    cmu_uni = cmu_uni.fillna(\"Other\")\n",
    "    cmu_uni = cmu_uni[cmu_uni.dept == \"RI\"]\n",
    "    # print(list(cmu_uni.name))\n",
    "    uni_names = list(cmu_uni.name)\n",
    "    uni_labels = list(cmu_uni.dept)\n",
    "    uni_labels_unique = list(set(uni_labels))\n",
    "cmu_scores = []\n",
    "uni_colors = []\n",
    "# uni_names = [unique_names[i] for i in (np.argsort(scores)[::-1])[:150]]\n",
    "for name, d in set(\n",
    "    [(aliasdict.get(n, n), dept) for n, dept in zip(uni_names, uni_labels)]\n",
    "):\n",
    "    if name in name_idx:\n",
    "        # if ri_scores[name_idx[name]] < 2.5:\n",
    "        #    continue\n",
    "        loc = mapped_all[name_idx[name], :].dot(vec_mat)\n",
    "        loc /= max(1, mapped_all_mag[name_idx[name]])\n",
    "        cmu_scores.append((loc, name))\n",
    "        uni_colors.append(uni_labels_unique.index(d))\n",
    "        # print(name,d)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_names  = list(cmu_uni.name)\n",
    "for row in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = np.vstack([_[0] for _ in cmu_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = TSNE(2, 2, init=\"random\", n_iter=6500)\n",
    "# embedder = TSNE(2,1)\n",
    "\n",
    "ys = embedder.fit_transform(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "nc = len(uni_labels_unique)\n",
    "cmap = plt.get_cmap(\"tab10_r\")\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.scatter(\n",
    "    ys[:, 0],\n",
    "    ys[:, 1],\n",
    "    s=20,\n",
    "    lw=0.2,\n",
    "    edgecolors=\"k\",\n",
    "    c=cmap(np.array(uni_colors) / 10 + 0.2),\n",
    ")\n",
    "for i in range(ys.shape[0]):\n",
    "    rv = np.random.randn(2)\n",
    "    xr, yr = 0.2 * (rv)  # /np.linalg.norm(rv)\n",
    "    text = plt.text(\n",
    "        ys[i, 0] + xr,\n",
    "        yr + ys[i, 1],\n",
    "        cmu_scores[i][1],\n",
    "        size=\"12\",\n",
    "        color=cmap(uni_colors[i] / 10 + 0.2),\n",
    "        horizontalalignment=\"center\",\n",
    "        verticalalignment=\"center\",\n",
    "        alpha=0.8,\n",
    "        weight=\"demibold\",\n",
    "    )\n",
    "    # text.set_path_effects([path_effects.Stroke(linewidth=0.05, foreground='black'),\n",
    "    #           path_effects.Normal()])\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cmu_faculty.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# very different stuff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "r1_scores = pickle.load(open(\"r1_scores.pkl\", \"rb\"))\n",
    "r1_confs = pickle.load(open(\"r1_confs.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = TSNE(perplexity=15, n_iter=10000, metric=\"cosine\")\n",
    "ys = embed.fit_transform(vec_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = MiniBatchKMeans(25, n_init=100)\n",
    "km.fit(vec_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_small = np.zeros(len(full_to_sub))\n",
    "for old, new in full_to_sub.items():\n",
    "    clf_small[new] = clf[old * span_years : (old + 1) * span_years][-2]\n",
    "    print(r1_confs[new], clf_small[new])\n",
    "    if r1_confs[new] == \"JCDL\":\n",
    "        print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# conf_d = cdist(vec_mat[31].reshape((1,-1)),vec_mat,metric='cosine')[0]\n",
    "# conf_s = np.argsort(conf_d)\n",
    "# for i in range(10):\n",
    "#    print(r1_confs[conf_s[i]],conf_d[conf_s[i]],clf_small[conf_s[i]])\n",
    "# old = conf_idx['Scientometrics']\n",
    "# print('Scientometrics',max(clf[old*span_years:(old+1)*span_years]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(25, 25))\n",
    "cmap = plt.get_cmap(\"tab20c_r\")\n",
    "# plt.subplot(1,2,1)\n",
    "plt.scatter(\n",
    "    ys[:, 0],\n",
    "    ys[:, 1],\n",
    "    c=km.labels_ / 25,\n",
    "    cmap=\"tab20c_r\",\n",
    "    s=0.15 * r1_scores ** 2,\n",
    "    lw=0.1,\n",
    "    edgecolors=\"k\",\n",
    ")\n",
    "for i in range(25):\n",
    "    tmp = [(r1_scores[i], i) for i, v in enumerate(km.labels_ == i) if v]\n",
    "    score_idx = sorted(tmp, reverse=True)\n",
    "    print(i)\n",
    "    k = 4\n",
    "    j = 0\n",
    "    for s, idx in reversed(score_idx[:k]):\n",
    "        rv = np.random.randn(2)\n",
    "        xr, yr = 3 * (rv)  # /np.linalg.norm(rv)\n",
    "        text = plt.text(\n",
    "            xr + ys[idx, 0],\n",
    "            2 * (j - (k - 1) / 2) / (k - 1) + ys[idx, 1],\n",
    "            r1_confs[idx],\n",
    "            size=\"18\",\n",
    "            color=np.array(cmap(i / 24)),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            alpha=0.9,\n",
    "            weight=\"bold\",\n",
    "        )\n",
    "        text.set_path_effects(\n",
    "            [\n",
    "                path_effects.Stroke(linewidth=1, foreground=\"black\"),\n",
    "                path_effects.Normal(),\n",
    "            ]\n",
    "        )\n",
    "        j += 1\n",
    "        print(\"\\t\", r1_confs[idx])\n",
    "    # print()\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tsne1.pdf\")\n",
    "# plt.title('Clusters and largest venues',size=48)\n",
    "if False:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patheffects as path_effects\n",
    "\n",
    "    cmap = plt.get_cmap(\n",
    "        \"tab20c_r\"\n",
    "    )  # cmap=cmap,c=km.labels_/26 #cmap=cmap2,c=cmap_small\n",
    "    cmap2 = plt.get_cmap(\"viridis\")\n",
    "    cmap_small = clf_small - clf_small.min()\n",
    "    cmap_small = cmap_small / cmap_small.max()\n",
    "    plt.scatter(\n",
    "        ys[:, 0],\n",
    "        ys[:, 1],\n",
    "        cmap=cmap2,\n",
    "        c=cmap_small,\n",
    "        s=0.15 * r1_scores ** 2,\n",
    "        lw=0.1,\n",
    "        edgecolors=\"k\",\n",
    "    )\n",
    "    for i in range(26):\n",
    "        tmp = [(clf_small[i], i) for i, v in enumerate(km.labels_ == i) if v]\n",
    "        score_idx = sorted(tmp, reverse=True)\n",
    "        # print(i)\n",
    "        k = 3\n",
    "        j = 0\n",
    "        print(i)\n",
    "        for s, idx in reversed(score_idx[:k]):\n",
    "            rv = np.random.randn(2)\n",
    "            xr, yr = 2 * (rv)  # /np.linalg.norm(rv) #np.array(cmap(i/25))\n",
    "            # print(cmap_small[idx],idx)\n",
    "            text = plt.text(\n",
    "                ys[idx, 0] + xr,\n",
    "                3 * (j - (k - 1) / 2) / (k - 1) + ys[idx, 1],\n",
    "                r1_confs[idx],\n",
    "                size=\"20\",\n",
    "                color=np.array(cmap2(cmap_small[idx])),\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                alpha=0.9,\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "            text.set_path_effects(\n",
    "                [\n",
    "                    path_effects.Stroke(\n",
    "                        linewidth=2, foreground=\"white\"\n",
    "                    ),  # foreground= np.array(cmap(i/25))),\n",
    "                    path_effects.Normal(),\n",
    "                ]\n",
    "            )\n",
    "            j += 1\n",
    "            print(\"\\t\", r1_confs[idx], s)\n",
    "    # plt.title('Highest Quality',size=48)\n",
    "    plt.savefig(\"tsne1.pdf\")\n",
    "    # print('\\t',r1_confs[idx])\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(25, 25))\n",
    "cmap = plt.get_cmap(\"tab20c_r\")\n",
    "# plt.subplot(1,2,1)\n",
    "plt.scatter(\n",
    "    ys[:, 0],\n",
    "    ys[:, 1],\n",
    "    c=km.labels_ / 26,\n",
    "    cmap=\"tab20c_r\",\n",
    "    s=0.15 * r1_scores ** 2,\n",
    "    lw=0.1,\n",
    "    edgecolors=\"k\",\n",
    ")\n",
    "for i in range(26):\n",
    "    tmp = [(r1_scores[i], i) for i, v in enumerate(km.labels_ == i) if v]\n",
    "    score_idx = sorted(tmp, reverse=True)\n",
    "    k = 4\n",
    "    j = 0\n",
    "    for s, idx in reversed(score_idx[:k]):\n",
    "        rv = np.random.randn(2)\n",
    "        xr, yr = 3 * (rv)  # /np.linalg.norm(rv)\n",
    "        text = plt.text(\n",
    "            xr + ys[idx, 0],\n",
    "            2 * (j - (k - 1) / 2) / (k - 1) + ys[idx, 1],\n",
    "            r1_confs[idx],\n",
    "            size=\"14\",\n",
    "            color=np.array(cmap(i / 25)),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            alpha=0.4,\n",
    "            weight=\"bold\",\n",
    "        )\n",
    "        text.set_path_effects(\n",
    "            [\n",
    "                path_effects.Stroke(linewidth=1, foreground=\"black\"),\n",
    "                path_effects.Normal(),\n",
    "            ]\n",
    "        )\n",
    "        j += 1\n",
    "    # print()\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.tight_layout()\n",
    "plt.title(\"Clusters of Venues\", size=25)\n",
    "if False:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patheffects as path_effects\n",
    "\n",
    "    cmap = plt.get_cmap(\n",
    "        \"tab20c_r\"\n",
    "    )  # cmap=cmap,c=km.labels_/26 #cmap=cmap2,c=cmap_small\n",
    "    cmap2 = plt.get_cmap(\"viridis\")\n",
    "    cmap_small = clf_small - clf_small.min()\n",
    "    cmap_small = cmap_small / cmap_small.max()\n",
    "    plt.scatter(\n",
    "        ys[:, 0],\n",
    "        ys[:, 1],\n",
    "        cmap=cmap2,\n",
    "        c=cmap_small,\n",
    "        s=0.15 * r1_scores ** 2,\n",
    "        lw=0.1,\n",
    "        edgecolors=\"k\",\n",
    "    )\n",
    "    for i in range(26):\n",
    "        tmp = [(clf_small[i], i) for i, v in enumerate(km.labels_ == i) if v]\n",
    "        score_idx = sorted(tmp, reverse=True)\n",
    "        # print(i)\n",
    "        k = 3\n",
    "        j = 0\n",
    "        for s, idx in reversed(score_idx[:k]):\n",
    "            rv = np.random.randn(2)\n",
    "            xr, yr = 2 * (rv)  # /np.linalg.norm(rv) #np.array(cmap(i/25))\n",
    "            text = plt.text(\n",
    "                ys[idx, 0] + xr,\n",
    "                3 * (j - (k - 1) / 2) / (k - 1) + ys[idx, 1],\n",
    "                r1_confs[idx],\n",
    "                size=\"20\",\n",
    "                color=np.array(cmap2(cmap_small[idx])),\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                alpha=0.9,\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "            text.set_path_effects(\n",
    "                [\n",
    "                    path_effects.Stroke(\n",
    "                        linewidth=2, foreground=\"white\"\n",
    "                    ),  # foreground= np.array(cmap(i/25))),\n",
    "                    path_effects.Normal(),\n",
    "                ]\n",
    "            )\n",
    "            j += 1\n",
    "    plt.title(\"Highest Quality\", size=48)\n",
    "    # print('\\t',r1_confs[idx])\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(25, 25))\n",
    "cmap = plt.get_cmap(\"tab20c_r\")  # cmap=cmap,c=km.labels_/26 #cmap=cmap2,c=cmap_small\n",
    "cmap2 = plt.get_cmap(\"viridis\")\n",
    "cmap_small = clf_small - clf_small.min()\n",
    "cmap_small = cmap_small / cmap_small.max()\n",
    "plt.scatter(\n",
    "    ys[:, 0],\n",
    "    ys[:, 1],\n",
    "    cmap=cmap,\n",
    "    c=km.labels_ / 26,\n",
    "    s=0.15 * r1_scores ** 2,\n",
    "    lw=0.1,\n",
    "    edgecolors=\"k\",\n",
    ")\n",
    "for i in range(26):\n",
    "    tmp = [(clf_small[i], i) for i, v in enumerate(km.labels_ == i) if v]\n",
    "    score_idx = sorted(tmp, reverse=True)\n",
    "    # print(i)\n",
    "    k = 3\n",
    "    j = 0\n",
    "    # print(i)\n",
    "    for s, idx in reversed(score_idx[:k]):\n",
    "        rv = np.random.randn(2)\n",
    "        xr, yr = 3 * (rv)  # /np.linalg.norm(rv) #np.array(cmap(i/25))\n",
    "        # print(cmap_small[idx],idx)\n",
    "        # text = plt.text(ys[idx,0]+xr,3*(j-(k-1)/2)/(k-1)+ys[idx,1],r1_confs[idx],size='20',color=np.array(cmap(km.labels_[idx]/25)),\n",
    "        #         ha='center',va='center',alpha=0.9,weight='bold')\n",
    "        # text.set_path_effects([path_effects.Stroke(linewidth=1, foreground='black'),\n",
    "        #               path_effects.Normal()])\n",
    "        j += 1\n",
    "        # print('\\t',r1_confs[idx],s)\n",
    "    # print('\\t',r1_confs[idx])\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(25, 25))\n",
    "cmap = plt.get_cmap(\"tab20c_r\")  # cmap=cmap,c=km.labels_/26 #cmap=cmap2,c=cmap_small\n",
    "cmap2 = plt.get_cmap(\"viridis\")\n",
    "cmap_small = clf_small - clf_small.min()\n",
    "cmap_small = np.minimum(1, 2 * cmap_small / cmap_small.max())\n",
    "plt.scatter(\n",
    "    ys[:, 0],\n",
    "    ys[:, 1],\n",
    "    cmap=cmap2,\n",
    "    c=cmap_small,\n",
    "    s=0.15 * r1_scores ** 2,\n",
    "    lw=0.1,\n",
    "    edgecolors=\"k\",\n",
    ")\n",
    "for i in range(26):\n",
    "    tmp = [(clf_small[i], i) for i, v in enumerate(km.labels_ == i) if v]\n",
    "    score_idx = sorted(tmp, reverse=True)\n",
    "    # print(i)\n",
    "    k = 30\n",
    "    j = 0\n",
    "    # print(i)\n",
    "    for s, idx in score_idx[:k]:\n",
    "        rv = np.random.randn(2)\n",
    "        xr, yr = 3 * (rv)  # /np.linalg.norm(rv) #np.array(cmap(i/25))\n",
    "        # print(cmap_small[idx],idx)\n",
    "        # text = plt.text(ys[idx,0]+xr,3*(j-(k-1)/2)/(k-1)+ys[idx,1],r1_confs[idx],size='20',color=np.array(cmap(km.labels_[idx]/25)),\n",
    "        #         ha='center',va='center',alpha=0.9,weight='bold')\n",
    "        # text.set_path_effects([path_effects.Stroke(linewidth=1, foreground='black'),\n",
    "        #               path_effects.Normal()])\n",
    "        j += 1\n",
    "        print(i, \"\\t\", r1_confs[idx], s)\n",
    "    # print('\\t',r1_confs[idx])\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = pd.read_csv(\"../ranks.csv\")\n",
    "top_k = 36\n",
    "subplot = int(round(np.sqrt(top_k)))\n",
    "min_v = ys.min(0)\n",
    "max_v = ys.max(0)\n",
    "plt.figure(figsize=(subplot * 4, subplot * 4))\n",
    "\n",
    "for i in range(top_k):\n",
    "    Uname = ranks.iloc[i, :].uni\n",
    "    uni_faculty = faculty_affil[faculty_affil.affiliation == Uname]\n",
    "    uni_names = np.array(uni_faculty.name)\n",
    "    uni_names = list(uni_names)\n",
    "    cmu_scores = []\n",
    "    for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "        if name in name_idx:\n",
    "            loc = mapped_all[name_idx[name], :].dot(ys)\n",
    "            loc /= max(1, mapped_all_mag[name_idx[name]])\n",
    "            cmu_scores.append((loc))\n",
    "    cmu_scores = np.squeeze(np.array(cmu_scores))\n",
    "    plt.subplot(subplot, subplot, i + 1)\n",
    "    plt.hexbin(\n",
    "        cmu_scores[:, 0],\n",
    "        cmu_scores[:, 1],\n",
    "        gridsize=13,\n",
    "        extent=(min_v[0], max_v[0], min_v[1], max_v[1]),\n",
    "        vmin=0,\n",
    "        vmax=4,\n",
    "    )\n",
    "    plt.title(Uname, color=\"k\", weight=\"demibold\")\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fingers.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_names = prev_cand  # + curious_names\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "\n",
    "cmu_uni = pd.read_csv(\"cmu_faculty.csv\")\n",
    "cmu_uni = cmu_uni.fillna(\"Other\")\n",
    "# print(list(cmu_uni.name))\n",
    "uni_names = list(cmu_uni.name) + good_names\n",
    "uni_labels = list(cmu_uni.dept) + len(good_names) * [\"cand\"]\n",
    "uni_labels_unique = list(set(uni_labels)) + [\"cand\"]\n",
    "cmu_scores = []\n",
    "cmu_full_dim = []\n",
    "cmu_names = []\n",
    "uni_colors = []\n",
    "cand_num = 0\n",
    "for name, d in [(aliasdict.get(n, n), dept) for n, dept in zip(uni_names, uni_labels)]:\n",
    "    if name in cmu_names:\n",
    "        continue\n",
    "    if name in name_idx:\n",
    "        # if ri_scores[name_idx[name]] < 2.5:\n",
    "        #    continue\n",
    "        loc = mapped_all[name_idx[name], :].dot(ys)\n",
    "        loc /= max(1, mapped_all_mag[name_idx[name]])\n",
    "        cmu_scores.append((loc))\n",
    "        loc = mapped_all[name_idx[name], :].dot(vec_mat)\n",
    "        loc /= max(1, mapped_all_mag[name_idx[name]])\n",
    "        cmu_full_dim.append((loc))\n",
    "        cmu_names.append(name)\n",
    "        uni_colors.append(uni_labels_unique.index(d))\n",
    "        if d == \"cand\":\n",
    "            cand_num += 1\n",
    "    else:\n",
    "        pass\n",
    "cmu_scores = np.squeeze(np.array(cmu_scores))\n",
    "import matplotlib.colors\n",
    "\n",
    "nc = len(uni_labels_unique)\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "plt.figure(figsize=(30, 30))\n",
    "plt.scatter(\n",
    "    cmu_scores[:, 0],\n",
    "    cmu_scores[:, 1],\n",
    "    s=120,\n",
    "    lw=1,\n",
    "    edgecolors=\"k\",\n",
    "    c=cmap(np.array(uni_colors) / nc - 0.0),\n",
    "    alpha=0.5,\n",
    ")\n",
    "for i in range(cmu_scores.shape[0]):\n",
    "    rv = np.random.randn(2)\n",
    "    xr, yr = 0.7 * (rv)  # /np.linalg.norm(rv)\n",
    "    plt.text(\n",
    "        cmu_scores[i, 0] + xr,\n",
    "        yr + cmu_scores[i, 1],\n",
    "        cmu_names[i],\n",
    "        size=\"16\",\n",
    "        color=cmap(uni_colors[i] / nc),\n",
    "        horizontalalignment=\"center\",\n",
    "        verticalalignment=\"center\",\n",
    "        alpha=0.9,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_full_dim = np.squeeze(np.array(cmu_full_dim))\n",
    "faculty = cmu_full_dim[:-cand_num, :]\n",
    "cands = cmu_full_dim[-cand_num:, :]\n",
    "faculty.shape, cands.shape\n",
    "nullvec = np.linalg.norm(faculty, axis=1) == 0\n",
    "faculty[nullvec] = np.random.randn(nullvec.sum(), faculty.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "dist = cdist(faculty, cands, metric=\"cosine\")\n",
    "min_dist = np.argmin(dist, 0)\n",
    "top_k = 3\n",
    "if False:  # if included candidates in cmu_names, plot their 3 nearest neighbors\n",
    "\n",
    "    for i, cand_name in enumerate(cmu_names[-cand_num:]):\n",
    "        nns = np.argsort(dist[:, i])\n",
    "        print(\"{:20s}\".format(cand_name), end=\"\\t\")\n",
    "        for j in range(top_k):\n",
    "            name_dist = \"{} ({:.1f})\".format(\n",
    "                cmu_names[nns[j]][:25], 100 * dist[nns[j], i]\n",
    "            )\n",
    "            print(\"{:30s}\".format(name_dist), end=\" \")\n",
    "        print(\"\\n\", end=\"\")\n",
    "        nns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "def di():\n",
    "    return defaultdict(float)\n",
    "\n",
    "\n",
    "author_by_year = defaultdict(di)\n",
    "for row in papers.itertuples():\n",
    "    paper_year = row[10]\n",
    "    conf = row[2]\n",
    "    n = row[4]\n",
    "    authors = row[3]\n",
    "    for a in authors:\n",
    "        auth = aliasdict.get(a, a)\n",
    "        author_by_year[auth][paper_year] += (\n",
    "            clf[span_years * conf_idx[conf] + paper_year - 1970] / n\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_by_year = np.zeros(2019 - 1969)\n",
    "v_count = np.zeros(2019 - 1969)\n",
    "for auth, years in author_by_year.items():\n",
    "    yrs = years.keys()\n",
    "    start_year = min(yrs)\n",
    "    end_year = max(yrs)\n",
    "    span = end_year - start_year\n",
    "    if span < 85:\n",
    "        for y, v in years.items():\n",
    "            val_by_year[y - start_year] += v\n",
    "            v_count[y - start_year] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "example_names = [\n",
    "    \"Takeo Kanade\",\n",
    "    \"Martial Hebert\",\n",
    "    \"Christopher G. Atkeson\",\n",
    "    \"Howie Choset\",\n",
    "    \"Deva Ramanan\",\n",
    "    \"Matthew T. Mason\",\n",
    "    \"Jessica K. Hodgins\",\n",
    "    \"Abhinav Gupta\",\n",
    "]  # ,'Pieter Abbeel'\n",
    "for example_name in example_names:\n",
    "    example_value = np.zeros(max_year + 1 - min_year)\n",
    "    years = author_by_year[example_name]\n",
    "    yrs = [_ for _ in years.keys() if _ > 0]\n",
    "    start_year = min(yrs)\n",
    "    end_year = max(yrs)\n",
    "    span = end_year - start_year\n",
    "    start_year, end_year, span\n",
    "    for y, v in years.items():\n",
    "        example_value[y - 1970] += v\n",
    "\n",
    "    plt.plot(\n",
    "        np.arange(1970, 2018),\n",
    "        gaussian_filter1d(example_value[:-2], sigma=2),\n",
    "        label=example_name,\n",
    "    )\n",
    "    # plt.plot(gaussian_filter1d(example_value[:span], sigma=2),label=example_name )\n",
    "\n",
    "# plt.plot((val_by_year/v_count),label='average author')\n",
    "plt.ylabel(\"annual value (3yr avg)\")\n",
    "# plt.xlabel('year since first publication')\n",
    "plt.xlabel(\"working year\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"cmu_careers.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_by_year)\n",
    "plt.title(\"author value by year\")\n",
    "plt.xlabel(\"years since first publication\")\n",
    "plt.ylabel(\"total annual value generated\")\n",
    "plt.grid(True)\n",
    "plt.figure()\n",
    "plt.plot(v_count)\n",
    "plt.xlabel(\"years since first publication\")\n",
    "plt.ylabel(\"number of authors\")\n",
    "plt.grid(True)\n",
    "plt.figure()\n",
    "plt.plot(val_by_year / v_count)\n",
    "plt.title(\"author value by year\")\n",
    "plt.xlabel(\"years since first publication\")\n",
    "plt.ylabel(\"average annual value generated\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(0, 26, 5):\n",
    "    plt.subplot(2, 3, i // 5 + 1)\n",
    "    val_by_year_surv = np.zeros(2019 - 1969)\n",
    "    v_count_surv = np.zeros(2019 - 1969)\n",
    "    for auth, years in author_by_year.items():\n",
    "        yrs = years.keys()\n",
    "        start_year = min(yrs)\n",
    "        end_year = max(yrs)\n",
    "        span = end_year - start_year\n",
    "        if span >= i:\n",
    "            # value_vec = np.array(list(years.values()))\n",
    "            # min_v = value_vec.min()\n",
    "            # total = (value_vec-min_v).sum()\n",
    "            for y, v in years.items():\n",
    "                val_by_year_surv[y - start_year] += v  # (v-min_v)/total\n",
    "                v_count_surv[y - start_year] += 1\n",
    "    plt.plot(val_by_year_surv / v_count_surv)\n",
    "    plt.title(\"author value by year (career $\\geq$ {} yrs)\".format(i))\n",
    "    plt.xlabel(\"years since first publication\")\n",
    "    plt.ylabel(\"annual value generated\")\n",
    "    # sorted_vals = sorted(val_by_year_surv)\n",
    "    # plt.ylim(-250,1950)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusted Plus-Minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xapm = scipy.sparse.dok_matrix((papers.shape[0], len(unique_names)))\n",
    "xdict = {}\n",
    "y = np.zeros(papers.shape[0])\n",
    "for row in papers.itertuples():\n",
    "    paper_year = row[10]\n",
    "    conf = row[2]\n",
    "    n = row[4]\n",
    "    authors = row[3]\n",
    "    if conf == \"CoRR\":\n",
    "        continue\n",
    "    # if conf not in r1_confs:\n",
    "    #    continue\n",
    "    y[row[0]] = clf[span_years * conf_idx[conf] + paper_year - min_year]\n",
    "    for a in authors:\n",
    "        xdict[(row[0], name_idx[a])] = 1\n",
    "        # Xapm[row[0],name_idx[a]] = 1\n",
    "Xapm._update(xdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist((y - y.mean()) / y.std(), 50)\n",
    "y.std(), y.mean()\n",
    "plt.figure()\n",
    "_ = plt.hist(y, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# huber is noise tolerant, squared is not, zeros weights conferences equally, otherwise using learned weightrs\n",
    "X = scipy.sparse.csr_matrix(Xapm)\n",
    "# good ones\n",
    "clf2 = SGDRegressor(\n",
    "    \"squared_loss\",\n",
    "    alpha=1e-3,\n",
    "    penalty=\"l2\",\n",
    "    tol=1e-6,\n",
    "    max_iter=100,\n",
    "    average=True,\n",
    "    verbose=1,\n",
    "    fit_intercept=True,\n",
    ")  # ,fit_intercept=False\n",
    "# clf2 = SGDRegressor('squared_loss',alpha=1e-3,penalty='l2',tol=1e-6,max_iter=1000,average=True,verbose=1)\n",
    "# high reg?\n",
    "# clf2 = SGDRegressor('huber',alpha=0,penalty='l2',tol=1e-6,max_iter=100,average=True,verbose=1)\n",
    "\n",
    "clf2.fit(X, (y - y.mean()) / y.std())\n",
    "# clf2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.argsort(clf2.coef_)[::-1]\n",
    "k = 500\n",
    "rs = ri_scores.std()\n",
    "us = clf2.coef_.std()\n",
    "ts = value_scores.std()\n",
    "for i in range(k):\n",
    "    idx = scores[i]\n",
    "    if ri_scores[idx] / rs < 20.0:\n",
    "        continue\n",
    "    print(\n",
    "        \"{}\\t{:35}\\t{:.1f}\".format(i + 1, unique_names[idx][:30], clf2.coef_[idx] / us)\n",
    "    )\n",
    "_ = plt.hist(clf2.coef_ / us, 100)\n",
    "clf2.coef_[name_idx[\"Judea Pearl\"]] / us, value_scores[name_idx[\"Judea Pearl\"]] / ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.argsort(value_scores)[::-1]\n",
    "ts = value_scores.std()\n",
    "k = 500\n",
    "for i in range(k):\n",
    "    idx = scores[i]\n",
    "    if ri_scores[idx] / rs < 20.0:\n",
    "        continue\n",
    "    print(\n",
    "        \"{}\\t{:35}\\t{:.1f}\".format(\n",
    "            i + 1, unique_names[idx][:30], value_scores[idx] / rs\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_papers = np.zeros(len(unique_names))\n",
    "count_norm_papers = np.zeros(len(unique_names))\n",
    "for row in papers.itertuples():\n",
    "    paper_year = row[10]\n",
    "    conf = row[2]\n",
    "    n = row[4]\n",
    "    authors = row[3]\n",
    "    for a in authors:\n",
    "        auth = aliasdict.get(a, a)\n",
    "        if auth in name_idx:\n",
    "            count_papers[name_idx[auth]] += 1\n",
    "            count_norm_papers[name_idx[auth]] += 1 / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_faculty = faculty_affil[\n",
    "    faculty_affil.affiliation == \"Carnegie Mellon University\"\n",
    "]  # Carnegie Mellon University\n",
    "uni_names = np.array(uni_faculty.name)\n",
    "uni_names = list(\n",
    "    uni_names\n",
    ")  # + ['Derek Hoiem','Nicholas Rhinehart','Jacob Walker','Lerrel Pinto','Brian Okorn','Leonid Keselman','Siddharth Ancha','Humphrey Hu']\n",
    "cmu_scores = []\n",
    "count_papers\n",
    "count_norm_papers\n",
    "for name in uni_names:  # ['Martial Hebert','Abhinav Gupta','Derek Hoiem','David Held']:\n",
    "    if name in name_idx:\n",
    "        idx = name_idx[name]\n",
    "        cmu_scores.append((clf2.coef_[idx] / us, unique_names[idx]))\n",
    "for s, name in sorted(cmu_scores, reverse=True):\n",
    "    print(\"{:40s}\\t\\t\\t\\t{:.1f}\".format(name[:38], s))\n",
    "Xapm.shape, len(unique_confs) * span_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_list = list(faculty_affil.name)\n",
    "fa_a_list = list(faculty_affil.affiliation)\n",
    "z = []\n",
    "ts = total_scores.std()\n",
    "for name in curious_names:\n",
    "    sidx = name_idx[name]\n",
    "    uni = \"unknown\"\n",
    "    if unique_names[sidx] in fa_list:\n",
    "        uni = fa_a_list[fa_list.index(unique_names[sidx])]\n",
    "    i = (scores.shape[0] - np.where(scores == sidx)[0])[0]\n",
    "    z.append(\n",
    "        (\n",
    "            clf2.coef_[sidx] / us,\n",
    "            unique_names[sidx][:20],\n",
    "            uni[:20],\n",
    "            total_scores[sidx] / ts,\n",
    "            ri_scores[sidx] / rs,\n",
    "            auth_years[sidx, 0],\n",
    "            auth_years[sidx, 1],\n",
    "        )\n",
    "    )\n",
    "print(\n",
    "    \"{}\\t{:30s}\\t{:25s}{}\\t{}\\t{} {}\".format(\n",
    "        \"APM\", \"name\", \"uni\", \"TS\", \"RI-s\", \"start\", \"end\"\n",
    "    )\n",
    ")\n",
    "for _ in sorted(z, reverse=True):\n",
    "    print(\"{:.2f}\\t{:30s}\\t{:25s}{:.1f}\\t{:.1f}\\t{:.0f} {:.0f}\".format(*_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "for name in prev_cand:\n",
    "    sidx = name_idx[name]\n",
    "    uni = \"unknown\"\n",
    "    if unique_names[sidx] in fa_list:\n",
    "        uni = fa_a_list[fa_list.index(unique_names[sidx])]\n",
    "    i = (scores.shape[0] - np.where(scores == sidx)[0])[0]\n",
    "    z.append(\n",
    "        (\n",
    "            i + 1,\n",
    "            unique_names[sidx][:20],\n",
    "            uni[:20],\n",
    "            clf2.coef_[sidx] / us,\n",
    "            total_scores[sidx] / ts,\n",
    "            ri_scores[sidx] / rs,\n",
    "            auth_years[sidx, 0],\n",
    "            auth_years[sidx, 1],\n",
    "        )\n",
    "    )\n",
    "print(\n",
    "    \"{}\\t{:30s}\\t{:25s}{}\\t{}\\t{}\\t{} {}\".format(\n",
    "        \"rank\", \"name\", \"uni\", \"APM\", \"TS\", \"RI-s\", \"start\", \"end\"\n",
    "    )\n",
    ")\n",
    "for _ in sorted(z):\n",
    "    print(\"{}\\t{:30s}\\t{:25s}{:.1f}\\t{:.1f}\\t{:.1f}\\t{:.0f} {:.0f}\".format(*_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "def di():\n",
    "    return defaultdict(float)\n",
    "\n",
    "\n",
    "apm_by_year = np.zeros(2019 - 1969)\n",
    "apm_cnt_by_year = np.zeros(2019 - 1969)\n",
    "for idx in range(clf2.coef_.shape[0]):\n",
    "    start_year = auth_years[idx, 0]\n",
    "    end_year = auth_years[idx, 1]\n",
    "    span = int(end_year - start_year)\n",
    "    if span >= 0:\n",
    "        apm_by_year[span] += clf2.coef_[idx] / us\n",
    "        apm_cnt_by_year[span] += 1\n",
    "plt.plot(apm_by_year)\n",
    "plt.title(\"plus minus by wokring year\")\n",
    "plt.xlabel(\"years since first publication\")\n",
    "plt.ylabel(\"total apm\")\n",
    "plt.grid(True)\n",
    "plt.figure()\n",
    "plt.plot(apm_cnt_by_year)\n",
    "plt.xlabel(\"years since first publication\")\n",
    "plt.ylabel(\"number of authors\")\n",
    "plt.grid(True)\n",
    "plt.figure()\n",
    "plt.plot(apm_by_year / apm_cnt_by_year)\n",
    "plt.title(\"author value by year\")\n",
    "plt.xlabel(\"years since first publication\")\n",
    "plt.ylabel(\"average apm\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apm_by_year = np.zeros(2019 - 1969)\n",
    "apm_cnt_by_year = np.zeros(2019 - 1969)\n",
    "for idx in range(total_scores.shape[0]):\n",
    "    start_year = auth_years[idx, 0]\n",
    "    end_year = auth_years[idx, 1]\n",
    "    span = int(end_year - start_year)\n",
    "    if span >= 0:\n",
    "        apm_by_year[span] += total_scores[idx] / ts\n",
    "        apm_cnt_by_year[span] += 1\n",
    "plt.figure()\n",
    "plt.plot(apm_by_year / apm_cnt_by_year)\n",
    "plt.title(\"author value by year\")\n",
    "plt.xlabel(\"years since first publication\")\n",
    "plt.ylabel(\"average value\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using CLF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftfy\n",
    "from unidecode import unidecode\n",
    "\n",
    "k = 500\n",
    "i = 0\n",
    "scores = np.argsort(clf2.coef_)  # norm_scores (rate), total_scores (total), clf2.coef_\n",
    "fa_list = list(faculty_affil.name)\n",
    "fa_a_list = list(faculty_affil.affiliation)\n",
    "rs = ri_scores.std()\n",
    "ts = total_scores.std()\n",
    "print(\n",
    "    \"rank\\t{:20s}\\t{:20s} {}\\t{:27s} {}\\t{}\\t{} {}\".format(\n",
    "        \"name\",\n",
    "        \"uni (if prof)\",\n",
    "        \"score\",\n",
    "        \"CMU nn            (nn dist)\",\n",
    "        \"APM\",\n",
    "        \"RI s\",\n",
    "        \"start\",\n",
    "        \"end\",\n",
    "    )\n",
    ")\n",
    "\n",
    "for sidx in scores[::-1]:\n",
    "    uni = \"unknown\"\n",
    "\n",
    "    if years_working[sidx] < 3:\n",
    "        continue\n",
    "    if years_working[sidx] > 9:\n",
    "        continue\n",
    "    if auth_years[sidx, 1] < 2016:\n",
    "        continue\n",
    "    if ri_scores[sidx] / rs < 1.4:\n",
    "        continue\n",
    "    if unique_names[sidx] in fa_list:\n",
    "        uni = fa_a_list[fa_list.index(unique_names[sidx])]\n",
    "    loc = mapped_all[sidx, :].dot(vec_mat)\n",
    "    loc /= max(1, mapped_all_mag[sidx])\n",
    "    dist = cdist(loc, faculty, metric=\"cosine\")\n",
    "\n",
    "    min_dist = np.argmin(dist[0])\n",
    "    cmn, cms = cmu_names[min_dist][:20], dist[0, min_dist]\n",
    "    name_dist = \"{:20s} ({:.1f})\".format(cmn, cms * 100)\n",
    "    print(\n",
    "        \"{}\\t{:20s}\\t{:20s} {:.2f}\\t{:25s} {:.1f}\\t{:.1f}\\t{:.0f} {:.0f}\".format(\n",
    "            i + 1,\n",
    "            unidecode(ftfy.fix_encoding(unique_names[sidx][:20])),\n",
    "            uni[:20],\n",
    "            total_scores[sidx] / ts,\n",
    "            name_dist,\n",
    "            clf2.coef_[sidx] / us,\n",
    "            ri_scores[sidx] / rs,\n",
    "            auth_years[sidx, 0],\n",
    "            auth_years[sidx, 1],\n",
    "        )\n",
    "    )\n",
    "    i += 1\n",
    "\n",
    "    if i == k:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftfy\n",
    "from unidecode import unidecode\n",
    "\n",
    "[\n",
    "    unidecode(ftfy.fix_encoding(unique_names[_]))\n",
    "    for _ in [641932, 612947, 127117, 852686, 879945]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands = (\n",
    "    (auth_years[:, 0] > 2010)\n",
    "    & (auth_years[:, 1] > 2016)\n",
    "    & (auth_years[:, 1] - auth_years[:, 0] >= 2)\n",
    "    & (ri_scores / rs > 1.3)\n",
    ")\n",
    "print(cands.sum())\n",
    "plt.scatter(total_scores[cands] / ts, clf2.coef_[cands] / us, s=3)\n",
    "plt.xlabel(\"total value\")\n",
    "plt.ylabel(\"credit assigned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands = np.zeros(len(unique_names)).astype(np.bool)\n",
    "for i in cmu_names:\n",
    "    cands[name_idx[i]] = True\n",
    "len_years = auth_years[:, 1] - auth_years[:, 0]\n",
    "len_years[len_years < 1] = 1\n",
    "xv = total_scores / (ts * len_years)\n",
    "yv = clf2.coef_ / (us * len_years)\n",
    "# xv[xv == 0] = 0\n",
    "# yv[yv == 0] = 1\n",
    "# xv,yv = np.log(xv),np.log(yv)\n",
    "# xv[np.isnan(xv)] = 0\n",
    "# yv[np.isnan(yv)] = 0\n",
    "plt.figure(figsize=(24, 24))\n",
    "plt.scatter(xv[cands], yv[cands], s=3)\n",
    "plt.xlabel(\"total value per year\")\n",
    "plt.ylabel(\"credit assigned year\")\n",
    "plt.xlim(0, 3)\n",
    "plt.ylim(0, 3)\n",
    "for i in cmu_names:\n",
    "    plt.text(xv[name_idx[i]], yv[name_idx[i]], i, ha=\"center\", va=\"center\")\n",
    "    if \"Lee\" in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# university rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_fil = [1 if _ + 1970 >= 2010 else 0 for _ in range(span_years)]\n",
    "recent_fil = len(conf_idx) * [1 if _ + 1970 >= 2010 else 0 for _ in range(span_years)]\n",
    "clf_fil = clf * np.array(recent_fil)\n",
    "rec_scores = Xauth.dot(ri_filter_mat).dot(clf_fil)\n",
    "rec_all_scores = Xauth.dot(clf_fil)\n",
    "unis = faculty_affil.affiliation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd():\n",
    "    return defaultdict(float)\n",
    "\n",
    "\n",
    "uni_fac_scores = defaultdict(fd)\n",
    "uni_ts_scores = defaultdict(fd)\n",
    "uni_rs_scores = defaultdict(fd)\n",
    "uni_tsall_scores = defaultdict(fd)\n",
    "\n",
    "for row in faculty_affil.itertuples():\n",
    "    auth = aliasdict.get(row[1], row[1])\n",
    "    uni = row[2]\n",
    "    if auth not in uni_fac_scores[row[2]] and auth in name_idx:\n",
    "        uni_fac_scores[row[2]][auth] = clf2.coef_[name_idx[auth]]\n",
    "        uni_ts_scores[row[2]][auth] = ri_scores[name_idx[auth]]\n",
    "        uni_rs_scores[row[2]][auth] = rec_scores[name_idx[auth]]\n",
    "        uni_tsall_scores[row[2]][auth] = rec_all_scores[name_idx[auth]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_fac_scores[\"Carnegie Mellon University\"].values()\n",
    "from scipy.stats import trim_mean, trimboth\n",
    "\n",
    "uni_pm = {k: trimboth(list(v.values()), 0.0).sum() for k, v in uni_fac_scores.items()}\n",
    "uni_ts = {k: trimboth(list(v.values()), 0.0).sum() for k, v in uni_ts_scores.items()}\n",
    "uni_rs = {k: trimboth(list(v.values()), 0.0).sum() for k, v in uni_rs_scores.items()}\n",
    "uni_tsall = {\n",
    "    k: trimboth(list(v.values()), 0.0).sum() for k, v in uni_tsall_scores.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_pm_scores = sorted([(v, k) for k, v in uni_pm.items()], reverse=True)\n",
    "uni_v_scores = sorted([(v, k) for k, v in uni_ts.items()], reverse=True)\n",
    "uni_r_scores = sorted([(v, k) for k, v in uni_rs.items()], reverse=True)\n",
    "uni_vall_scores = sorted([(v, k) for k, v in uni_tsall.items()], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_pm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_vall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_v_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_r_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_vall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analytics (authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg(M, alpha=0.85, tol=1e-6, max_iter=1, verbose=False):\n",
    "    N = M.shape[0]\n",
    "    nodelist = np.arange(N)\n",
    "    S = scipy.array(M.sum(axis=1)).flatten()\n",
    "    S[S != 0] = 1.0 / S[S != 0]\n",
    "    Q = scipy.sparse.spdiags(S.T, 0, *M.shape, format=\"csr\")\n",
    "    M = Q * M\n",
    "\n",
    "    # initial vector\n",
    "    x = scipy.repeat(1.0 / N, N)\n",
    "\n",
    "    # Personalization vector\n",
    "    p = scipy.repeat(1.0 / N, N)\n",
    "\n",
    "    # Dangling nodes\n",
    "    dangling_weights = p\n",
    "    is_dangling = scipy.where(S == 0)[0]\n",
    "\n",
    "    # power iteration: make up to max_iter iterations\n",
    "    for _ in range(max_iter):\n",
    "        xlast = x\n",
    "        x = alpha * (x * M + sum(x[is_dangling]) * dangling_weights) + (1 - alpha) * p\n",
    "        # check convergence, l1 norm\n",
    "        err = scipy.absolute(x - xlast).sum()\n",
    "        if verbose:\n",
    "            print(_, err)\n",
    "        if err < N * tol:\n",
    "            return x\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "gauth_auth = scipy.sparse.dok_matrix((len(unique_names), len(unique_names)))\n",
    "g_auth = {}\n",
    "for row in papers.itertuples():\n",
    "    paper_year = row[10]\n",
    "    conf = row[2]\n",
    "    n = row[4]\n",
    "    authors = row[3]\n",
    "    if clf[span_years * conf_idx[conf] : span_years * (conf_idx[conf] + 1)].max() > 0:\n",
    "        for a, a2 in itertools.product(authors, authors):\n",
    "            auth = aliasdict.get(a, a)\n",
    "            auth2 = aliasdict.get(a2, a2)\n",
    "            if auth in name_idx and auth2 in name_idx:\n",
    "                g_auth[(name_idx[auth], name_idx[auth2])] = 1 + g_auth.get(\n",
    "                    (name_idx[auth], name_idx[auth2]), 0\n",
    "                )\n",
    "gauth_auth._update(g_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import igraph as ig\n",
    "\n",
    "    sources, targets = gauth_auth.nonzero()\n",
    "    weights = gauth_auth[sources, targets]\n",
    "    weights = np.array(\n",
    "        weights\n",
    "    )  # Need to convert Scipy's matrix format into a form appropriate for igraph\n",
    "    # g = ig.Graph(zip(sources, targets), directed=True, edge_attrs={'weight': weights})\n",
    "    weights.shape\n",
    "    pr2 = ig.pagerank(g, niter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauth_auth = scipy.sparse.csr_matrix(gauth_auth)\n",
    "pr = pg(gauth_auth, max_iter=100, verbose=True, tol=1e-12)\n",
    "print(gauth_auth.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_s = np.argsort(pr)[::-1]\n",
    "top_k = 100\n",
    "i = 0\n",
    "j = 0\n",
    "rs = ri_scores.std()\n",
    "while i < top_k:\n",
    "    j += 1\n",
    "    idx = pr_s[j]\n",
    "    if ri_scores[idx] / rs < 20.0:\n",
    "        continue\n",
    "    print(unique_names[idx], pr[idx], ri_scores[idx] / rs)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(pr,open('pagerank_people.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis (confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_confs = defaultdict(set)\n",
    "for row in papers.itertuples():\n",
    "    paper_year = row[10]\n",
    "    conf = row[2]\n",
    "    n = row[4]\n",
    "    authors = row[3]\n",
    "    # if clf[conf_idx[conf]] > 0:\n",
    "    for a in authors:\n",
    "        auth = aliasdict.get(a, a)\n",
    "        auth_confs[auth].add(conf_idx[conf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_confs = {k: list(v) for k, v in auth_confs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "auth_confs_iter = {\n",
    "    k: itertools.combinations_with_replacement(v, 2) for k, v in auth_confs.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "dconf = dict()\n",
    "\n",
    "gconf_conf = scipy.sparse.dok_matrix((len(conf_idx), len(conf_idx)))\n",
    "dconf = {}\n",
    "for k, v in auth_confs_iter.items():\n",
    "    for i, j in v:\n",
    "        tmp = 1 + dconf.get((i, j), 0)\n",
    "        dconf[(i, j)] = tmp\n",
    "        if i != j:\n",
    "            dconf[(j, i)] = tmp\n",
    "\n",
    "gconf_conf._update(dconf)\n",
    "# n = len(v)\n",
    "# for i in range(n):\n",
    "#    new_row = scipy.sparse.dok_matrix((1,len(conf_idx)))\n",
    "#    for j in range(i,n):\n",
    "#        new_row[0,v[j]] = 1\n",
    "#    new_row = scipy.sparse.csr_matrix(new_row)\n",
    "#    gconf_conf[v[i]] += new_row\n",
    "#        i1 = v[i]\n",
    "#        i2 = v[j]\n",
    "#        gconf_conf[i1,i2] += 1\n",
    "# gconf_conf[i2,i1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gconf_conf.setdiag(gconf_conf.diagonal()/2)\n",
    "# gconf_conf =  gconf_conf + gconf_conf.T - scipy.sparse.diags(gconf_conf.diagonal(),format='dok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .diagonal() and .setdiag()\n",
    "gconf_conf = scipy.sparse.csr_matrix(gconf_conf)\n",
    "prc = pg(gconf_conf, max_iter=100, verbose=True, tol=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_s = np.argsort(prc)[::-1]\n",
    "top_k = 100\n",
    "i = 0\n",
    "while i < top_k:\n",
    "    idx = prc_s[i]\n",
    "    print(unique_confs[idx], prc[idx])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(prc,open('pagerank_conf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.hist(np.log(prc), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcs = np.log(prc)\n",
    "prcs = (prcs - prcs.mean()) / prcs.std()\n",
    "scores = []\n",
    "for conf in conf_choice:  # + ['STOC','FOCS','SODA']:\n",
    "    idx = conf_idx[conf]\n",
    "    scores.append((prcs[idx], conf))\n",
    "for s, n in sorted(scores, reverse=True):\n",
    "    print(\"{:30}\\t{:.1f}\".format(n[:25], s))\n",
    "_ = plt.hist(prcs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
