{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('papers.h5','table')\n",
    "unique_names = pickle.load(open('big_names.pkl','rb'))\n",
    "uniqie_confs = pickle.load(open('confs.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#big_names = np.unique(np.concatenate(df.name))\n",
    "unique_names = pickle.load(open('big_names.pkl','rb'))\n",
    "unique_confs = pickle.load(open('confs.pkl','rb'))\n",
    "faculty_affil = pd.read_csv('faculty-affiliations.csv')\n",
    "ranks = pd.read_csv('ranks.csv')\n",
    "def csv2dict_str_str(fname):\n",
    "    with open(fname, mode='r') as infile:\n",
    "        rdr = csv.reader(infile)\n",
    "        d = {rows[0].strip(): rows[1].strip() for rows in rdr}\n",
    "    return d\n",
    "aliasdict = csv2dict_str_str('dblp-aliases.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, unique_names.shape, unique_confs.shape,faculty_affil.shape, ranks.shape\n",
    "#unique_names = [str(_) for _ in unique_names]\n",
    "#np.savetxt('names.txt',unique_names,encoding='utf-8',fmt='%s')\n",
    "\n",
    "conf_idx = {}\n",
    "name_idx = {}\n",
    "for i in range(unique_names.shape[0]):\n",
    "    authorName = unique_names[i]\n",
    "    realName = aliasdict.get(authorName, authorName)\n",
    "    name_idx[realName] = i\n",
    "    name_idx[authorName] = i\n",
    "for i in range(unique_confs.shape[0]):\n",
    "    confName = unique_confs[i]\n",
    "    conf_idx[confName] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for name in faculty_affil.affiliation.unique():\n",
    "        if name in list(ranks.uni):\n",
    "            print(',',end='')\n",
    "        else: #print(name)\n",
    "            print(name)\n",
    "            print('.',end='')\n",
    "    for name in faculty_affil.name:\n",
    "        if name in unique_names:\n",
    "            print(',',end='')\n",
    "        else: \n",
    "            print(name)\n",
    "            print('.',end='')\n",
    "ranks[ranks.index < 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = df.year.min()\n",
    "max_year = df.year.max()\n",
    "span_years = max_year - min_year\n",
    "year_blocks = 8\n",
    "offset_years = [(i-min_year)//year_blocks for i in range(min_year,max_year+1)]\n",
    "year_ind = max(offset_years)+1\n",
    "conf_idx = pickle.load(open('conf_idx.pkl','rb'))\n",
    "name_idx = pickle.load(open('name_idx.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "X = scipy.sparse.dok_matrix((len(unique_names),year_ind*unique_confs.shape[0]))\n",
    "xdict = {}\n",
    "\n",
    "auth_years = np.ones((len(unique_names),2)) * np.array([3000,1000]) \n",
    "#y = np.zeros(len(unique_names))#scipy.sparse.dok_matrix((1,len(unique_names)))\n",
    "for row in df.itertuples():\n",
    "    paper_year = row[10]\n",
    "    #if row['year'] < 2005:\n",
    "    #    continue\n",
    "    #print(row)\n",
    "    #if row['conf'] == 'CoRR':\n",
    "    #    continue\n",
    "    conf = row[2]\n",
    "    n = row[4]\n",
    "    authors = row[3]\n",
    "    j = year_ind*conf_idx[conf] + (paper_year-min_year)//year_blocks\n",
    "    for a in authors:\n",
    "        i = name_idx[a]\n",
    "        if conf != 'CoRR':\n",
    "            xdict[(i,j)] = 1/n + xdict.get((i,j),0)\n",
    "        auth_years[i,0] = min(auth_years[i,0],paper_year)\n",
    "        auth_years[i,1] = max(auth_years[i,1],paper_year)\n",
    "X._update(xdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(X,open('x.pkl','wb'))\n",
    "#pickle.dump(conf_idx,open('conf_idx.pkl','wb'))\n",
    "#pickle.dump(name_idx,open('name_idx.pkl','wb'))\n",
    "#X_dup = np.copy(X)\n",
    "#for i in range(5):\n",
    "#    j = year_ind*conf_idx['CoRR'] + (i-min_year)//year_blocks\n",
    "#    X[:,j] = 0\n",
    "\n",
    "\n",
    "settings = [-6,'hinge',15,0]\n",
    "settings = [-6, 'hinge', 20, 0.15]\n",
    "#settings = [-8.548444243014805, 'hinge', 25, 0.8315610452033819]\n",
    "#settings = [-8.053796519336224, 'log', 15, 0.04885118622350815]\n",
    "#settings = [-8.305486025332591, 'hinge', 70, 0.8854278179436874]\n",
    "#settings = [-8.475194214243022, 'modified_huber', 11, 0.01707933834322717,0.1]\n",
    "#settings = [-8.403912963838302, 'modified_huber', 10, 0.7195030417696724,0.1] #15, .8,4\n",
    "#settings = [-8.57, 'modified_huber',22, 0.78, 0.07]\n",
    "#settings =  [-7.687656839233525, 'modified_huber', 106, 0.8035188318995535,0.1] # 27, .7. 1\n",
    "#settings = [-8.438322018202042, 'modified_huber', 34, 0.746304732399994,0.1] # 23 .77 2\n",
    "settings = [-4.228109135925832, 'modified_huber', 31, 0.919015912687292, 0.7758551488895429] # good ranking, bad acc\n",
    "#settings = [-8.778235592882929, 'modified_huber', 11, 0.5720682745534834, 0.8463472302623746] # good acc, bad ranking\n",
    "settings = [-4.502004811792925, 'modified_huber', 9, 0.9680926337835235, 0.6488148993147007] # maybe balance\n",
    "settings = [-5.323680251147268,'modified_huber',9,0.9873050198822073,0.4352589129929476] # 1 error and 85 acc, it says\n",
    "settings = [-4.228109135925832,'modified_huber',31,\t0.919015912687292,0.7758551488895429] # no errors but little acc\n",
    "#settings =[-6.013005893126464,\t'modified_huber',\t30,\t0.9485296659531548,\t0.683735528500138] # errors but acc\n",
    "#settings = [-5.3,'modified_huber',31,0.98,0.6] # my own model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(len(unique_names))\n",
    "for i in range(settings[2]): #40?\n",
    "    uni_name = ranks.iloc[i]['uni']\n",
    "    uni_faculty = faculty_affil[faculty_affil.affiliation == uni_name]\n",
    "    uni_names = np.array(uni_faculty.name)\n",
    "    for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "        if name in name_idx:\n",
    "            y[name_idx[name]] = 1\n",
    "        else:\n",
    "            pass\n",
    "            #print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape,y.reshape((-1,))\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X = scipy.sparse.csr_matrix(X)\n",
    "print(X.shape,y.shape)\n",
    "clf = SGDClassifier(settings[1],average=False,verbose=1,warm_start=True,tol=1e-5,max_iter=1,alpha=10 ** settings[0],penalty='elasticnet',l1_ratio=settings[3],epsilon=settings[4])\n",
    "clf.fit(X,y)\n",
    "for i in range(25):\n",
    "    minv = clf.coef_[clf.coef_ > 0].min()\n",
    "    maxv = clf.coef_[clf.coef_ > 0].max()\n",
    "    #clf.coef_ = np.maximum(minv,clf.coef_)\n",
    "    clf = clf.partial_fit(X,y)\n",
    "    print(minv,maxv)\n",
    "#minv = clf.coef_[clf.coef_ > 0].min()\n",
    "#clf.coef_ = np.maximum(minv,clf.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scipy.sparse.csr_matrix(X)\n",
    "\n",
    "import csv\n",
    "with open('pairwise_tiers.csv','rt') as csvfile:\n",
    "    filereader = csv.reader(csvfile)\n",
    "    conf_pairs = [[t.strip('\\ufeff') for t in _ if len(t)!=0] for _ in filereader]\n",
    "if False:\n",
    "    best_cost = 1000\n",
    "    best_params = []\n",
    "    for itr in range(1000):\n",
    "        alpha = np.random.uniform(-6.5,-3)\n",
    "        hinge_log = 'hinge' if np.random.rand() < 0.5 else 'modified_huber'\n",
    "        uni_rank = int(round(np.exp(np.random.uniform(np.log(5),np.log(50)))))\n",
    "        l1r = np.random.uniform(0.2,1)\n",
    "        eps = np.random.uniform(0.1,1)\n",
    "        \n",
    "        y = np.zeros(len(unique_names))\n",
    "        for i in range(uni_rank): #40?\n",
    "            uni_name = ranks.iloc[i]['uni']\n",
    "            uni_faculty = faculty_affil[faculty_affil.affiliation == uni_name]\n",
    "            uni_names = np.array(uni_faculty.name)\n",
    "            for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "                if name in name_idx:\n",
    "                    y[name_idx[name]] = 1\n",
    "                else:\n",
    "                    pass\n",
    "                    #print(name)\n",
    "        #X.shape,y.reshape((-1,))\n",
    "        \n",
    "        from sklearn.linear_model import SGDClassifier\n",
    "        clf = SGDClassifier(hinge_log,average=True,verbose=0,tol=1e-5,max_iter=1,alpha= 10 ** alpha,penalty='elasticnet',l1_ratio=l1r,epsilon=eps)\n",
    "        clf.fit(X,y)\n",
    "        for i in range(25):\n",
    "            clf.coef_ = np.maximum(0,clf.coef_)\n",
    "            clf = clf.partial_fit(X,y)\n",
    "        clf.coef_ = np.maximum(0,clf.coef_)\n",
    "\n",
    "        classifier_cost = 0\n",
    "        conf_ord = np.argsort(np.squeeze(clf.coef_))\n",
    "        conf_rank_dict = {}\n",
    "        conf_elem = len(unique_confs)*year_ind\n",
    "        for i in range(len(unique_confs)*year_ind):\n",
    "            idx = conf_ord[-(i+1)]\n",
    "            conf_name = unique_confs[idx//year_ind]\n",
    "            conf_score = clf.coef_[0,idx]\n",
    "            if idx%year_ind < 3:\n",
    "                continue\n",
    "            if conf_score == 0:\n",
    "                conf_rank_dict[conf_name] = num_elem\n",
    "            else:\n",
    "                conf_rank_dict[conf_name] = i\n",
    "        pair_len = len(conf_pairs)//2\n",
    "        neg_top = 0\n",
    "        for i in range(pair_len):\n",
    "            better = conf_pairs[2*i]\n",
    "            worse = conf_pairs[2*i+1]\n",
    "            #print(better,worse)\n",
    "            for b in better:\n",
    "                neg_top += clf.coef_[0,conf_idx[b]*year_ind+4] < 0\n",
    "                for w in worse:\n",
    "                    classifier_cost += conf_rank_dict[w] < conf_rank_dict[b]\n",
    "                    #if  conf_rank_dict[w] < conf_rank_dict[b]:\n",
    "                    #    print(w,conf_rank_dict[w],'\\t',b,conf_rank_dict[b])\n",
    "        all_choices = clf.decision_function(X)\n",
    "        frac_correct = (all_choices[y.astype(np.bool)] > 0).sum()\n",
    "        print(classifier_cost,[alpha,hinge_log,uni_rank,l1r,eps],frac_correct/y.sum(),neg_top,clf.coef_[0,5570])\n",
    "        if classifier_cost < best_cost:\n",
    "            best_cost = classifier_cost\n",
    "            best_params = [alpha,hinge_log,uni_rank,l1r,eps]\n",
    "            #print(best_cost,best_params)\n",
    "            #8 [-3.5003506670165976, 'log', 21]\n",
    "            #10 [-3.0421236321136265, 'log', 47]\n",
    "            #11 [-3.954162400006843, 'log', 109]\n",
    "else:\n",
    "    classifier_cost = 0\n",
    "    conf_ord = np.argsort(np.squeeze(clf.coef_))\n",
    "    conf_rank_dict = {}\n",
    "    num_elem = len(unique_confs)*year_ind\n",
    "    for i in range(num_elem):\n",
    "        idx = conf_ord[-(i+1)]\n",
    "        conf_name = unique_confs[idx//year_ind]\n",
    "        conf_score = clf.coef_[0,idx]\n",
    "        if idx%year_ind < 3:\n",
    "            continue\n",
    "        if conf_score == 0:\n",
    "            conf_rank_dict[conf_name] = num_elem\n",
    "        else:\n",
    "            conf_rank_dict[conf_name] = i\n",
    "    pair_len = len(conf_pairs)//2\n",
    "    for i in range(pair_len):\n",
    "        better = conf_pairs[2*i]\n",
    "        worse = conf_pairs[2*i+1]\n",
    "        #print(better,worse)\n",
    "        for b in better:\n",
    "            for w in worse:\n",
    "                classifier_cost += (conf_rank_dict[w] < conf_rank_dict[b])\n",
    "                if conf_rank_dict[w] < conf_rank_dict[b]:\n",
    "                    print(w,conf_rank_dict[w],'\\t',b,conf_rank_dict[b])\n",
    "\n",
    "    all_choices = clf.decision_function(X)\n",
    "    frac_correct = (all_choices[y.astype(np.bool)] > 0).sum()\n",
    "    print(classifier_cost,settings,frac_correct/y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_choices > 0).sum(),y.sum(),(all_choices[y.astype(np.bool)] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_choice = ['SIGGRAPH','NIPS','3DV','HRI','ECCV (8)','ECCV (1)','Comput. Graph. Forum','Shape Modeling International','Symposium on Geometry Processing',' Computer Aided Geometric Design','ICLR','NIPS','AAAI','I. J. Robotics Res.','CVPR','International Journal of Computer Vision','Robotics: Science and Systems','ICRA','WACV','ICML','AISTATS','CoRR','SIGGRAPH Asia','ECCV','ICCV','ISER','Humanoids','3DV','IROS','CoRL','Canadian Conference on AI','ACCV ','Graphics Interface','CRV','BMVC']\n",
    "ri_confs = np.zeros(len(unique_confs)*year_ind)\n",
    "print(clf.intercept_)\n",
    "ms = clf.coef_.mean()\n",
    "ss = clf.coef_.std()\n",
    "for i in range(len(unique_confs)*year_ind):\n",
    "    idx = conf_ord[-(i+1)]\n",
    "    conf_name = unique_confs[idx//year_ind]\n",
    "    conf_score = clf.coef_[0,idx]\n",
    "    if conf_name in conf_choice:\n",
    "        ri_confs[idx] = 1\n",
    "    if conf_name in conf_choice and (idx%year_ind)==5:\n",
    "    #if 'ICCV' in conf_name and (idx%year_ind)==4:\n",
    "        start_year = offset_years.index(idx%year_ind) + 1970\n",
    "        end_year = len(offset_years) - 1 - offset_years[::-1].index(idx%year_ind) + 1970\n",
    "        print_name =conf_name + '_' + str(start_year)[-2:] +'t' + str(end_year)[-2:]\n",
    "        print('{:20s}\\t{:.0f}\\t{:.1f}'.format(print_name[:20],100*conf_score,(conf_score-ms)/ss))\n",
    "    ri_confs.shape,ri_confs.sum(),X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clf.decision_function(X)\n",
    "years_working = (1+auth_years[:,1]-auth_years[:,0])\n",
    "value_scores = scores -  clf.intercept_[0]\n",
    "norm_scores = (value_scores)/years_working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_filter_mat = scipy.sparse.diags(ri_confs)\n",
    "ri_scores = clf.decision_function(X.dot(ri_filter_mat))-clf.intercept_[0]\n",
    "ri_norm_scores = ri_scores/years_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_cand = ['Pulkit Agrawal',\n",
    " 'Joydeep Biswas',\n",
    " 'Katherine L. Bouman',\n",
    " 'David Braun',\n",
    " 'Jia Deng',\n",
    " 'Naomi T. Fitter',\n",
    " 'David F. Fouhey',\n",
    " 'Saurabh Gupta',\n",
    " 'Judy Hoffman',\n",
    " 'Hanbyul Joo',\n",
    " 'Honglak Lee',\n",
    " 'Changliu Liu',\n",
    " 'Petter Nilsson',\n",
    " \"Matthew O'Toole\",\n",
    " 'Alessandro Roncone',\n",
    " 'Alanson P. Sample',\n",
    " 'Manolis Savva',\n",
    " 'Adriana Schulz',\n",
    " 'Amy Tabb',\n",
    " 'Fatma Zeynep Temel',\n",
    " 'Long Wang',\n",
    " 'Cathy Wu',\n",
    " 'Ling-Qi Yan']\n",
    "print('{:20s}\\t{:4s}\\t{:4s}\\t{:4s}\\t{}'.format('name','rate','total','ri','years'))\n",
    "for ns, name in sorted([(value_scores[name_idx[ni]],ni) for ni in prev_cand],reverse=True):\n",
    "    ni = name_idx[name]\n",
    "    print('{:20s}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.0f}'.format(name,norm_scores[ni],value_scores[ni],ri_scores[ni],years_working[ni]))\n",
    "print('')\n",
    "curious_names = ['Xiaolong Wang 0004','Kumar Shaurya Shankar',\n",
    "                 'Nicholas Rhinehart',\n",
    "                 'Humphrey Hu',\n",
    "                 'David F. Fouhey',\n",
    "                 'Lerrel Pinto',\n",
    "                 'Justin Johnson',\n",
    "                 'Amir Roshan Zamir',\n",
    "                 'Brian Okorn']\n",
    "print('{:20s}\\t{:4s}\\t{:4s}\\t{:4s}\\t{}'.format('name','rate','total','ri','years'))\n",
    "for name in curious_names:\n",
    "    ni = name_idx[name]\n",
    "    print('{:20s}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.0f}'.format(name,norm_scores[ni],value_scores[ni],ri_scores[ni],years_working[ni]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    uni_faculty = faculty_affil[faculty_affil.affiliation == 'Carnegie Mellon University'] #Carnegie Mellon University\n",
    "    uni_names = np.array(uni_faculty.name)\n",
    "    uni_names = list(uni_names) + ['Jacob Walker','Lerrel Pinto','Brian Okorn','Leonid Keselman','Siddharth Ancha']\n",
    "    cmu_scores = []\n",
    "    for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "        if name in name_idx:\n",
    "            #if ri_scores[name_idx[name]] < 2.5:\n",
    "            #    continue\n",
    "            score = scores[name_idx[name]]\n",
    "            cmu_scores.append((score,name))\n",
    "        else:\n",
    "            pass\n",
    "            #print(name)\n",
    "    for s,p in sorted(cmu_scores,reverse=True):\n",
    "        print('{:20s}\\t{:.1f}'.format(p,s))\n",
    "    print('\\nvalue based!\\n')\n",
    "    cmu_scores = []\n",
    "    for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "        if name in name_idx:\n",
    "            #print(name,auth_years[name_idx[name]])\n",
    "            score = (scores[name_idx[name]]-clf.intercept_)[0]/(1+auth_years[name_idx[name],1]-auth_years[name_idx[name],0])\n",
    "            #if ri_scores[name_idx[name]] < 2.5:\n",
    "            #    continue \n",
    "            cmu_scores.append((score, value_scores[name_idx[name]] ,name))\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "            #print(name)\n",
    "    for s,rs,p in sorted(cmu_scores,reverse=True):\n",
    "        print('{:20s}\\t{:.1f}\\t{:.1f}'.format(p,rs,s))\n",
    "\n",
    "if True:\n",
    "    print('\\n best overall \\n')\n",
    "    cmu_scores = []\n",
    "\n",
    "    best_scores = np.argsort(value_scores)[::-1]\n",
    "    #print(best_scores.shape,unique_names[best_scores[0]])\n",
    "    fa_list = list(faculty_affil.name)\n",
    "    fa_a_list = list(faculty_affil.affiliation)\n",
    "    uni_names = [unique_names[i] for i in best_scores[:20000]]\n",
    "    for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "        if name in name_idx:\n",
    "            uni = 'unknown'\n",
    "            if name in fa_list:\n",
    "                uni = fa_a_list[fa_list.index(name)]\n",
    "            if name not in ['Jacob Walker','Justin Johnson','Pieter Abbeel','Martial Hebert','Jessica K. Hodgins','Abhinav Gupta','Christopher G. Atkeson','Tom M. Mitchell','Matthew T. Mason']:\n",
    "                if years_working[name_idx[name]] < 3:\n",
    "                    continue\n",
    "                if years_working[name_idx[name]] > 8:\n",
    "                    continue\n",
    "                #if ri_scores[name_idx[name]] < 5:\n",
    "                #    continue\n",
    "                if auth_years[name_idx[name],1] < 2016:\n",
    "                    continue\n",
    "            #if (np.array(X[name_idx[name],:].todense()) * ri_confs).sum() == 0:\n",
    "            #    continue\n",
    "            #print(name,auth_years[name_idx[name]])\n",
    "            score = norm_scores[name_idx[name]]\n",
    "            ri_vscore = ri_norm_scores[name_idx[name]]\n",
    "            vscore = value_scores[name_idx[name]]\n",
    "            cmu_scores.append((score,ri_scores[name_idx[name]],vscore,uni,name,auth_years[name_idx[name]]))\n",
    "        else:\n",
    "            pass\n",
    "            #print(name)\n",
    "    print('{:22s}\\t{:15s}\\t{:5s}\\t{:3s}\\t{:4s}\\t{} {}'.format('name','uni','rate','RI-t','total','start','end'))\n",
    "    for s,ris,vs,u,p,yrs in sorted(cmu_scores,reverse=True):\n",
    "        print('{:22s}\\t{:15s}\\t{:.3f}\\t{:.1f}\\t{:.2f}\\t{} {}'.format(p[:22],u[:15],s,ris,vs,int(yrs[0]),int(yrs[1])))\n",
    "\n",
    "if False:\n",
    "    gz = gzip.GzipFile('dblp.xml.gz')\n",
    "    names = set()\n",
    "    places = set()\n",
    "    papers = []\n",
    "    def handle_article(_, article):\n",
    "        try:\n",
    "            if 'author' not in article:\n",
    "                return True\n",
    "            if type(article['author']) != list:\n",
    "                authors = [article['author']]\n",
    "            else:\n",
    "                authors = article['author']\n",
    "\n",
    "            if 'booktitle' in article:\n",
    "                venue = article['booktitle']\n",
    "            elif 'journal' in article:\n",
    "                venue = article['journal']\n",
    "            else:\n",
    "                return True\n",
    "            names = names.union(set(authors))\n",
    "            places.add(venue)\n",
    "        except:\n",
    "            print(sys.exc_info()[0])\n",
    "            failures += 1\n",
    "            raise\n",
    "        return True\n",
    "\n",
    "    xmltodict.parse(gz, item_depth=2, item_callback=handle_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls *.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf.coef_,open('clf_faculty_neg_pos_light_reg.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
