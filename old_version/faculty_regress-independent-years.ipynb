{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import zipfile\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_hdf('papers.h5','table')\n",
    "df = pd.read_pickle('papers.pkl.bz2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "main_log = pickle.load(bz2.BZ2File('../CSrankings/main_log.pkl.bz2','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names = pickle.load(open('big_names.pkl','rb'))\n",
    "unique_confs = pickle.load(open('confs.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_names = set(sum([list(_) for _ in df.name],[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_set = {}\n",
    "for names in df.name:\n",
    "    nv = {k: 1 for k in names}\n",
    "    name_set.update(nv)\n",
    "unique_names = list(name_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "    for a in row[3]:\n",
    "        if a == b'Angela Dai':\n",
    "            print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in main_log:\n",
    "    for a in paper['name']:\n",
    "        if a == b'Angela Dai':\n",
    "            print(paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_confs = pickle.load(open('r1_confs.pkl','rb'))\n",
    "r1_confs_dict = {_:1 for _ in r1_confs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the big paper thing\n",
    "papers = pd.read_hdf('papers.h5','table')\n",
    "unique_names = pickle.load(open('big_names.pkl','rb'))\n",
    "unique_confs = pickle.load(open('confs.pkl','rb'))\n",
    "\n",
    "faculty_affil = pd.read_csv('faculty-affiliations.csv')\n",
    "ranks = pd.read_csv('ranks.csv')\n",
    "def csv2dict_str_str(fname):\n",
    "    with open(fname, mode='r') as infile:\n",
    "        rdr = csv.reader(infile)\n",
    "        d = {rows[0].strip(): rows[1].strip() for rows in rdr}\n",
    "    return d\n",
    "aliasdict = csv2dict_str_str('dblp-aliases.csv')\n",
    "conf_idx = pickle.load(open('conf_idx.pkl','rb'))\n",
    "name_idx = pickle.load(open('name_idx.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areadict = {\n",
    "    'icse' : ['ICSE', 'ICSE (1)'],\n",
    "    'fse'  : ['SIGSOFT FSE', 'ESEC/SIGSOFT FSE'],\n",
    "    'usenixatc' : ['USENIX Annual Technical Conference', 'USENIX Annual Technical Conference, General Track'], # next tier\n",
    "    'imc': ['IMC', 'Internet Measurement Conference'],\n",
    "    'sigmetrics': ['SIGMETRICS', 'SIGMETRICS/Performance', 'POMACS'],\n",
    "    'mobicom' : ['MobiCom', 'MOBICOM'],\n",
    "    'rtas' : ['RTAS', 'IEEE Real-Time and Embedded Technology and Applications Symposium'],\n",
    "    'ccs': ['CCS', 'ACM Conference on Computer and Communications Security'],\n",
    "    'oakland' : ['IEEE Symposium on Security and Privacy'],\n",
    "    'usenixsec' : ['USENIX Security Symposium', 'USENIX Security'],\n",
    "    'pets' : ['PoPETs', 'Privacy Enhancing Technologies'],\n",
    "    'cav': ['CAV', 'CAV (1)', 'CAV (2)'],\n",
    "    'lics' : ['LICS', 'CSL-LICS'],\n",
    "    'nips': ['NIPS', 'NeurIPS'],\n",
    "    'icml': ['ICML', 'ICML (1)', 'ICML (2)', 'ICML (3)'],\n",
    "    'aaai': ['AAAI', 'AAAI/IAAI'],\n",
    "    'ubicomp' : ['UbiComp', 'Ubicomp', 'IMWUT', 'Pervasive'],\n",
    "    'emnlp': ['EMNLP', 'EMNLP-CoNLL', 'HLT/EMNLP'],\n",
    "    'acl' : ['ACL', 'ACL (1)', 'ACL (2)', 'ACL/IJCNLP', 'COLING-ACL'],\n",
    "    'naacl' : ['NAACL', 'HLT-NAACL', 'NAACL-HLT'],\n",
    "    'cvpr': ['CVPR', 'CVPR (1)', 'CVPR (2)'],\n",
    "    'eccv': ['ECCV', 'ECCV (1)', 'ECCV (2)', 'ECCV (3)', 'ECCV (4)', 'ECCV (5)', 'ECCV (6)', 'ECCV (7)', 'ECCV (8)', 'ECCV (9)', 'ECCV (10)', 'ECCV (11)', 'ECCV (12)', 'ECCV (13)', 'ECCV (14)', 'ECCV (15)', 'ECCV (16)'],\n",
    "    'icra': ['ICRA', 'ICRA (1)', 'ICRA (2)'],\n",
    "    'rss': ['Robotics: Science and Systems'],\n",
    "    'crypto': ['CRYPTO', 'CRYPTO (1)', 'CRYPTO (2)', 'CRYPTO (3)'],\n",
    "    'eurocrypt': ['EUROCRYPT', 'EUROCRYPT (1)', 'EUROCRYPT (2)', 'EUROCRYPT (3)'],\n",
    "}\n",
    "inverse_area_dict = {}\n",
    "for k,v in areadict.items():\n",
    "    n = len(v)\n",
    "    for i in range(1,n):\n",
    "        inverse_area_dict[v[i]] = v[0]\n",
    "for k,v in inverse_area_dict.items():\n",
    "    if k in conf_idx and v in conf_idx:\n",
    "        conf_idx[k] = conf_idx[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# munge the years\n",
    "min_year = papers.year.min()\n",
    "max_year = papers.year.max()\n",
    "span_years = max_year - min_year +1\n",
    "\n",
    "print(span_years,min_year,max_year,len(name_idx))\n",
    "ranks[ranks.index < 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "sigma = 3\n",
    "weights = []\n",
    "for i in range(span_years):\n",
    "    a = np.array([scipy.stats.norm.pdf( (j-i)/sigma) for j in range(span_years)])\n",
    "    a[a < 0.05] = 0\n",
    "    weights.append(a/np.linalg.norm(a))\n",
    "_ = plt.plot(np.arange(span_years)+min_year,weights[2000-min_year])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "#pairs_of_years = itertools.product(range(span_years),range(span_years))\n",
    "\n",
    "wdict = {}\n",
    "for i,j,k in itertools.product(range(unique_confs.shape[0]),range(span_years),range(span_years)):\n",
    "    wdict[i*span_years+j,i*span_years+k] = weights[j][k]\n",
    "wsa = scipy.sparse.dok_matrix((span_years*unique_confs.shape[0],span_years*unique_confs.shape[0]))\n",
    "wsa._update(wdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "X = scipy.sparse.dok_matrix((len(unique_names),span_years*unique_confs.shape[0]))\n",
    "xdict = {}\n",
    "\n",
    "auth_years = np.ones((len(unique_names),2)) * np.array([3000,1000]) \n",
    "#y = np.zeros(len(unique_names))#scipy.sparse.dok_matrix((1,len(unique_names)))\n",
    "for row in df.itertuples():\n",
    "    paper_year = row[10]\n",
    "\n",
    "    conf = row[2]\n",
    "    n = row[4]\n",
    "    authors = row[3]\n",
    "    j = span_years*conf_idx[conf] + paper_year-min_year\n",
    "    for a in authors:\n",
    "        i = name_idx[a]\n",
    "        xdict[(i,j)] = 1/n + xdict.get((i,j),0)\n",
    "        auth_years[i,0] = min(auth_years[i,0],paper_year)\n",
    "        auth_years[i,1] = max(auth_years[i,1],paper_year)\n",
    "X._update(xdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scipy.sparse.csr_matrix(X)\n",
    "wsa = scipy.sparse.csr_matrix(wsa)\n",
    "X = X @ wsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings = [-4.228109135925832,'modified_huber',31,\t0.919015912687292,0.7758551488895429] # no errors but little acc\n",
    "settings =[-6.013005893126464,\t'modified_huber',\t30,\t0.9485296659531548,\t0.683735528500138] # errors but acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(len(unique_names))\n",
    "for i in range(5): #40?\n",
    "    uni_name = ranks.iloc[i]['uni']\n",
    "    uni_faculty = faculty_affil[faculty_affil.affiliation == uni_name]\n",
    "    uni_names = np.array(uni_faculty.name)\n",
    "    for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "        if name in name_idx:\n",
    "            y[name_idx[name]] = 1\n",
    "        else:\n",
    "            pass\n",
    "            #print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonarxiv = np.ones(span_years*len(unique_confs))\n",
    "nonarxiv[span_years*conf_idx['CoRR']:span_years*(conf_idx['CoRR']+1)] = 0\n",
    "r1_confs = np.ones(span_years*len(unique_confs))\n",
    "\n",
    "for k,v in r1_confs_dict.items():\n",
    "    pass\n",
    "    #r1_confs[span_years*conf_idx[k]:span_years*(conf_idx[k]+1)] = 1\n",
    "\n",
    "skipped_conf = scipy.sparse.diags(nonarxiv * r1_confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X = scipy.sparse.csr_matrix(X)\n",
    "clf = SGDClassifier(settings[1],average=False,verbose=1,warm_start=True,tol=1e-5,max_iter=1,alpha=1e-3)\n",
    "tmp = X@ skipped_conf\n",
    "clf.fit(tmp,y)\n",
    "for i in range(35):\n",
    "    minv = clf.coef_[clf.coef_ > 0].min()\n",
    "    maxv = clf.coef_[clf.coef_ > 0].max()\n",
    "    #clf.coef_ = np.maximum(minv,clf.coef_)\n",
    "    clf = clf.partial_fit(tmp,y)\n",
    "    print(minv,maxv)\n",
    "minv = clf.coef_[clf.coef_ > 0].min()\n",
    "#clf.coef_ = np.maximum(minv,clf.coef_)\n",
    "tmp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_results = np.squeeze(clf.coef_)\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "conf_ord = np.argsort(conf_results)\n",
    "conf_choice = ['SIGGRAPH','HRI','ECCV','Comput. Graph. Forum','Shape Modeling International','Symposium on Geometry Processing','Computer Aided Geometric Design','I. J. Robotics Res.','CVPR','International Journal of Computer Vision','Robotics: Science and Systems','ICRA','WACV','ICML','AISTATS','CoRR','SIGGRAPH Asia','ECCV','ICCV','ISER','Humanoids','3DV','IROS','CoRL','Canadian Conference on AI','ACCV','Graphics Interface','CRV','BMVC']\n",
    "ri_confs = np.zeros(len(unique_confs)*span_years)\n",
    "print(clf.intercept_)\n",
    "ms = conf_results.mean()\n",
    "ss = conf_results.std()\n",
    "seen = {}\n",
    "for i in range(len(unique_confs)*span_years):\n",
    "    idx = conf_ord[-(i+1)]\n",
    "    conf_name = unique_confs[idx//span_years]\n",
    "    conf_score = conf_results[idx]\n",
    "    if conf_name in conf_choice:\n",
    "        ri_confs[idx] = 1\n",
    "    if conf_name in conf_choice and conf_name not in seen:\n",
    "        print('{:20s}{}\\t{:.1f}'.format(conf_name[:20],str(min_year + (idx % span_years)),(conf_score-ms)/ss))\n",
    "        seen[conf_name] =1\n",
    "ri_confs.shape,ri_confs.sum(),X.shape\n",
    "\n",
    "conf_choice2 = ['SIGGRAPH','AAAI','NIPS','CVPR','ICRA','ICML','ICCV',\n",
    "               'International Journal of Computer Vision','Robotics: Science and Systems']\n",
    "conf_choice3 = []\n",
    "vs = conf_results.std()\n",
    "for conf in conf_choice2:\n",
    "    idx = conf_idx[conf]\n",
    "    s = max(conf_results[span_years*idx:span_years*(idx+1)])\n",
    "    conf_choice3.append((s,conf))\n",
    "plt.figure(figsize=(12,8))\n",
    "for s,conf in sorted(conf_choice3,reverse=True):\n",
    "    idx = conf_idx[conf]\n",
    "    _ = plt.plot(np.arange(min_year,max_year+1)[:-4],gaussian_filter1d(conf_results[span_years*idx:span_years*(idx+1)]/vs,sigma=1)[:-4],label=conf)\n",
    "plt.grid()\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('value')\n",
    "plt.legend()\n",
    "plt.savefig('faculty-fixed.pdf')\n",
    "plt.figure()\n",
    "conf_choice2 = ['CVPR','ECCV','BMVC','CRV','ICCV']\n",
    "conf_choice3 = []\n",
    "vs = conf_results.std()\n",
    "for conf in conf_choice2:\n",
    "    idx = conf_idx[conf]\n",
    "    s = max(conf_results[span_years*idx:span_years*(idx+1)])\n",
    "    conf_choice3.append((s,conf))\n",
    "plt.figure(figsize=(12,8))\n",
    "for s,conf in sorted(conf_choice3,reverse=True):\n",
    "    idx = conf_idx[conf]\n",
    "    _ = plt.plot(np.arange(min_year,max_year+1)[:-4],gaussian_filter1d(conf_results[span_years*idx:span_years*(idx+1)]/vs,sigma=1)[:-4],label=conf)\n",
    "plt.grid()\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('value')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "conf_choice2 = ['AAAI','IJCAI','UAI','AAMAS']\n",
    "conf_choice3 = []\n",
    "vs = conf_results.std()\n",
    "for conf in conf_choice2:\n",
    "    idx = conf_idx[conf]\n",
    "    s = max(conf_results[span_years*idx:span_years*(idx+1)])\n",
    "    conf_choice3.append((s,conf))\n",
    "plt.figure(figsize=(12,8))\n",
    "for s,conf in sorted(conf_choice3,reverse=True):\n",
    "    idx = conf_idx[conf]\n",
    "    _ = plt.plot(np.arange(min_year,max_year+1)[:-4],gaussian_filter1d(conf_results[span_years*idx:span_years*(idx+1)]/vs,sigma=1)[:-4],label=conf)\n",
    "plt.grid()\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('value')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 50\n",
    "i = -1\n",
    "j = 0\n",
    "seen = {}\n",
    "while j < top_k:\n",
    "    i += 1\n",
    "    idx = conf_ord[-(i+1)]\n",
    "    conf_name = unique_confs[idx//span_years]\n",
    "    if conf_name in seen:\n",
    "        continue\n",
    "    j+=1\n",
    "    conf_score = conf_results[idx]\n",
    "    seen[conf_name] = 1\n",
    "    print('{:20s}\\t{}\\t\\t{:.3f}\\t{:.2f}'.format(conf_name[:18],min_year + (idx % span_years),100*conf_score,(conf_score-ms)/ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = hist(clf.coef_,70)\n",
    "pickle.dump(conf_results,open('faculty_indep-fixed_16.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Xauth is None or (Xauth.shape[1] != span_years*unique_confs.shape[0]):  \n",
    "    Xauth = scipy.sparse.dok_matrix((len(unique_names),span_years*unique_confs.shape[0]))\n",
    "    xdict = {}\n",
    "    auth_years = np.ones((len(unique_names),2)) * np.array([3000,1000]) \n",
    "    for row in papers.itertuples():\n",
    "        paper_year = row[10]\n",
    "        #if row['year'] < 2005:\n",
    "        #    continue\n",
    "        #print(row)\n",
    "        #if row['conf'] == 'CoRR':\n",
    "        #    continue\n",
    "        conf = row[2]\n",
    "        n = row[4]\n",
    "        authors = row[3]\n",
    "        j = span_years*conf_idx[conf] + (paper_year-min_year)\n",
    "        for a in authors:\n",
    "            i = name_idx[a]\n",
    "            xdict[(i,j)] = 1/n + xdict.get((i,j),0)\n",
    "            auth_years[i,0] = min(auth_years[i,0],paper_year)\n",
    "            auth_years[i,1] = max(auth_years[i,1],paper_year)\n",
    "    Xauth._update(xdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clf.predict(Xauth) - np.squeeze(clf.intercept_)\n",
    "years_working = (1+auth_years[:,1]-auth_years[:,0])\n",
    "value_scores = scores\n",
    "norm_scores = (value_scores)/years_working\n",
    "ri_filter_mat = scipy.sparse.diags(ri_confs)\n",
    "ri_scores = clf.predict(Xauth.dot(ri_filter_mat))-np.squeeze(clf.intercept_)\n",
    "ri_norm_scores = ri_scores/years_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_cand = ['Pulkit Agrawal',\n",
    " 'Joydeep Biswas',\n",
    " 'Katherine L. Bouman',\n",
    " 'David Braun',\n",
    " 'Jia Deng',\n",
    " 'Naomi T. Fitter',\n",
    " 'David F. Fouhey',\n",
    " 'Saurabh Gupta',\n",
    " 'Judy Hoffman',\n",
    " 'Hanbyul Joo',\n",
    " 'Honglak Lee',\n",
    " 'Changliu Liu',\n",
    " 'Petter Nilsson',\n",
    " \"Matthew O'Toole\",\n",
    " 'Alessandro Roncone',\n",
    " 'Alanson P. Sample',\n",
    " 'Manolis Savva',\n",
    " 'Adriana Schulz',\n",
    " 'Amy Tabb',\n",
    " 'Fatma Zeynep Temel',\n",
    " 'Long Wang',\n",
    " 'Cathy Wu',\n",
    " 'Ling-Qi Yan']\n",
    "print('{:20s}\\t{:4s}\\t{:4s}\\t{:4s}\\t{}'.format('name','rate','total','ri','years'))\n",
    "for ns, name in sorted([(value_scores[name_idx[ni]],ni) for ni in prev_cand],reverse=True):\n",
    "    ni = name_idx[name]\n",
    "    print('{:20s}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.0f}'.format(name,100*norm_scores[ni],100*value_scores[ni],100*ri_scores[ni],years_working[ni]))\n",
    "print('')\n",
    "curious_names = ['Xiaolong Wang 0004','Judy Hoffman','Paris Siminelakis',\n",
    "                 'Nicholas Rhinehart',\n",
    "                 'Humphrey Hu',\n",
    "                 'David F. Fouhey',\n",
    "                 'Lerrel Pinto',\n",
    "                 'Justin Johnson',\n",
    "                 'Amir Roshan Zamir',\n",
    "                 'Brian Okorn','David Held']\n",
    "print('{:20s}\\t{:4s}\\t{:4s}\\t{:4s}\\t{}'.format('name','rate','total','ri','years'))\n",
    "for _,name in sorted([(value_scores[name_idx[_]],_) for _ in curious_names],reverse=True):\n",
    "    ni = name_idx[name]\n",
    "    print('{:20s}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.0f}'.format(name,100*norm_scores[ni],100*value_scores[ni],100*ri_scores[ni],years_working[ni]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n best overall \\n')\n",
    "cmu_scores = []\n",
    "\n",
    "best_scores = np.argsort(value_scores)[::-1]\n",
    "#print(best_scores.shape,unique_names[best_scores[0]])\n",
    "fa_list = list(faculty_affil.name)\n",
    "fa_a_list = list(faculty_affil.affiliation)\n",
    "uni_names = [unique_names[i] for i in best_scores[:38000]]\n",
    "for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "    if name in name_idx:\n",
    "        uni = 'unknown'\n",
    "        if name in fa_list:\n",
    "            uni = fa_a_list[fa_list.index(name)]\n",
    "        if name not in []:#['Jacob Walker','Justin Johnson','Pieter Abbeel','Martial Hebert','Jessica K. Hodgins','Abhinav Gupta','Christopher G. Atkeson','Tom M. Mitchell','Matthew T. Mason']:\n",
    "            if years_working[name_idx[name]] < 3:\n",
    "                continue\n",
    "            if years_working[name_idx[name]] > 8:\n",
    "                continue\n",
    "            if ri_scores[name_idx[name]] < 0.008:\n",
    "                continue\n",
    "            if auth_years[name_idx[name],1] < 2017:\n",
    "                continue\n",
    "        #if (np.array(X[name_idx[name],:].todense()) * ri_confs).sum() == 0:\n",
    "        #    continue\n",
    "        #print(name,auth_years[name_idx[name]])\n",
    "        score = norm_scores[name_idx[name]]\n",
    "        ri_vscore = ri_norm_scores[name_idx[name]]\n",
    "        vscore = value_scores[name_idx[name]]\n",
    "        cmu_scores.append((vscore,ri_scores[name_idx[name]],score,uni,name,auth_years[name_idx[name]],ri_vscore))\n",
    "    else:\n",
    "        pass\n",
    "        #print(name)\n",
    "        ri_norm_scores\n",
    "print('{:22s}\\t{:15s}\\t{:5s}\\t{:3s}\\t{:4s}\\t{:4s}\\t{} {}'.format('name','uni','rate','RI-t','total','RI-r','start','end'))\n",
    "for vs,ris,s,u,p,yrs,rir in sorted(cmu_scores,reverse=True):\n",
    "    print('{:22s}\\t{:15s}\\t{:.3f}\\t{:.1f}\\t{:.2f}\\t{:.2f}\\t{} {}'.format(p[:22],u[:15],s*100,ris*100,vs*100,rir*100,int(yrs[0]),int(yrs[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_faculty = faculty_affil[faculty_affil.affiliation == 'Carnegie Mellon University'] #Carnegie Mellon University\n",
    "uni_names = np.array(uni_faculty.name)\n",
    "uni_names = list(uni_names) + ['Nicholas Rhinehart','Jacob Walker','Lerrel Pinto','Brian Okorn','Leonid Keselman','Siddharth Ancha','Humphrey Hu']\n",
    "cmu_scores = []\n",
    "#uni_names = [unique_names[i] for i in (np.argsort(scores)[::-1])[:150]]\n",
    "for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "    if name in name_idx:\n",
    "        #if ri_scores[name_idx[name]] < 2.5:\n",
    "        #    continue\n",
    "        score = scores[name_idx[name]]\n",
    "        cmu_scores.append((score,name))\n",
    "    else:\n",
    "        pass\n",
    "        #print(name)\n",
    "for s,p in sorted(cmu_scores,reverse=True):\n",
    "    print('{:30s}\\t\\t{:.3f}'.format(p,s*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Xauth,open('xauth.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du -h *.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
