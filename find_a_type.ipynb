{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv\n",
    "import scipy.sparse\n",
    "Xauth = None\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the update to work despite the broken scipy documentation\n",
    "try:\n",
    "    a = scipy.sparse.dok_matrix((10,10))\n",
    "    a.update({(0,0):1.0})\n",
    "    scipy.sparse.dok_matrix.my_update = scipy.sparse.dok_matrix.update\n",
    "except:\n",
    "    a = scipy.sparse.dok_matrix((10,10))\n",
    "    a._update({(0,0):1.0})\n",
    "    scipy.sparse.dok_matrix.my_update = scipy.sparse.dok_matrix._update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('useful_venue_list.pkl.gz','rb') as fp:\n",
    "    all_venues = pickle.load(fp)\n",
    "with gzip.open('useful_authors_list.pkl.gz','rb') as fp:\n",
    "    all_authors = pickle.load(fp)\n",
    "with gzip.open('useful_papers.pkl.gz','rb') as fp:\n",
    "    all_papers = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_year = all_papers[0][6]\n",
    "max_year = all_papers[-1][6]\n",
    "span_years = max_year - min_year + 1\n",
    "print(min_year,max_year,span_years)\n",
    "conf_idx = {v:i for i,v in enumerate(all_venues)}\n",
    "name_idx = {v:i for i,v in enumerate(all_authors)}\n",
    "n_confs = len(all_venues)\n",
    "n_auths = len(all_authors)\n",
    "n_papers = len(all_papers)\n",
    "print(n_confs,n_auths,n_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =  np.load('clf_gold.pkl.npy')\n",
    "years_per_conf = clf.shape[0]//n_confs\n",
    "YEAR_BLOCKS = span_years//years_per_conf\n",
    "import gzip\n",
    "import pickle\n",
    "with gzip.open('scoresV2.pkl.gz','rb') as fp:\n",
    "    scoreV = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_totals = np.zeros(n_auths)\n",
    "author_coauthors = np.zeros(n_auths)\n",
    "author_coauth_set = defaultdict(set)\n",
    "\n",
    "author_vecs = {}\n",
    "last_years = np.zeros(n_auths)\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    n = len(authors)\n",
    "    c_value =  clf[years_per_conf*(conf_idx[venue]) + (year-min_year)//YEAR_BLOCKS]\n",
    "    c_value = max(c_value,1e-9)\n",
    "    if n not in author_vecs:\n",
    "        v= 1/(np.arange(n)+1)\n",
    "        v = v/v.sum()\n",
    "        author_vecs[n] = v\n",
    "        \n",
    "    for ai,a in enumerate(authors):\n",
    "        idx = name_idx[a]\n",
    "        last_years[idx] = max(last_years[idx],year)\n",
    "        w =  c_value*author_vecs[n][ai]\n",
    "        author_totals[idx] += w\n",
    "        author_coauthors[idx] += n*w\n",
    "        for a2 in authors:\n",
    "            author_coauth_set[a].add(a2)\n",
    "author_coauthors /= np.maximum(1e-12,author_totals)\n",
    "author_coauth_num = np.array([len(author_coauth_set[a]) for a in all_authors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.ones_like(scoreV['1/i_CV_1970'])\n",
    "#prod_col = [v for k,v in scoreV.items() if 'apm' in k] + [1/scoreV['working_years'],1/author_coauthors,1/author_coauth_num,scoreV['1/i_CV_1970'],scoreV['1/i_GR_1970'],scoreV['full_total_1970']]\n",
    "#prod_col = [scoreV['1/i_total_1970']] #+ [scoreV['pw_apmTrue']]\n",
    "#prod_col = [v for k,v in scoreV.items() if 'apm' in k]\n",
    "prod_col = [scoreV['_apmTrue'],scoreV['_apmFalse']]\n",
    "#prod_col = [1/scoreV['working_years'],1/author_coauthors,1/author_coauth_num,scoreV['1/i_CV_1970'],scoreV['1/i_GR_1970'],scoreV['full_total_1970']]\n",
    "#prod_col = [scoreV['1/i_CV_1970'],scoreV['1/i_GR_1970'],scoreV['1/i_ML_1970'],scoreV['full_total_1970'],1/author_coauthors,1/scoreV['working_years']]\n",
    "\n",
    "tot_score = scoreV['full_total_1970']\n",
    "for col in prod_col:\n",
    "    vec += (col-col.mean())/col.std()\n",
    "vec = (vec)/len(prod_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:20s}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('name','scoreV','score','coauth','auth','yr'))\n",
    "for i in (np.argsort(vec)[::-1])[:8000]:\n",
    "    yz = int(scoreV['working_years'][i])\n",
    "    pz_per_year = author_coauth_num[i]/yz\n",
    "    if last_years[i] < 2018:\n",
    "        continue\n",
    "    if yz < 80 and pz_per_year < 150 and author_coauthors[i] <= 13.5:\n",
    "        print('{:20s}\\t{:.2f}\\t{:.0f}\\t{:.0f}\\t{:.1f}\\t{:d}'.format(all_authors[i],vec[i],tot_score[i],author_coauth_num[i]/yz,author_coauthors[i],yz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreV.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreV['1/i_total_1970'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curious_names = ['Xiaolong Wang 0004','Judy Hoffman','Paris Siminelakis','Roie Levin','Leonid Keselman',\n",
    "                 'Nicholas Rhinehart','Vincent Sitzmann','Siddharth Ancha','Xingyu Lin',\n",
    "                 'Humphrey Hu','Aditya Dhawale','Nick Gisolfi','Andrey Kurenkov','Micah Corah',\n",
    "                 'David F. Fouhey','Chelsea Finn','Akshara Rai','Ankit Bhatia','Xuning Yang',\n",
    "                 'Lerrel Pinto','Alexander Spitzer','Roberto Shu','Allison Del Giorno','Nadine Chang',\n",
    "                 'Justin Johnson 0001','Kumar Shaurya Shankar','Ellen A. Cappo','Hunter Goforth',\n",
    "                 'Amir Roshan Zamir','Jonathan T. Barron','Dorsa Sadigh','Derek Hoiem','Vaggos Chatziafratis',\n",
    "                 'Brian Okorn','David Held','Adam W. Harley','Hsiao-Yu Fish Tung','Tess Lee Hellebrekers']\n",
    "print('{:20s}\\t{}\\t{}\\t{}\\t{}'.format('name','score','coauth/yr','avg auth','yr'))\n",
    "for i in (np.argsort(vec)[::-1]):\n",
    "    if all_authors[i] not in curious_names:\n",
    "        continue\n",
    "    yz = int(scoreV['working_years'][i])\n",
    "    pz_per_year = author_coauth_num[i]/yz\n",
    "    print('{:20s}\\t{:.1f}\\t{:.1f}\\t\\t{:.1f}\\t\\t{:d}'.format(all_authors[i],vec[i],author_coauth_num[i]/yz,author_coauthors[i],yz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k,v[name_idx['Martial Hebert']]/v[name_idx['Abhinav Gupta 0001']]) for k,v in scoreV.items() if 'apm' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2dict_str_str(fname):\n",
    "    with open(fname, mode='r') as infile:\n",
    "        rdr = csv.reader(infile)\n",
    "        d = {rows[0].strip(): rows[1].strip() for rows in rdr}\n",
    "    return d\n",
    "aliasdict = csv2dict_str_str('dblp-aliases-expanded.csv')\n",
    "ri_names = list(set([aliasdict.get(row[1],row[1]) for row in pd.read_csv('other_ranks/cmu_faculty.csv').itertuples() if row[2] == 'RI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:20s}\\t{}\\t{}\\t{}\\t{}'.format('name','score','coauth/yr','avg auth','yr'))\n",
    "for i in (np.argsort(vec)[::-1]):\n",
    "    if all_authors[i] not in ri_names:\n",
    "        continue\n",
    "    yz = int(scoreV['working_years'][i])\n",
    "    pz_per_year = author_coauth_num[i]/yz\n",
    "    print('{:20s}\\t{:.1f}\\t{:.0f}\\t\\t{:.1f}\\t\\t{:d}'.format(all_authors[i],vec[i],author_coauth_num[i]/yz,author_coauthors[i],yz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "associated_colab = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    n = len(authors)\n",
    "    c_value =  clf[years_per_conf*(conf_idx[venue]) + (year-min_year)//YEAR_BLOCKS]\n",
    "    for ai,a in enumerate(authors):\n",
    "        w =  c_value*author_vecs[n][ai]\n",
    "        for a2 in authors:\n",
    "            associated_colab[a2][a] += w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([(v,k) for k,v in associated_colab['Jonathan T. Barron'].items()],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_score = np.zeros(n_auths)\n",
    "ent_score = np.zeros(n_auths)\n",
    "\n",
    "for a in associated_colab:\n",
    "    cl = associated_colab[a]\n",
    "    ms = cl[a]\n",
    "    vvec = np.array(list(cl.values()))\n",
    "    os = max(1e-9,vvec.sum())\n",
    "    ms_os = max(1e-9,os-ms)\n",
    "    \n",
    "    vvec_N = vvec/os\n",
    "    entr = -(np.log(np.maximum(1e-9,vvec_N))*vvec_N).sum()\n",
    "    ratio_score[name_idx[a]] = ms_os/max(1e-9,ms)\n",
    "    ent_score[name_idx[a]] = entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:20s}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('name','score','coauth/yr','avg auth','yr','ratio','ent'))\n",
    "for i in (np.argsort(ratio_score)[::-1]):\n",
    "    if all_authors[i] not in curious_names:\n",
    "        continue\n",
    "    yz = int(scoreV['working_years'][i])\n",
    "    pz_per_year = author_coauth_num[i]/yz\n",
    "    print('{:20s}\\t{:.1f}\\t{:.0f}\\t\\t{:.1f}\\t\\t{:d}\\t{:.1f}\\t{:.1f}'.format(all_authors[i],vec[i],author_coauth_num[i]/yz,author_coauthors[i],yz,ratio_score[i],ent_score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_colab_set = sorted(list(set(sum([list(author_coauth_set[n]) for n in ri_names],[]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_a = pd.DataFrame([all_authors] + [_ for _ in scoreV.values() if len(_.shape) == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_a = pd.DataFrame([all_authors])\n",
    "df_a = pd.DataFrame(np.array(all_authors),columns=['name'])\n",
    "valO_v = np.array([sum([v for k,v in associated_colab[a].items() if k!=a]) for a in all_authors])\n",
    "#for k,v in scoreV.items():\n",
    "#    if len(v.shape) != 1:\n",
    "#          continue\n",
    "#    df_a[k] = v\n",
    "df_a['val'] = author_totals\n",
    "df_a['adv'] = scoreV['pw_apmTrue']\n",
    "df_a['coauth'] = author_coauth_num\n",
    "df_a['avg_co'] = author_coauthors\n",
    "df_a['ratio'] = ratio_score\n",
    "df_a['ratio2'] = author_totals/(valO_v+author_totals)\n",
    "df_a['ent'] = ent_score\n",
    "df_a['valO'] = valO_v\n",
    "#adv2 = [np.maximum(1e-9,v) for k,v in scoreV.items() if 'apm' in k]\n",
    "#adv2 = np.prod(adv2,axis=0)**(1/len(adv2))\n",
    "df_a['adv2'] = scoreV['_apmTrue'] + scoreV['_apmFalse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_a[df_a.name.isin(ri_colab_set)].sort_values('adv',0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.scatter(df2.ratio,df2.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import statsmodels.api as sm\n",
    "df3 = df2[df2.ratio < 10]\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df3['coauth'],df3['val'])\n",
    "sns.lmplot('coauth','val',df3)\n",
    "slope,intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regf = sm.OLS(df_r2['val'],df_r2['coauth']).fit()\n",
    "#regf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "#plt.figure(figsize=(4,4))\n",
    "df_r = df_a[df_a.name.isin(ri_names)]\n",
    "df_r = df_r[df_r.val < 300]\n",
    "df_r['pval'] = df_r.coauth*0.62\n",
    "sns.lmplot('val','pval',df_r)\n",
    "#plt.scatter(df_r.val,df_r.coauth*0.25)\n",
    "#plt.xlabel('academic value')\n",
    "#plt.ylabel('coauthors times 0.25')\n",
    "#plt.grid(True)\n",
    "#plt.axis('equal')\n",
    "#plt.xlim(0,200)\n",
    "plt.ylabel('CoAuthors x 0.62')\n",
    "plt.xlabel('Academic Contribution')\n",
    "plt.title('RI Faculty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_r2['pval'] = 0.6*df_r2.coauth\n",
    "#df_r2['overExpect'] = (df_r2.val - df_r2.pval)/df_r2.val\n",
    "#df_r2.sort_values('overExpect',0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(open('download/ri_students.html','rt').read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stud_names = []\n",
    "advisor_set = []\n",
    "is_phd = []\n",
    "students = soup.find_all('div',{'class':'RIpersoninfo'})\n",
    "for stud in students:\n",
    "    filt = [_ for _ in [_.strip().rstrip().replace('\\t',' ') for _ in stud.get_text().split('\\n')] if len(_) > 0]\n",
    "    stud_names.append(filt[0])\n",
    "    advisors = [_.strip().rstrip() for _ in filt if 'Advisor' in _]\n",
    "    if len(advisors) > 0:\n",
    "        a_set = advisors[0].split(':')[-1].rstrip().strip()\n",
    "        a_set = [_.strip().rstrip() for _ in a_set.split(' and ')]\n",
    "        a_set = [_ for _ in a_set if len(_) > 0]\n",
    "    else:\n",
    "        a_set = []\n",
    "        \n",
    "    advisor_set.append(a_set)\n",
    "    is_phd.append('PhD' in stud.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "a_count = sorted([(v,k) for k,v in Counter(sum(advisor_set,[])).items()])[::-1]\n",
    "ri_names = list(set([aliasdict.get(row[1],row[1]) for row in pd.read_csv('other_ranks/cmu_faculty.csv',encoding='utf8').itertuples() if row[2] == 'RI']))\n",
    "ri_colab_set = set(sorted(list(set(sum([list(author_coauth_set[n]) for n in ri_names],[])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thefuzz.process\n",
    "if False:\n",
    "    dblp_stud = []\n",
    "    dblp_cand_s = []\n",
    "    for stud_n,advis_n,isP in zip(stud_names,advisor_set,is_phd):\n",
    "        if len(advis_n) == 0:\n",
    "            continue\n",
    "        res = thefuzz.process.extract(stud_n,ri_colab_set)\n",
    "        if res[0][1] >= 88:\n",
    "            r = res[0][0]\n",
    "            dblp_stud.append(res[0][0])\n",
    "        elif stud_n in name_idx and stud_n + ' 0001' not in name_idx:\n",
    "            r = stud_n\n",
    "        else:\n",
    "            r = ''\n",
    "            print(res,stud_n,advis_n)\n",
    "        dblp_cand_s.append([stud_n,advis_n,isP,r])\n",
    "    df_s_out = pd.DataFrame(dblp_cand_s,columns = ['name','advis','phd','dblp name'])\n",
    "    df_s_out.to_csv('stud_lookup2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s_out = pd.read_csv('stud_lookup2.csv')\n",
    "filt_set1 = df_s_out[df_s_out['dblp name'].map(lambda x: type(x) is str) & df_s_out.phd]\n",
    "filt_set2 = df_s_out[df_s_out['dblp name'].map(lambda x: type(x) is float and np.isnan(x)) & df_s_out.phd]\n",
    "\n",
    "dblp_stud = list(filt_set1['dblp name'])\n",
    "filt_set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advisor_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_stud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [_[1] for _ in a_count]:\n",
    "    res = thefuzz.process.extract(n,ri_names)\n",
    "    if res[0][1] < 80:\n",
    "        print(n,res[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = df_a[df_a.name.isin(dblp_stud)]\n",
    "\n",
    "s_clf = sm.OLS(df_s['val'],df_s[['valO']]).fit()\n",
    "s_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "#plt.figure(figsize=(4,4))\n",
    "#df_s = df_s[df_s.coauth < 100]\n",
    "#df_s = df_s[df_s.val < 20]\n",
    "\n",
    "df_s['pval'] = s_clf.predict()\n",
    "\n",
    "df_s['diff'] = (df_s.val - df_s.pval)#/(df_s.valO+df_s.val)\n",
    "sns.lmplot('val','pval',df_s)\n",
    "#plt.scatter(df_r.val,df_r.coauth*0.25)\n",
    "#plt.xlabel('academic value')\n",
    "#plt.ylabel('coauthors times 0.25')\n",
    "#plt.grid(True)\n",
    "#plt.axis('equal')\n",
    "#plt.xlim(0,200)\n",
    "plt.ylabel('Predicted value')\n",
    "plt.xlabel('Academic Contribution')\n",
    "plt.title('RI Students')\n",
    "#plt.ylim(0,20)\n",
    "#plt.xlim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 300)\n",
    "df_s.sort_values('ratio2',0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(open('download/ri_alumni.html','rt').read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alum = soup2.find_all('div',{'class':'col-lg-12 col-md-12 col-sm-12 col-xs-12 alumni-block'})\n",
    "alum_names = []\n",
    "for stud in alum:\n",
    "    res = [_ for _ in stud.get_text().split('\\n') if len(_) > 0]\n",
    "    \n",
    "    is_phd = [_ for _ in res if 'Program: PhD' == _]\n",
    "    is_complete = [_ for _ in res if 'Date Completed' in _]\n",
    "    if is_phd and len(is_complete) > 0:\n",
    "        #print(res)\n",
    "        alum_names.append((res[0],int(is_complete[0][-4:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alum_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_ for _ in ri_colab_set if 'Matt' in  _]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import thefuzz.process\n",
    "    dblp_alum = []\n",
    "    dblp_alum_yr = []\n",
    "    failed_alum_find = []\n",
    "    for stud_n,yr in alum_names:\n",
    "        if len(ri_colab_set) == 0:\n",
    "            continue\n",
    "        res = thefuzz.process.extract(stud_n,ri_colab_set)\n",
    "        if res[0][1] < 88:\n",
    "            print(res,stud_n,yr)\n",
    "            r = ''\n",
    "        else:\n",
    "            r = res[0][0]\n",
    "            dblp_alum.append(r)\n",
    "            dblp_alum_yr.append((r,yr))\n",
    "        failed_alum_find.append([stud_n,yr,r])\n",
    "        \n",
    "    df_a_out = pd.DataFrame(failed_alum_find,columns = ['name','year','dblp name'])\n",
    "    df_a_out.to_csv('alum_lookup2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_out = pd.read_csv('alum_lookup.csv')\n",
    "df_a_out[df_a_out['dblp name'].map(lambda x: type(x) is float and np.isnan(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "#plt.figure(figsize=(4,4))\n",
    "df_l = df_a[df_a.name.isin(set(df_a_out['dblp name']))]\n",
    "#df_l = df_l[df_l.coauth < 100]\n",
    "#df_l = df_l[df_l.val < 20]\n",
    "\n",
    "df_l['pval'] = 0.45*df_l.coauth\n",
    "df_l['diff'] = (df_l.val - df_l.pval)/np.maximum(df_l.pval,df_l.val)\n",
    "sns.lmplot('val','pval',df_l)\n",
    "#plt.scatter(df_r.val,df_r.coauth*0.25)\n",
    "#plt.xlabel('academic value')\n",
    "#plt.ylabel('coauthors times 0.25')\n",
    "#plt.grid(True)\n",
    "#plt.axis('equal')\n",
    "#plt.xlim(0,200)\n",
    "plt.ylabel('CoAuthors')\n",
    "plt.xlabel('Academic Contribution')\n",
    "plt.title('RI Students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l.sort_values('val',0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_a_out.itertuples():\n",
    "    print(row[2],row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_alum_yr = {_[3]:_[2] for _ in df_a_out.itertuples() if type(_[3]) == str}\n",
    "bad_list = ['Eric Huang','David Silver']\n",
    "for n in bad_list:\n",
    "    if n in dblp_alum_yr:\n",
    "        del dblp_alum_yr[n]\n",
    "for n in dblp_alum_yr:\n",
    "    if n not in name_idx:\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_vals = defaultdict(float)\n",
    "author_vals_O = defaultdict(float)\n",
    "\n",
    "author_cos = defaultdict(list)\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    n = len(authors)\n",
    "    c_value =  clf[years_per_conf*(conf_idx[venue]) + (year-min_year)//YEAR_BLOCKS]\n",
    "    for ai,a in enumerate(authors):\n",
    "        w =  c_value*author_vecs[n][ai]\n",
    "        if a in dblp_alum_yr and year <= dblp_alum_yr[a]:\n",
    "            author_cos[a] = authors + author_cos[a]\n",
    "            author_vals[a] += w\n",
    "            author_vals_O[a] += c_value-w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_cos_l = {k:len(set(v)) for k,v in author_cos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_a[df_a.name.isin(dblp_alum_yr)].sort_values('adv2',0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a2 = pd.DataFrame([author_cos_l,author_vals,author_vals_O,dblp_alum_yr]).T\n",
    "df_a2.columns = ['coauth','val','valO','year']\n",
    "df_a2 = df_a2.fillna(0)\n",
    "df_a2['pval'] = df_a2.coauth*0.5\n",
    "df_a2['diff'] =  (df_a2.val - df_a2.pval)/np.maximum(df_a2.pval,df_a2.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a2[df_a2.coauth.map(lambda x:np.isnan(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a3 = df_a2.copy()\n",
    "df_a3 = df_a3.dropna()\n",
    "#[df_a2.coauth < 190]\n",
    "#df_a3 = df_a3[df_a3.val < 60]\n",
    "#df_a3 = df_a3[df_a3.year >= 2010]\n",
    "df_a3[df_a3.year == 1994].sort_values('val',0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_a3.groupby('year').median()['val'])\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Median Production')\n",
    "plt.title('RI PhD students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_a3.val,df_a3.coauth*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regf = sm.OLS(df_a3['val'],df_a3[['coauth','valO']]).fit()\n",
    "regf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_a3.val,50)\n",
    "#plt.xlim(0,20)\n",
    "q1,q2,q3 = np.median(df_a3.val),np.quantile(df_a3.val,0.25),np.quantile(df_a3.val,0.75)\n",
    "plt.title('RI PhD Student Productivity\\nMedian: {:.2f}, IQR: [{:.1f} to {:.1f}]'.format(q1,q2,q3))\n",
    "plt.xlabel('Production before graduating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a3['pred'] = regf.predict()\n",
    "df_a3['diff2'] =  (df_a3.val - df_a3.pred)/np.maximum(df_a3.pred,df_a3.val)\n",
    "df_a3 = df_a3.sort_values('diff2',0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_alum_yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a3.sort_values('diff',0,False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
