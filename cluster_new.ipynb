{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import zipfile\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_affil = pd.read_csv('faculty-affiliations.csv')\n",
    "def csv2dict_str_str(fname):\n",
    "    with open(fname, mode='r') as infile:\n",
    "        rdr = csv.reader(infile)\n",
    "        d = {rows[0].strip(): rows[1].strip() for rows in rdr}\n",
    "    return d\n",
    "aliasdict = csv2dict_str_str('dblp-aliases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_unis = faculty_affil.affiliation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = pd.read_csv('other_ranks/r1.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for row in r1.itertuples():\n",
    "    if not row[1] in csr_unis:\n",
    "        print(row[1])\n",
    "        i +=1\n",
    "print(i)\n",
    "r1 = list(r1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_faculty_affil = {k:v for k,v in faculty_affil.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get r1\n",
    "filter_set = [1 if row[2] in r1 else 0 for row in faculty_affil.itertuples()]\n",
    "fss = np.array(filter_set).astype(np.bool)\n",
    "r1_faculty_affil = faculty_affil[fss]\n",
    "\n",
    "# get alias\n",
    "r1_unique = sorted(set([aliasdict.get(row[1],row[1]) for row in r1_faculty_affil.itertuples()]))\n",
    "len(r1_unique),r1_faculty_affil.shape\n",
    "r1_unique_dict = {k:1 for k in r1_unique}\n",
    "affils_dict = {row[1]:row[2] for row in r1_faculty_affil.itertuples()} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    r1_unique_dict2 = {k:1 for k in r1_unique_2}\n",
    "    new_names = []\n",
    "    for name in r1_unique:\n",
    "        if name not in r1_unique_dict2:\n",
    "            new_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('useful_venue_list.pkl.gz','rb') as fp:\n",
    "    all_venues = pickle.load(fp)\n",
    "with gzip.open('useful_authors_list.pkl.gz','rb') as fp:\n",
    "    all_authors = pickle.load(fp)\n",
    "with gzip.open('useful_papers.pkl.gz','rb') as fp:\n",
    "    all_papers = pickle.load(fp)\n",
    "conf_idx = {v:i for i,v in enumerate(all_venues)}\n",
    "name_idx = {v:i for i,v in enumerate(all_authors)}\n",
    "n_confs = len(all_venues)\n",
    "n_auths = len(all_authors)\n",
    "#r1_confs = pickle.load(open('old_version/r1_confs.pkl','rb'))\n",
    "#r1_confs_dict = {_:1 for _ in r1_confs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr1 = scipy.sparse.dok_matrix((len(r1),n_confs))\n",
    "xdict = {}\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, conf, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    j = conf_idx[conf]\n",
    "    if year < 2000:\n",
    "        continue\n",
    "    for a in authors:\n",
    "        name = aliasdict.get(a,a)\n",
    "        if name in affils_dict:\n",
    "            uni = affils_dict[name]\n",
    "            i = r1.index(uni)\n",
    "            xdict[(i,j)] = 1\n",
    "Xr1._update(xdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_confs = (Xr1.sum(0) > 20)\n",
    "\n",
    "\n",
    "\n",
    "r1_confs = [conf for conf in all_venues if filtered_confs[0,conf_idx[conf]]]\n",
    "print(len(r1_confs))\n",
    "#print(r1_confs)\n",
    "r1_conf_idx = {v:i for i,v in enumerate(r1_confs)}\n",
    "r1_conf_idx_orig = [conf_idx[conf] for conf in all_venues if filtered_confs[0,conf_idx[conf]]]\n",
    "\n",
    "r1_scores = Xr1[:,np.array(filtered_confs).reshape((-1))]\n",
    "r1_scores = np.array(r1_scores.sum(0)).reshape((-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpaper = scipy.sparse.dok_matrix((len(r1_unique),len(r1_confs)))\n",
    "xdict = {}\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, conf, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    if conf not in r1_conf_idx:\n",
    "        continue\n",
    "    if year < 2000:\n",
    "        continue\n",
    "    j = r1_conf_idx[conf]\n",
    "    for a in authors:\n",
    "        name = aliasdict.get(a,a)\n",
    "        if name in affils_dict:\n",
    "            i = r1_unique.index(name)\n",
    "            xdict[(i,j)] = 1 + xdict.get((i,j),0)\n",
    "Xpaper._update(xdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1counts = np.squeeze(np.array(Xpaper.sum(0)))\n",
    "'SIGIR' in r1_conf_idx\n",
    "if False:\n",
    "    indexs = []\n",
    "    for name in new_names:\n",
    "        indexs.append(r1_unique.index(name))\n",
    "    DP = np.array(Xpaper.todense())\n",
    "    for idx  in np.argsort(DP[np.array(indexs),:].sum(1))[::-1]:\n",
    "        idxt = indexs[idx]\n",
    "        print(r1_unique[idxt],DP[idxt].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_authors = np.squeeze(np.array(Xpaper.sum(1) > 15) & np.array(Xpaper.sum(1) < 500))\n",
    "#Xpaper_da = Xpaper[filtered_authors,:]\n",
    "Xpaper_da = Xpaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpaper_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1,i2 = r1_conf_idx['RECOMB'],r1_conf_idx['EMNLP']\n",
    "Xpaper2 = np.array(Xpaper_da.todense())\n",
    "filters_tmp = (Xpaper2[:,i1] > 2) & (Xpaper2[:,i2] > 2)\n",
    "fidx = np.where(filters_tmp > 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LatentDirichletAllocation(50,max_iter=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what = clf.fit_transform(Xpaper_da.T)\n",
    "what.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatorig = np.copy(what)\n",
    "what = what#/np.linalg.norm(what,axis=0)\n",
    "what = np.copy(whatorig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = TSNE(perplexity=16,n_iter=12000,metric='cosine',init='random') # cosine euclidean\n",
    "ys = embed.fit_transform(what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import metrics\n",
    "CLASS_NUM = 32\n",
    "km = MiniBatchKMeans(CLASS_NUM,n_init=3200,max_iter=450)#, max_iter=5000,max_no_improvement=None,reassignment_ratio=0.02)\n",
    "km.fit(what)\n",
    "s = metrics.silhouette_score(what,km.labels_,metric='cosine')\n",
    "print('{}\\t\\t{}'.format(CLASS_NUM,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(ys[:,0],ys[:,1],c=km.labels_/CLASS_NUM,cmap='tab20c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gold = np.load('clf_gold.pkl.npy')\n",
    "years_per_conf = clf_gold.shape[0]//n_confs\n",
    "max_clf = clf_gold.reshape((-1,years_per_conf))[:,-5:].mean(1)\n",
    "filt_vec = np.squeeze(np.array(filtered_confs))\n",
    "max_clf_filt = max_clf[filt_vec]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_to_look_at = max_clf_filt  #max_clf_filt or r1_scores\n",
    "for i in range(CLASS_NUM):\n",
    "    tmp = [(vector_to_look_at[i],i) for i,v in enumerate(km.labels_ == i) if v ] \n",
    "    score_idx = sorted(tmp,reverse=True)\n",
    "    print(i,len(score_idx))\n",
    "    for s,idx in score_idx[:5]:\n",
    "        print('\\t',r1_confs[idx])\n",
    "    #print('NEXT')\n",
    "    #tmp = [(r1_scores[i],i) for i,v in enumerate(km.labels_ == i) if v ] \n",
    "    #score_idx = sorted(tmp,reverse=True)\n",
    "    #for s,idx in score_idx[:5]:\n",
    "    #    print('\\t',r1_confs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as path_effects\n",
    "plt.figure(figsize=(25,25))\n",
    "cmap = plt.get_cmap('tab20c_r')\n",
    "#plt.subplot(1,2,1)\n",
    "plt.scatter(ys[:,0],ys[:,1],c=[cmap(_) for _ in km.labels_/CLASS_NUM],s=0.35*r1_scores**2,lw=0.1,edgecolors='k')\n",
    "for i in range(CLASS_NUM):\n",
    "    tmp = [(vector_to_look_at[i],i) for i,v in enumerate(km.labels_ == i) if v ] \n",
    "    score_idx = sorted(tmp,reverse=True)\n",
    "    #print(i)\n",
    "    k = 3\n",
    "    j = 0\n",
    "    for s,idx in reversed(score_idx[:k]):\n",
    "        #if s < 1.5:\n",
    "        #    continue\n",
    "        rv = np.random.randn(2)\n",
    "        xr,yr = 1.5*(rv)#/np.linalg.norm(rv)\n",
    "        text = plt.text(xr+ys[idx,0],3*(j-(k-1)/2)/(k-1)+ys[idx,1],r1_confs[idx],size='20',color=np.array(cmap(i/CLASS_NUM)),\n",
    "                 ha='center',va='center',alpha=0.9,weight='bold')\n",
    "        text.set_path_effects([path_effects.Stroke(linewidth=1, foreground='black'),\n",
    "                       path_effects.Normal()])\n",
    "        j+=1\n",
    "        #print('\\t',r1_confs[idx])\n",
    "    #print()\n",
    "plt.xticks([],[])\n",
    "plt.yticks([],[])\n",
    "plt.tight_layout()\n",
    "plt.axis('off')\n",
    "plt.savefig('tsne3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('labels',km.labels_)\n",
    "np.save('mask',np.squeeze(np.array(filtered_confs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('useful_authors_list.pkl.gz','rb') as fp:\n",
    "    all_authors = pickle.load(fp)\n",
    "name_idx = {v:i for i,v in enumerate(all_authors)}\n",
    "n_auths = len(all_authors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filt_confs = what.shape[0]\n",
    "old_idx_to_small = {}\n",
    "j = 0\n",
    "for i in range(filt_vec.shape[0]):\n",
    "    if filt_vec[i]:\n",
    "        old_idx_to_small[i] = j\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_auth_papers = np.zeros(n_auths)\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    n = len(authors)\n",
    "    if filt_vec[conf_idx[venue]]:\n",
    "        for ai in range(n):\n",
    "            i = name_idx[authors[ai]]\n",
    "            num_auth_papers[i] += 1/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "Xauth = scipy.sparse.dok_matrix((n_auths,num_filt_confs))\n",
    "xdict = {}\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    n = len(authors)\n",
    "    if filt_vec[conf_idx[venue]]:\n",
    "        j = old_idx_to_small[conf_idx[venue]]\n",
    "        for ai in range(n):#zip(count_vecs[n],authors):\n",
    "            i = name_idx[authors[ai]]\n",
    "            xdict[(i,j)] = (1/n)/num_auth_papers[i] + xdict.get((i,j),0)\n",
    "    #j = years_per_conf*conf_idx[venue] + (year-min_year)\n",
    "    #for ai in range(n):#zip(count_vecs[n],authors):\n",
    "    #    i = name_idx[authors[ai]]\n",
    "    #    #xdict[(i,j)] = 1/n + xdict.get((i,j),0)\n",
    "    #    xdict[(i,j)] = count_vecs[n][ai] + xdict.get((i,j),0)\n",
    "\n",
    "\n",
    "Xauth._update(xdict)\n",
    "\n",
    "Xauth = scipy.sparse.csr_matrix(Xauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmapped = Xauth @ what\n",
    "Xmapped_2d = Xauth @ ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = pd.read_csv('other_ranks/ranks.csv')\n",
    "top_k = 36\n",
    "subplot = int(round(np.sqrt(top_k)))\n",
    "min_v = ys.min(0)\n",
    "max_v = ys.max(0)\n",
    "plt.figure(figsize=(subplot*4,subplot*4))\n",
    "plt.rcParams = plt.rcParamsDefault\n",
    "plt.set_cmap('viridis')\n",
    "for i in range(top_k):\n",
    "    Uname = ranks.iloc[i,:].uni\n",
    "    uni_faculty = faculty_affil[faculty_affil.affiliation == Uname] \n",
    "    uni_names = np.array(uni_faculty.name)\n",
    "    uni_names = list(uni_names)\n",
    "    cmu_scores = []\n",
    "    for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "        if name in name_idx:\n",
    "            loc = Xmapped_2d[name_idx[name],:]\n",
    "            cmu_scores.append((loc))\n",
    "    cmu_scores = np.squeeze(np.array(cmu_scores))\n",
    "    plt.subplot(subplot,subplot,i+1)\n",
    "    plt.hexbin(cmu_scores[:,0],cmu_scores[:,1],gridsize=12,extent=(min_v[0],max_v[0],min_v[1],max_v[1]),vmin=0,vmax=4)\n",
    "    plt.title(Uname,color='k',weight='demibold')\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fingers3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(what,open('top_conf_embed.pkl','wb'))\n",
    "#pickle.dump(filtered_confs,open('top_conf_ind.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(r1_scores,open('r1_scores.pkl','wb'))\n",
    "#pickle.dump(r1_confs,open('r1_confs.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_uni = pd.read_csv('other_ranks/cmu_faculty.csv')\n",
    "cmu_uni = cmu_uni.fillna('CSD')\n",
    "#print(list(cmu_uni.name))\n",
    "uni_names = list(cmu_uni.name)\n",
    "uni_labels = list(cmu_uni.dept)\n",
    "uni_labels_unique = list(set(uni_labels))\n",
    "uni_labels_unique = ['CSD','RI','MLD',\"LTI\",'HCI','ISR','BIO']\n",
    "\n",
    "cmu_scores = []\n",
    "uni_colors = []\n",
    "for name,d in set([(aliasdict.get(n, n),dept) for n,dept in zip(uni_names,uni_labels)]):\n",
    "    if name in name_idx:\n",
    "        loc = Xmapped[name_idx[name],:]\n",
    "        cmu_scores.append((loc,name))\n",
    "        uni_colors.append( uni_labels_unique.index(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed2 = np.vstack([_[0] for _ in cmu_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder2 = TSNE(2,20,init='pca',n_iter=6500)\n",
    "ys2 = embedder2.fit_transform(embed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "nc = (len(uni_labels_unique))\n",
    "cmap = plt.get_cmap('tab10')\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.scatter(ys2[:,0],ys2[:,1],s=120,lw=1,edgecolors='k',c=cmap(np.array(uni_colors)/nc-0.0))\n",
    "for i in range(ys2.shape[0]):\n",
    "    rv = np.random.randn(2)\n",
    "    xr,yr = 0.2*(rv)#/np.linalg.norm(rv)\n",
    "    text= plt.text(ys2[i,0]+xr,yr+ys2[i,1],cmu_scores[i][1],size='14',color=cmap(uni_colors[i]/nc),\n",
    "             horizontalalignment='center',verticalalignment='center',alpha=0.9,weight='bold')\n",
    "    text.set_path_effects([path_effects.Stroke(linewidth=0.2, foreground='black'),\n",
    "               path_effects.Normal()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "import matplotlib.patheffects as path_effects\n",
    "from cycler import cycler\n",
    "#plt.style.use('Solarize_Light2') #bmh\n",
    "plt.style.use('default')\n",
    "plt.style.use('seaborn-white')\n",
    "#plt.rcParams[\"axes.prop_cycle\"] =  cycler(color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "plt.rcParams[\"axes.prop_cycle\"] =  cycler(color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b',  '#bcbd22', '#17becf'])\n",
    "nc = (len(uni_labels_unique))\n",
    "cmap = plt.get_cmap('tab10')\n",
    "plt.figure(figsize=(12,12))\n",
    "colors_for_now = []\n",
    "uni_colors = np.array(uni_colors)\n",
    "legends = []\n",
    "\n",
    "for i in [0,1,2,3,4,5,6]:\n",
    "    #c=[cmap(uni_colors[i]/10+0.2) for j in uni_colors if j==i],\n",
    "    lgd = plt.scatter(ys2[i == uni_colors,0],ys2[i == uni_colors,1],s=25,lw=0.2,edgecolors='k',label=uni_labels_unique[i])\n",
    "    legends.append(lgd)\n",
    "colors_for_now = [l.get_facecolor() for l in legends]\n",
    "plt.legend(markerscale = 5,prop={'size': 24}) #\n",
    "\n",
    "if True:\n",
    "    for i in range(ys2.shape[0]):\n",
    "        rv = np.random.randn(2)\n",
    "        xr,yr = 0.15*(rv)#/np.linalg.norm(rv)\n",
    "        def name(txt):\n",
    "            txts = txt.split(' ')\n",
    "            if txts[-1].isdigit():\n",
    "                txts = txts[:-1]\n",
    "            return txts[0][0] + ' ' + txts[-1]\n",
    "        the_name = name(cmu_scores[i][1])\n",
    "        text= plt.text(ys2[i,0]+xr,yr+ys2[i,1],the_name,size='12',color=colors_for_now[uni_colors[i]][0],\n",
    "                 horizontalalignment='center',verticalalignment='center',alpha=0.8,weight='demibold')\n",
    "        #text.set_path_effects([path_effects.Stroke(linewidth=0.05, foreground='black'),\n",
    "        #           path_effects.Normal()])\n",
    "plt.gca().axis('off')\n",
    "plt.xticks([],[])\n",
    "plt.yticks([],[])\n",
    "plt.tight_layout()\n",
    "plt.savefig('cmu_faculty4.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
