{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv\n",
    "import scipy.sparse\n",
    "Xauth = None\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the update to work despite the broken scipy documentation\n",
    "try:\n",
    "    a = scipy.sparse.dok_matrix((10,10))\n",
    "    a.update({(0,0):1.0})\n",
    "    scipy.sparse.dok_matrix.my_update = scipy.sparse.dok_matrix.update\n",
    "except:\n",
    "    a = scipy.sparse.dok_matrix((10,10))\n",
    "    a._update({(0,0):1.0})\n",
    "    scipy.sparse.dok_matrix.my_update = scipy.sparse.dok_matrix._update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('useful_venue_list.pkl.gz','rb') as fp:\n",
    "    all_venues = pickle.load(fp)\n",
    "with gzip.open('useful_authors_list.pkl.gz','rb') as fp:\n",
    "    all_authors = pickle.load(fp)\n",
    "with gzip.open('useful_papers.pkl.gz','rb') as fp:\n",
    "    all_papers = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_idx = {v:i for i,v in enumerate(all_venues)}\n",
    "name_idx = {v:i for i,v in enumerate(all_authors)}\n",
    "n_confs = len(all_venues)\n",
    "n_auths = len(all_authors)\n",
    "print(n_confs,n_auths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_affil = pd.read_csv('faculty-affiliations.csv')\n",
    "ranks = pd.read_csv('other_ranks/ranks.csv')\n",
    "def csv2dict_str_str(fname):\n",
    "    with open(fname, mode='r') as infile:\n",
    "        rdr = csv.reader(infile)\n",
    "        d = {rows[0].strip(): rows[1].strip() for rows in rdr}\n",
    "    return d\n",
    "aliasdict = csv2dict_str_str('dblp-aliases-expanded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = all_papers[0][6]\n",
    "max_year = all_papers[-1][6]\n",
    "span_years = max_year - min_year + 1\n",
    "print(min_year,max_year,span_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curious_names = [\n",
    "    'Aditya Dhawale',\n",
    "    'Tesca Fitzgerald',\n",
    "    'Adam W. Harley',\n",
    "    \"Xiaolong Wang 0004\",\n",
    "    \"Judy Hoffman\",\n",
    "    \"Paris Siminelakis\",\n",
    "    \"Roie Levin\",\n",
    "    \"Leonid Keselman\",\n",
    "    \"Rick Goldstein\",\n",
    "    \"Nicholas Rhinehart\",\n",
    "    \"Vincent Sitzmann\",\n",
    "    \"Siddharth Ancha\",\n",
    "    \"Xingyu Lin\",\n",
    "    \"Humphrey Hu\",\n",
    "    \"David F. Fouhey\",\n",
    "    \"Chelsea Finn\",\n",
    "    \"Dinesh Jayaraman\",\n",
    "    \"Wen Sun 0002\",\n",
    "    \"Lerrel Pinto\",\n",
    "    \"Justin Johnson 0001\",\n",
    "    \"Amir Zamir\",\n",
    "    \"Dominik Peters\",\n",
    "    \"Jonathan T. Barron\",\n",
    "    \"Dorsa Sadigh\",\n",
    "    \"Derek Hoiem\",\n",
    "    \"Vaggos Chatziafratis\",\n",
    "    \"Brian Okorn\",\n",
    "    \"David Held\"\n",
    "]\n",
    "\n",
    "curious_names2 = ['Pulkit Agrawal',\n",
    " 'Joydeep Biswas',\n",
    " 'Katherine L. Bouman',\n",
    " 'David Braun',\n",
    " 'Jia Deng',\n",
    " 'Naomi T. Fitter',\n",
    " 'David F. Fouhey',\n",
    " 'Saurabh Gupta',\n",
    " 'Judy Hoffman',\n",
    " 'Hanbyul Joo',\n",
    " 'Honglak Lee',\n",
    " 'Changliu Liu',\n",
    " 'Petter Nilsson',\n",
    " \"Matthew O'Toole\",\n",
    " 'Alessandro Roncone',\n",
    " 'Alanson P. Sample',\n",
    " 'Manolis Savva',\n",
    " 'Adriana Schulz',\n",
    " 'Amy Tabb',\n",
    " 'Fatma Zeynep Temel',\n",
    " 'Long Wang',\n",
    " 'Ling-Qi Yan']\n",
    "\n",
    "curious_names = ['Xiaolong Wang 0004','Judy Hoffman','Paris Siminelakis','Roie Levin','Leonid Keselman',\n",
    "                 'Nicholas Rhinehart','Vincent Sitzmann','Siddharth Ancha','Xingyu Lin',\n",
    "                 'Humphrey Hu','Aditya Dhawale','Nick Gisolfi','Andrey Kurenkov',\n",
    "                 'David F. Fouhey','Chelsea Finn','Akshara Rai','Ankit Bhatia',\n",
    "                 'Lerrel Pinto','Graeme Best','Alexander Spitzer','Roberto Shu','Amir Abboud',\n",
    "                 'Justin Johnson 0001','Kumar Shaurya Shankar','Ellen A. Cappo',\n",
    "                 'Amir Zamir','Dominik Peters','Jonathan T. Barron','Dorsa Sadigh','Derek Hoiem','Vaggos Chatziafratis',\n",
    "                 'Brian Okorn','David Held']\n",
    "\n",
    "interesting_set = set(curious_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_names = list(set([aliasdict.get(row[1],row[1]) for row in pd.read_csv('other_ranks/cmu_faculty.csv').itertuples() if row[2] == 'RI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreV = None\n",
    "try:\n",
    "    import gzip\n",
    "    import pickle\n",
    "    with gzip.open('scoresV2.pkl.gz','rb') as fp:\n",
    "        scoreV = pickle.load(fp)\n",
    "except:\n",
    "    print('failed!')\n",
    "    \n",
    "clf =  np.load('clf_gold.pkl.npy')\n",
    "years_per_conf = clf.shape[0]//n_confs\n",
    "YEAR_BLOCKS = span_years//years_per_conf\n",
    "pr_full = pickle.load(open('new_pagerank_people.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "author_results = defaultdict(dict)\n",
    "for name in interesting_set:\n",
    "    idx = name_idx[name]\n",
    "    author_results[name]['Affiliation'] = faculty_lookup.get(name,'Unknown')\n",
    "    author_results[name]['Years'] = scoreV['working_years'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_years = (auth_years[:,1] - auth_years[:,0]+1)\n",
    "\n",
    "v = scoreV['1/i_total_1970']/(np.maximum(2,working_years.astype(np.float32)))\n",
    "ratio_v = np.maximum(1e-3,scoreV['1/i_RI_1970'])/np.maximum(1e-3,scoreV['1/i_total_1970'])\n",
    "v *= np.sqrt(ratio_v)\n",
    "v *= 1/np.log(np.maximum(2,working_years.astype(np.float32)))\n",
    "tv = np.zeros_like(scoreV['1/i_total_1970'])\n",
    "for n in ['_apmFalse', '_apmTrue',  'pw_apmFalse', 'pw_apmTrue', 'pweff_apmFalse', 'pweff_apmTrue', 'pwunk_apmFalse','pwunk_apmTrue']:\n",
    "    tv +=  scoreV[n]\n",
    "v *= np.log(np.maximum(tv,10))\n",
    "v *= np.log(scoreV['1/i_max_yr']-1965)\n",
    "v = np.nan_to_num(v)\n",
    "meta_metric = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthors  = defaultdict(lambda: defaultdict(int))\n",
    "coauthors_frac  = defaultdict(lambda: defaultdict(float))\n",
    "coauthors_num  = defaultdict(list)\n",
    "author_pos  = defaultdict(list)\n",
    "conf_paper_frac  =  defaultdict(lambda: defaultdict(int))\n",
    "paper_num  = defaultdict(int)\n",
    "paper_frac  = defaultdict(float)\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    n = len(authors)\n",
    "    parse = False\n",
    "    for a in authors:\n",
    "        if a in interesting_set:\n",
    "            parse = True\n",
    "            break\n",
    "    if parse:\n",
    "        for i,a in enumerate(authors):\n",
    "            if a in interesting_set:\n",
    "                conf_paper_frac[a][venue] += 1/n\n",
    "                coauthors_num[a].append(n)\n",
    "                author_pos[a].append((i+1)/n)\n",
    "                paper_num[a] += 1\n",
    "                paper_frac[a] += 1/n\n",
    "                for a2 in authors:\n",
    "                    if a2 == a:\n",
    "                        continue\n",
    "                    coauthors[a][a2] += 1\n",
    "                    coauthors_frac[a][a2] += 1/n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in interesting_set:\n",
    "    idx = name_idx[name]\n",
    "    author_results[name]['MetaMetric'] = meta_metric[idx]\n",
    "    author_results[name]['Score (1/pos)'] = scoreV['1/i_total_1970'][idx]\n",
    "    \n",
    "    author_results[name]['RIScore'] = scoreV['1/i_RI_1970'][idx]\n",
    "    author_results[name]['RI %'] = scoreV['1/i_RI_1970'][idx]/scoreV['1/i_total_1970'][idx]\n",
    "\n",
    "    sum_v = 0\n",
    "    for sub in ['ROB','CV','GR','ML']:\n",
    "        den = scoreV['1/i_{}_1970'.format(sub)][idx]\n",
    "        den = den if den != 0.0 else 0\n",
    "        author_results[name][sub + ' %'] = den/max(1e-9,scoreV['1/i_total_1970'][idx])\n",
    "        sum_v += den\n",
    "    author_results[name]['Other %'] = max(0,scoreV['1/i_total_1970'][idx] - sum_v)/scoreV['1/i_total_1970'][idx]\n",
    "    \n",
    "    author_results[name]['From'] = scoreV['auth_years'][idx][0]\n",
    "    author_results[name]['Until'] = scoreV['auth_years'][idx][1]\n",
    "\n",
    "    author_results[name]['YearlyScore (1/pos)'] = scoreV['1/i_total_1970'][idx]/scoreV['working_years'][idx]\n",
    "    author_results[name]['YearlyRIScore'] = scoreV['1/i_RI_1970'][idx]/scoreV['working_years'][idx]\n",
    "\n",
    "new_set = set()\n",
    "\n",
    "for name in interesting_set:\n",
    "    idx = name_idx[name]\n",
    "\n",
    "    author_results[name]['avgCoauthor'] = np.array(coauthors_num[name]).mean()\n",
    "    colabs = sorted([(v,k) for k,v in coauthors_frac[name].items()],reverse=True)\n",
    "    fam_colab = sorted([(v*scoreV['1/i_total_1970'][name_idx[k]],k) for k,v in coauthors_frac[name].items()],reverse=True)\n",
    "    \n",
    "    freq_colabs = sorted([(v,k) for k,v in coauthors[name].items() if v >= 4],reverse=True)\n",
    "    if len(colabs) > 0:\n",
    "        author_results[name]['mostCoauthorName'] = unidecode(colabs[0][1])\n",
    "        author_results[name]['mostCoauthorTimes'] = colabs[0][0]\n",
    "        new_set.add(colabs[0][1])\n",
    "    else:\n",
    "        author_results[name]['mostCoauthorName'] = ''\n",
    "        author_results[name]['mostCoauthorTimes'] = 0\n",
    "\n",
    "    if len(fam_colab) > 0:\n",
    "        author_results[name]['famCoauthorName'] = unidecode(fam_colab[0][1])\n",
    "        new_set.add(fam_colab[0][1])\n",
    "    else:\n",
    "        author_results[name]['famCoauthorName'] = ''\n",
    "\n",
    "    author_results[name]['authorPosition%'] = np.array(author_pos[name]).mean()\n",
    "    author_results[name]['totalCoauth'] = len(colabs)\n",
    "    author_results[name]['freqCoauth (> 3 papers)'] = len(freq_colabs)\n",
    "    author_results[name]['famCoauthFrac'] = sum([_[0] for _ in fam_colab])\n",
    "    author_results[name]['totalCoauthFrac'] = sum([_[0] for _ in colabs])\n",
    "    \n",
    "    author_results[name]['mostPaperConf'] = sorted([(v,k) for k,v in conf_paper_frac[name].items()],reverse=True)[0][1]\n",
    "    author_results[name]['venuesPublishedIn'] = len(conf_paper_frac[name].items())\n",
    "    author_results[name]['pageRank'] = pr_full[idx]\n",
    "    #author_results[name]['pageRankRI'] = pr_ri[idx]\n",
    "    \n",
    "    \n",
    "    author_results[name]['numPapers'] = paper_num[name]\n",
    "    author_results[name]['numPapersFrac'] = paper_frac[name]\n",
    "\n",
    "\n",
    "    author_results[name]['YearlyScore (1/n)'] = scoreV['1/n_total_1970'][idx]/scoreV['working_years'][idx]\n",
    "    author_results[name]['YearlyScore (Full)'] = scoreV['full_total_1970'][idx]/scoreV['working_years'][idx]\n",
    "    author_results[name]['Score (1/n)'] = scoreV['1/n_total_1970'][idx]\n",
    "    author_results[name]['Score (Full)'] = scoreV['full_total_1970'][idx]\n",
    "    \n",
    "    author_results[name]['MaxScore'] = scoreV['1/i_max'][idx]\n",
    "    author_results[name]['MaxScore (1/n)'] = scoreV['1/n_max'][idx]\n",
    "    author_results[name]['MaxScore (Full)'] = scoreV['full_max'][idx]\n",
    "    \n",
    "    author_results[name]['BestYear'] = scoreV['1/i_max_yr'][idx]\n",
    "    author_results[name]['BestYear (1/n)'] = scoreV['1/n_max_yr'][idx]\n",
    "    author_results[name]['BestYear (Full)'] = scoreV['full_max_yr'][idx]\n",
    "    \n",
    "    for i,n in enumerate(['_apmFalse', '_apmTrue',  'pw_apmFalse', 'pw_apmTrue', 'pweff_apmFalse', 'pweff_apmTrue', 'pwunk_apmFalse','pwunk_apmTrue']):\n",
    "        author_results[name]['Adv'+str(i+1)] =  scoreV[n][idx]\n",
    "results_list = []\n",
    "for k,v in author_results.items():\n",
    "    v['Name'] = k\n",
    "    results_list.append(v)\n",
    "def_order = list(author_results[list(author_results.keys())[0]].keys())\n",
    "df_results = pd.DataFrame(results_list)[def_order].set_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[[_ for _ in df_results.columns if 'Adv!' not in _]].sort_values('Adv1',0,False).style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
