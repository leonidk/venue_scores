{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv\n",
    "import scipy.sparse\n",
    "Xauth = None\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_affil = pd.read_csv('faculty-affiliations.csv')\n",
    "ranks = pd.read_csv('other_ranks/ranks.csv')\n",
    "def csv2dict_str_str(fname):\n",
    "    with open(fname, mode='r') as infile:\n",
    "        rdr = csv.reader(infile)\n",
    "        d = {rows[0].strip(): rows[1].strip() for rows in rdr}\n",
    "    return d\n",
    "alias_dict = csv2dict_str_str('dblp-aliases.csv')\n",
    "alias_dict_values = set(alias_dict.values())\n",
    "alias_dict_keys = set(alias_dict.keys())\n",
    "faculty_affil_set = set(faculty_affil.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pickle.load(gzip.open('parsed_files.pkl.gz','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = papers[0]\n",
    "print(papers[0],len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "copyfile('dblp-aliases.csv', 'dblp-aliases-expanded.csv')\n",
    "more_aliases = pickle.load(gzip.open('dblp_aliases_auto.pkl.gz','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dblp-aliases-expanded.csv','at') as fp:\n",
    "    for names in more_aliases:\n",
    "        # does it exist as a target\n",
    "        exists = [_ in alias_dict_values for _ in names]\n",
    "        # does it exist as an affiliation\n",
    "        exists_affil = [_ in faculty_affil_set for _ in names]\n",
    "        # does it have a number in it\n",
    "        has_nonumbers = [(not _.split(' ')[-1].isdigit()) for _ in names]\n",
    "\n",
    "        # last priority default is the first name\n",
    "        true_name = names[0]\n",
    "        \n",
    "        # can we use the names for stuff\n",
    "        take_from_affil = sum(exists_affil) > 0\n",
    "        take_from_alias = sum(exists) > 0\n",
    "        take_from_alpha = sum(has_nonumbers) > 0\n",
    "        \n",
    "        # second last option is a non-numbered alias\n",
    "        if not has_nonumbers[0] and take_from_alpha:\n",
    "            true_name = [_ for _ in names if (not _.split(' ')[-1].isdigit())][0]\n",
    "        # second option is an affiliation\n",
    "        if take_from_affil:\n",
    "            true_name = [_ for _ in names if _ in faculty_affil_set][0]\n",
    "        # top option is an existing alias target \n",
    "        if take_from_alias:\n",
    "            true_name = [_ for _ in names if _ in alias_dict_values][0]\n",
    "        \n",
    "        # if there is no affiliation, no need for this alias\n",
    "        #if not take_from_affil:\n",
    "        #    continue\n",
    "        \n",
    "        for name in names:\n",
    "            # don't need an alias for the true name\n",
    "            if name == true_name:\n",
    "                continue\n",
    "            # only to existing faculty\n",
    "            #if name in exists_affil:\n",
    "            #    continue\n",
    "            # it doesn't already exist as a source or target\n",
    "            if not ( (name in alias_dict_keys) or (name in alias_dict_values) ):\n",
    "                fp.write('{},{}\\r\\n'.format(name,true_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliasdict = csv2dict_str_str('dblp-aliases-expanded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "informal_venues = {}\n",
    "total_venues = {}\n",
    "pubtypes = {}\n",
    "pagecounts = {}\n",
    "conf_ambiguity = defaultdict(dict)\n",
    "for paper in papers:\n",
    "    tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    total_venues[venue] = 1 + total_venues.get(venue,0)\n",
    "    pagecounts[pages] = 1 + pagecounts.get(pages,0)\n",
    "    pubtypes[publtype] = 1\n",
    "    if publtype is not None:\n",
    "        informal_venues[venue] = 1 + informal_venues.get(venue,0)\n",
    "    if url != '':\n",
    "        key = '/'.join(url.split('/')[:3])\n",
    "        conf_ambiguity[key][venue] = 1 + conf_ambiguity[key].get(venue,0)\n",
    "\n",
    "frac_informal_venues = {k:v/total_venues[k] for k,v in informal_venues.items()}\n",
    "skip_venues = {k:v for k,v in frac_informal_venues.items() if v > 0.5 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_venues = {}\n",
    "year_mappings = {}\n",
    "for k in conf_ambiguity:\n",
    "    venues = [_ for _ in conf_ambiguity[k] if (not '@' in _.lower())]\n",
    "    venues = [_ for _ in venues if (not 'workshop' in _.lower())]\n",
    "    venues = [_ for _ in venues if (not 'companion' in _.lower())]\n",
    "    venues = [_ for _ in venues if (not 'adjunct' in _.lower())]\n",
    "    venues = [_ for _ in venues if (not 'selected' in _.lower())]\n",
    "    venues = [_ for _ in venues if (not 'poster' in _.lower())]\n",
    "    venues = [_ for _ in venues if (not 'doctoral consortium' in _.lower())]\n",
    "    venues = [_ for _ in venues if (not 'short' in _.lower())]\n",
    "\n",
    "    if len(venues) > 1:\n",
    "        if 'db/series/' in k:\n",
    "            for v in venues:\n",
    "                combine_venues[v] = k\n",
    "        else:\n",
    "            if '/' in k:\n",
    "                if k not in year_mappings:\n",
    "                    year_mappings[k] = {}\n",
    "                for v in venues:\n",
    "                    year_mappings[k][v] = np.zeros(50)\n",
    "                print(\"'\" + k +\"':\",venues,\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_urls  = {}\n",
    "for paper in papers:\n",
    "    tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "\n",
    "    if url != '':\n",
    "        key = '/'.join(url.split('/')[:3])\n",
    "        venue_set = venue_urls.get(venue,set())\n",
    "        venue_set.add(key)\n",
    "        venue_urls[venue] = venue_set\n",
    "        \n",
    "        if key in year_mappings:\n",
    "            if venue in year_mappings[key]:\n",
    "                year_mappings[key][venue][np.clip(year,1970,2019)-1970] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_url_counts = {k:len(v) for k,v in venue_urls.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_aliases = {}\n",
    "\n",
    "for url_key,url_val in year_mappings.items():\n",
    "    if (np.sum([v for k,v in url_val.items()],0) <= 1).sum()  == 50 \\\n",
    "    and sum([venue_url_counts[v] for v in url_val]) == len(url_val):\n",
    "        print(url_key)\n",
    "        print(url_val.keys())\n",
    "        print([v.sum() for k,v in url_val.items()])\n",
    "        print([np.argmax(v[::-1]) for k,v in url_val.items()])\n",
    "        name = sorted([(v.sum(),k) for k,v in url_val.items()])[-1][1]\n",
    "        if max([v.sum() for k,v in url_val.items()]) == 1:\n",
    "            name = url_key[3:]\n",
    "        print(name)\n",
    "        for k in url_val:\n",
    "            conf_aliases[k] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_ambiguity['db/conf/icadl']#TPDL,ICADL\n",
    "#combine_venues\n",
    "conf_aliases['IESA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for paper in papers:\n",
    "        tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "        if 'IEEE Trans. Vis. Comput. Graph.' in venue:\n",
    "            #print(year,title,'\\n',venue)\n",
    "            print(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted([(v,k,frac_informal_venues[k]) for k,v in informal_venues.items()],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pubtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_toofew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_papers = []\n",
    "all_venues = set()\n",
    "all_authors = set()\n",
    "for paper in papers:\n",
    "    tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    # these seem like.. not helpful..\n",
    "    # should either combine them or drop them. combine_venues for combine. this for drop\n",
    "    if 'db/series/' in url:\n",
    "        continue\n",
    "    # these seem like noise?\n",
    "    if 'db/conf/dagstuhl/' in url:\n",
    "        continue\n",
    "    if 'db/conf/dimacs/' in url:\n",
    "        continue\n",
    "    if 'db/conf/ac/' in url:\n",
    "        continue\n",
    "    #if 'db/conf/ifip' in url: # that's not a typo!\n",
    "    #    continue\n",
    "    if 'db/conf/birthday/' in url:\n",
    "        continue\n",
    "    if 'db/books/collections/' in url:\n",
    "        continue\n",
    "    venue = conf_aliases.get(venue,venue)\n",
    "    #if venue == 'IEEE Trans. Vis. Comput. Graph.':\n",
    "    #    print(paper)\n",
    "    #    print(publtype is None,venue not in skip_venues,(pages != 0 or (not eb_toofew)),tag != 'incollection',not eb_skip,year >= 1970,year < 2020,(pages==-1 or pages >=4 or (not eb_toofew)),(pages <= 100 or (not eb_toofew)))\n",
    "    if publtype is None and venue not in skip_venues and (pages != 0 or (not eb_toofew)) and tag != 'incollection' and not eb_skip \\\n",
    "                        and year >= 1970 and year < 2020 and (pages==-1 or pages >=4 or (not eb_toofew)) and (pages <= 100 or (not eb_toofew)):\n",
    "        authors = [aliasdict.get(a,a) for a in authors]\n",
    "        for a in authors:\n",
    "            all_authors.add(a)\n",
    "        all_venues.add(venue)\n",
    "        #if venue == 'IEEE Trans. Vis. Comput. Graph.':\n",
    "        #    print(paper)\n",
    "        useful_papers.append((tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_venues),len(all_authors),len(useful_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_venues = sorted(list(all_venues))\n",
    "all_authors = sorted(list(all_authors))\n",
    "useful_papers = sorted(useful_papers,key = lambda paper: (paper[6],paper[3])) #sort by year,conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_idx = {v:i for i,v in enumerate(all_venues)}\n",
    "name_idx = {v:i for i,v in enumerate(all_authors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('useful_venue_list.pkl.gz','wb') as fp:\n",
    "    pickle.dump(all_venues,fp,-1)\n",
    "with gzip.open('useful_authors_list.pkl.gz','wb') as fp:\n",
    "    pickle.dump(all_authors,fp,-1)\n",
    "with gzip.open('useful_papers.pkl.gz','wb') as fp:\n",
    "    pickle.dump(useful_papers,fp,-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
