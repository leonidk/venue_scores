{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import zipfile\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsf data\n",
    "df2 = pd.read_pickle('nsf2.pkl')\n",
    "df = pd.read_pickle('nsf.pkl')\n",
    "Xauth=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the big paper thing\n",
    "papers = pd.read_hdf('papers.h5','table')\n",
    "unique_names = pickle.load(open('big_names.pkl','rb'))\n",
    "unique_confs = pickle.load(open('confs.pkl','rb'))\n",
    "\n",
    "faculty_affil = pd.read_csv('faculty-affiliations.csv')\n",
    "ranks = pd.read_csv('ranks.csv')\n",
    "def csv2dict_str_str(fname):\n",
    "    with open(fname, mode='r') as infile:\n",
    "        rdr = csv.reader(infile)\n",
    "        d = {rows[0].strip(): rows[1].strip() for rows in rdr}\n",
    "    return d\n",
    "aliasdict = csv2dict_str_str('dblp-aliases.csv')\n",
    "conf_idx = pickle.load(open('conf_idx.pkl','rb'))\n",
    "name_idx = pickle.load(open('name_idx.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsf_paper_n, _ = df2.shape\n",
    "nsf_paper_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter,defaultdict\n",
    "# create or load some author data\n",
    "def dd():\n",
    "    return defaultdict(list)\n",
    "if True:\n",
    " \n",
    "    author_papers = defaultdict(dd)\n",
    "\n",
    "    for row in papers.itertuples():\n",
    "        paper_year = row[10]\n",
    "        conf = row[2]\n",
    "        n = row[4]\n",
    "        authors = row[3]\n",
    "        for a in authors:\n",
    "            split_name = a.split(' ')\n",
    "            first_last = split_name[0] +' ' + split_name[-1]\n",
    "            author_papers[first_last][paper_year].append((conf,n))\n",
    "    import pickle\n",
    "    with open('nsf_auth.pkl','wb') as fp:\n",
    "        pickle.dump(author_papers,fp)\n",
    "else:\n",
    "    with open('nsf_auth.pkl','rb') as fp:\n",
    "        author_papers = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddn():\n",
    "    return defaultdict(int)\n",
    "author_amounts = defaultdict(ddn)\n",
    "for i,row in enumerate(df2.itertuples()):\n",
    "    authors, year, amount = row[3],row[4],row[5]\n",
    "    # some infinite amounts exist! bad!\n",
    "    if not np.isfinite(amount):\n",
    "        continue\n",
    "    for a in authors:\n",
    "        split_name = a.split(' ')\n",
    "        first_last = split_name[0] +' ' + split_name[-1]\n",
    "        for yr in range(int(year),2020):\n",
    "            author_amounts[first_last][yr] += min(amount/len(a),3e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create design mattrix\n",
    "X = scipy.sparse.dok_matrix((nsf_paper_n,unique_confs.shape[0]))\n",
    "xdict = {}\n",
    "y = np.zeros(nsf_paper_n,dtype=np.float32)\n",
    "for i,row in enumerate(df2.itertuples()):\n",
    "    authors, year, amount = row[3],row[4],row[5]\n",
    "    # some infinite amounts exist! bad!\n",
    "    \n",
    "    if not np.isfinite(amount):\n",
    "        continue\n",
    "    # maybe the old years are misleading!?\n",
    "    #if year < 2002:\n",
    "    #    continue\n",
    "    # small grants are misleading? 150000\n",
    "    if amount < 1000: #50000\n",
    "        continue\n",
    "    # giant grants are msileading?\n",
    "    if amount >= 1e9: #5e7\n",
    "        continue\n",
    "    #print(len(authors),sum([(a in author_papers) for a in authors]))\n",
    "    #print(a)\n",
    "    if len(authors)*0.5 <= sum([(a in author_papers) for a in authors]):\n",
    "        y[i] = sum([author_amounts[first_last][year] for first_last in authors]) #or amount!?\n",
    "        for a in authors:\n",
    "            for year_a,conf_list in author_papers[a].items():\n",
    "                if year_a <= year:\n",
    "                    for paper in conf_list:\n",
    "                        #if paper[0] in noisey_crap:\n",
    "                        #    continue\n",
    "                        if paper[0] == 'CoRR':\n",
    "                            continue\n",
    "                        j = conf_idx[paper[0]]\n",
    "                        xdict[(i,j)] = 1/paper[1]\n",
    "X._update(xdict)\n",
    "y_orig = np.copy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_orig = np.copy(y)\n",
    "print((y_orig > 0).sum())\n",
    "y = np.copy(y_orig)\n",
    "#y[y > 2e6] = 2e6\n",
    "#y[y == 0] = y.mean()\n",
    "from matplotlib.pyplot import figure,hist\n",
    "hist((y-y.mean())/y.std(),100)\n",
    "figure()\n",
    "_ = hist(np.log(y+1),100)\n",
    "figure()\n",
    "logy = np.log(y+1)\n",
    "print(logy.mean())\n",
    "um = logy[logy!=np.log(1)].mean()\n",
    "us = logy[logy!=np.log(1)].std()\n",
    "_ = hist((logy[logy!=np.log(1)]-um)/us,100)\n",
    "\n",
    "figure()\n",
    "logy[logy==np.log(1)] = np.mean(logy[logy!=np.log(1)])\n",
    "#logy[logy == 0] = logy.mean()\n",
    "_ = hist((logy[logy!=logy.mean()]-logy.mean())/logy.std(),100)\n",
    "print(logy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X = scipy.sparse.csr_matrix(X)\n",
    "clf = SGDRegressor('huber',tol=1e-9,max_iter=250,verbose=1,penalty='l2',alpha=1e-6,epsilon=0.01,average=True)\n",
    "clf.fit(X,(logy[logy!=logy.mean()]-logy.mean())/logy.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_ord = np.argsort(np.squeeze(clf.coef_))\n",
    "conf_choice = ['SIGGRAPH','3DV','HRI','ECCV (8)','ECCV (1)','Comput. Graph. Forum','Shape Modeling International','Symposium on Geometry Processing',' Computer Aided Geometric Design','ICLR','I. J. Robotics Res.','CVPR','International Journal of Computer Vision','Robotics: Science and Systems','ICRA','WACV','ICML','AISTATS','CoRR','SIGGRAPH Asia','ECCV','ICCV','ISER','Humanoids','3DV','IROS','CoRL','Canadian Conference on AI','ACCV ','Graphics Interface','CRV','BMVC']\n",
    "ri_confs = np.zeros(len(unique_confs))\n",
    "print(clf.intercept_)\n",
    "for i in range(len(unique_confs)):\n",
    "    idx = conf_ord[-(i+1)]\n",
    "    conf_name = unique_confs[idx]\n",
    "    conf_score = clf.coef_[idx]\n",
    "    if conf_name in conf_choice:\n",
    "        ri_confs[idx] = 1\n",
    "    if conf_name in conf_choice:\n",
    "    #if 'ICCV' in conf_name and (idx%year_ind)==4:\n",
    "        print('{},{:.4f}'.format(conf_name,100*conf_score))\n",
    "ri_confs.shape,ri_confs.sum(),X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(clf.coef_,100)\n",
    "print((clf.coef_ > 0.07).sum())\n",
    "noisey_crap2 = set([unique_confs[i] for i,_ in enumerate(clf.coef_ > 0.07) if _])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = X.T.sum(1)\n",
    "[x1[conf_idx[n]] for n in noisey_crap2],noisey_crap2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noisey_crap = noisey_crap.union(noisey_crap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noisey_crap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Xauth is None or (Xauth.shape[1] != unique_confs.shape[0]):  \n",
    "    Xauth = scipy.sparse.dok_matrix((len(unique_names),unique_confs.shape[0]))\n",
    "    xdict = {}\n",
    "    auth_years = np.ones((len(unique_names),2)) * np.array([3000,1000]) \n",
    "    for row in papers.itertuples():\n",
    "        paper_year = row[10]\n",
    "\n",
    "        conf = row[2]\n",
    "        n = row[4]\n",
    "        authors = row[3]\n",
    "        j = conf_idx[conf]\n",
    "        for a in authors:\n",
    "            i = name_idx[a]\n",
    "            xdict[(i,j)] = 1/n + xdict.get((i,j),0)\n",
    "            auth_years[i,0] = min(auth_years[i,0],paper_year)\n",
    "            auth_years[i,1] = max(auth_years[i,1],paper_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xauth.updatedate(xdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clf.predict(Xauth) - np.squeeze(clf.intercept_)\n",
    "years_working = (1+auth_years[:,1]-auth_years[:,0])\n",
    "value_scores = scores\n",
    "norm_scores = (value_scores)/years_working\n",
    "ri_filter_mat = scipy.sparse.diags(ri_confs)\n",
    "ri_scores = clf.predict(Xauth.dot(ri_filter_mat))-np.squeeze(clf.intercept_)\n",
    "ri_norm_scores = ri_scores/years_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_cand = ['Pulkit Agrawal',\n",
    " 'Joydeep Biswas',\n",
    " 'Katherine L. Bouman',\n",
    " 'David Braun',\n",
    " 'Jia Deng',\n",
    " 'Naomi T. Fitter',\n",
    " 'David F. Fouhey',\n",
    " 'Saurabh Gupta',\n",
    " 'Judy Hoffman',\n",
    " 'Hanbyul Joo',\n",
    " 'Honglak Lee',\n",
    " 'Changliu Liu',\n",
    " 'Petter Nilsson',\n",
    " \"Matthew O'Toole\",\n",
    " 'Alessandro Roncone',\n",
    " 'Alanson P. Sample',\n",
    " 'Manolis Savva',\n",
    " 'Adriana Schulz',\n",
    " 'Amy Tabb',\n",
    " 'Fatma Zeynep Temel',\n",
    " 'Long Wang',\n",
    " 'Cathy Wu',\n",
    " 'Ling-Qi Yan']\n",
    "print('{:20s}\\t{:4s}\\t{:4s}\\t{:4s}\\t{}'.format('name','rate','total','ri','years'))\n",
    "for ns, name in sorted([(value_scores[name_idx[ni]],ni) for ni in prev_cand],reverse=True):\n",
    "    ni = name_idx[name]\n",
    "    print('{:20s}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.0f}'.format(name,100*norm_scores[ni],100*value_scores[ni],100*ri_scores[ni],years_working[ni]))\n",
    "print('')\n",
    "curious_names = ['Xiaolong Wang 0004','Judy Hoffman','Kumar Shaurya Shankar','Leonid Keselman',\n",
    "                 'Nicholas Rhinehart','Roie Levin',\n",
    "                 'Humphrey Hu',\n",
    "                 'David F. Fouhey',\n",
    "                 'Lerrel Pinto','Hunter Goforth',\n",
    "                 'Justin Johnson',\n",
    "                 'Amir Roshan Zamir','Paris Siminelakis',\n",
    "                 'Brian Okorn','David Held']\n",
    "print('{:20s}\\t{:4s}\\t{:4s}\\t{:4s}\\t{}'.format('name','rate','total','ri','years'))\n",
    "for _,name in sorted([(value_scores[name_idx[_]],_) for _ in curious_names],reverse=True):\n",
    "    ni = name_idx[name]\n",
    "    print('{:20s}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.0f}'.format(name,100*norm_scores[ni],100*value_scores[ni],100*ri_scores[ni],years_working[ni]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n best overall \\n')\n",
    "cmu_scores = []\n",
    "\n",
    "best_scores = np.argsort(norm_scores)[::-1]\n",
    "#print(best_scores.shape,unique_names[best_scores[0]])\n",
    "fa_list = list(faculty_affil.name)\n",
    "fa_a_list = list(faculty_affil.affiliation)\n",
    "uni_names = [unique_names[i] for i in best_scores[:8000]]\n",
    "for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "    if name in name_idx:\n",
    "        uni = 'unknown'\n",
    "        if name in fa_list:\n",
    "            uni = fa_a_list[fa_list.index(name)]\n",
    "        if name not in []:#['Jacob Walker','Justin Johnson','Pieter Abbeel','Martial Hebert','Jessica K. Hodgins','Abhinav Gupta','Christopher G. Atkeson','Tom M. Mitchell','Matthew T. Mason']:\n",
    "            if years_working[name_idx[name]] < 3:\n",
    "                continue\n",
    "            if years_working[name_idx[name]] > 8:\n",
    "                continue\n",
    "            #if ri_scores[name_idx[name]] < 0.034:\n",
    "            #    continue\n",
    "            if auth_years[name_idx[name],1] < 2016:\n",
    "                continue\n",
    "        #if (np.array(X[name_idx[name],:].todense()) * ri_confs).sum() == 0:\n",
    "        #    continue\n",
    "        #print(name,auth_years[name_idx[name]])\n",
    "        score = norm_scores[name_idx[name]]\n",
    "        ri_vscore = ri_norm_scores[name_idx[name]]\n",
    "        vscore = value_scores[name_idx[name]]\n",
    "        cmu_scores.append((vscore,ri_scores[name_idx[name]],score,uni,name,auth_years[name_idx[name]],ri_vscore))\n",
    "    else:\n",
    "        pass\n",
    "        #print(name)\n",
    "        ri_norm_scores\n",
    "print('{:22s}\\t{:15s}\\t{:5s}\\t{:3s}\\t{:4s}\\t{:4s}\\t{} {}'.format('name','uni','rate','RI-t','total','RI-r','start','end'))\n",
    "for vs,ris,s,u,p,yrs,rir in sorted(cmu_scores,reverse=True):\n",
    "    print('{:22s}\\t{:15s}\\t{:.3f}\\t{:.1f}\\t{:.2f}\\t{:.2f}\\t{} {}'.format(p[:22],u[:15],s*100,ris*100,vs*100,rir*100,int(yrs[0]),int(yrs[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xauth[name_idx['Stan Melax']].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xauth[name_idx['Leonid Keselman']].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_confs[12154]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_faculty = faculty_affil[faculty_affil.affiliation == 'Carnegie Mellon University'] #Carnegie Mellon University\n",
    "uni_names = np.array(uni_faculty.name)\n",
    "uni_names = list(uni_names) + ['Dieter Fox','Nicholas Rhinehart','Jacob Walker','Lerrel Pinto','Brian Okorn','Leonid Keselman','Siddharth Ancha','Humphrey Hu']\n",
    "cmu_scores = []\n",
    "#uni_names = [unique_names[i] for i in (np.argsort(value_scores)[::-1])[:20]]\n",
    "for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "    if name in name_idx:\n",
    "        #if ri_scores[name_idx[name]] < 2.5:\n",
    "        #    continue\n",
    "        score = value_scores[name_idx[name]]\n",
    "        cmu_scores.append((score,name))\n",
    "    else:\n",
    "        pass\n",
    "        #print(name)\n",
    "for s,p in sorted(cmu_scores,reverse=True):\n",
    "    print('{:30s}\\t\\t{:.3f}'.format(p,s*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 50\n",
    "for i in range(top_k):\n",
    "    idx = conf_ord[-(i+1)]\n",
    "    conf_name = unique_confs[idx]\n",
    "    conf_score = clf.coef_[idx]\n",
    "    print('{:30s}\\t{:.1f}'.format(conf_name[:25],100*conf_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
