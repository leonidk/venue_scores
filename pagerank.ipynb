{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import zipfile\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('useful_venue_list.pkl.gz','rb') as fp:\n",
    "    all_venues = pickle.load(fp)\n",
    "with gzip.open('useful_authors_list.pkl.gz','rb') as fp:\n",
    "    all_authors = pickle.load(fp)\n",
    "with gzip.open('useful_papers.pkl.gz','rb') as fp:\n",
    "    all_papers = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_idx = {v:i for i,v in enumerate(all_venues)}\n",
    "name_idx = {v:i for i,v in enumerate(all_authors)}\n",
    "n_confs = len(all_venues)\n",
    "n_auths = len(all_authors)\n",
    "r1_confs = pickle.load(open('old_version/r1_confs.pkl','rb'))\n",
    "r1_confs_dict = {_:1 for _ in r1_confs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_affil = pd.read_csv('faculty-affiliations.csv')\n",
    "def csv2dict_str_str(fname):\n",
    "    with open(fname, mode='r') as infile:\n",
    "        rdr = csv.reader(infile)\n",
    "        d = {rows[0].strip(): rows[1].strip() for rows in rdr}\n",
    "    return d\n",
    "aliasdict = csv2dict_str_str('dblp-aliases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg(M,alpha=0.85,tol=1e-6,max_iter=1,verbose=False):\n",
    "    N = M.shape[0]\n",
    "    nodelist = np.arange(N)\n",
    "    S = scipy.array(M.sum(axis=1)).flatten()\n",
    "    S[S != 0] = 1.0 / S[S != 0]\n",
    "    Q = scipy.sparse.spdiags(S.T, 0, *M.shape, format='csr')\n",
    "    M = Q * M\n",
    "\n",
    "    # initial vector\n",
    "    x = scipy.repeat(1.0 / N, N)\n",
    "\n",
    "    # Personalization vector\n",
    "    p = scipy.repeat(1.0 / N, N)\n",
    "\n",
    "    # Dangling nodes\n",
    "    dangling_weights = p\n",
    "    is_dangling = scipy.where(S == 0)[0]\n",
    "\n",
    "    # power iteration: make up to max_iter iterations\n",
    "    for _ in range(max_iter):\n",
    "        xlast = x\n",
    "        x = alpha * (x * M + sum(x[is_dangling]) * dangling_weights) + \\\n",
    "            (1 - alpha) * p\n",
    "        # check convergence, l1 norm\n",
    "        err = scipy.absolute(x - xlast).sum()\n",
    "        if verbose:\n",
    "            print(_,err)\n",
    "        if err < N * tol:\n",
    "            return x\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "gauth_auth = scipy.sparse.dok_matrix((n_auths,n_auths))\n",
    "g_auth = {}\n",
    "\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, conf, pages, startPage,paper_year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    n = len(authors)\n",
    "\n",
    "    #if clf[span_years*conf_idx[conf]:span_years*(conf_idx[conf]+1)].max() > 0:\n",
    "    for a,a2 in itertools.product(authors,authors):\n",
    "        auth = aliasdict.get(a,a)\n",
    "        auth2 = aliasdict.get(a2,a2)\n",
    "        if auth in name_idx and auth2 in name_idx:\n",
    "            g_auth[(name_idx[auth],name_idx[auth2])] = 1 + g_auth.get((name_idx[auth],name_idx[auth2]),0)\n",
    "gauth_auth._update(g_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauth_auth = scipy.sparse.csr_matrix(gauth_auth)\n",
    "pr = pg(gauth_auth,max_iter=100,verbose=True,tol=1e-12)\n",
    "print(gauth_auth.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_s = np.argsort(pr)[::-1]\n",
    "top_k = 100\n",
    "i = 0\n",
    "j = 0 \n",
    "while i < top_k:\n",
    "    j += 1\n",
    "    idx = pr_s[j]\n",
    "    #if(ri_scores[idx]/rs < 20.0):\n",
    "    #    continue\n",
    "    print(all_authors[idx],pr[idx])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(pr,open('new_pagerank_people.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "auth_confs = defaultdict(set)\n",
    "\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, conf, pages, startPage,paper_year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    n = len(authors)\n",
    "    for a in authors:\n",
    "        auth = aliasdict.get(a,a)\n",
    "        auth_confs[auth].add(conf_idx[conf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_confs = {k: list(v) for k,v in auth_confs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "auth_confs_iter = {k: itertools.combinations_with_replacement(v,2) for k,v in auth_confs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "dconf = dict()\n",
    "\n",
    "gconf_conf = scipy.sparse.dok_matrix((n_confs,n_confs))\n",
    "dconf = {}\n",
    "for k,v in auth_confs_iter.items():\n",
    "    for i,j in v:\n",
    "        tmp = 1 + dconf.get((i,j),0)\n",
    "        dconf[(i,j)] = tmp\n",
    "        if i != j:\n",
    "            dconf[(j,i)] = tmp\n",
    "\n",
    "gconf_conf._update(dconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gconf_conf = scipy.sparse.csr_matrix(gconf_conf)\n",
    "prc = pg(gconf_conf,max_iter=100,verbose=True,tol=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_s = np.argsort(prc)[::-1]\n",
    "top_k = 100\n",
    "i = 0\n",
    "while i < top_k:\n",
    "    idx = prc_s[i]\n",
    "    print(all_venues[idx],prc[idx])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(prc,open('new_pagerank_conf.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
