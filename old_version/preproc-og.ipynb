{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('papers.h5','table')\n",
    "unique_names = pickle.load(open('big_names.pkl','rb'))\n",
    "uniqie_confs = pickle.load(open('confs.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#big_names = np.unique(np.concatenate(df.name))\n",
    "unique_names = pickle.load(open('big_names.pkl','rb'))\n",
    "unique_confs = pickle.load(open('confs.pkl','rb'))\n",
    "faculty_affil = pd.read_csv('faculty-affiliations.csv')\n",
    "ranks = pd.read_csv('ranks.csv')\n",
    "def csv2dict_str_str(fname):\n",
    "    with open(fname, mode='r') as infile:\n",
    "        rdr = csv.reader(infile)\n",
    "        d = {rows[0].strip(): rows[1].strip() for rows in rdr}\n",
    "    return d\n",
    "aliasdict = csv2dict_str_str('dblp-aliases.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, unique_names.shape, unique_confs.shape,faculty_affil.shape, ranks.shape\n",
    "#unique_names = [str(_) for _ in unique_names]\n",
    "#np.savetxt('names.txt',unique_names,encoding='utf-8',fmt='%s')\n",
    "\n",
    "conf_idx = {}\n",
    "name_idx = {}\n",
    "for i in range(unique_names.shape[0]):\n",
    "    authorName = unique_names[i]\n",
    "    realName = aliasdict.get(authorName, authorName)\n",
    "    name_idx[realName] = i\n",
    "    name_idx[authorName] = i\n",
    "for i in range(unique_confs.shape[0]):\n",
    "    confName = unique_confs[i]\n",
    "    conf_idx[confName] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for name in faculty_affil.affiliation.unique():\n",
    "        if name in list(ranks.uni):\n",
    "            print(',',end='')\n",
    "        else: #print(name)\n",
    "            print(name)\n",
    "            print('.',end='')\n",
    "    for name in faculty_affil.name:\n",
    "        if name in unique_names:\n",
    "            print(',',end='')\n",
    "        else: \n",
    "            print(name)\n",
    "            print('.',end='')\n",
    "ranks[ranks.index < 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = df.year.min()\n",
    "max_year = df.year.max()\n",
    "span_years = max_year - min_year\n",
    "year_blocks = 10\n",
    "offset_years = [(i-min_year)//year_blocks for i in range(min_year,max_year+1)]\n",
    "year_ind = max(offset_years)+1\n",
    "conf_idx = pickle.load(open('conf_idx.pkl','rb'))\n",
    "name_idx = pickle.load(open('name_idx.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "X = scipy.sparse.dok_matrix((len(unique_names),year_ind*unique_confs.shape[0]))\n",
    "auth_years = np.ones((len(unique_names),2)) * np.array([3000,1000]) \n",
    "#y = np.zeros(len(unique_names))#scipy.sparse.dok_matrix((1,len(unique_names)))\n",
    "for index, row in df.iterrows():\n",
    "    paper_year = row['year']\n",
    "    #if row['year'] < 2005:\n",
    "    #    continue\n",
    "    #print(row)\n",
    "    #if row['conf'] == 'CoRR':\n",
    "    #    continue\n",
    "    j = year_ind*conf_idx[row['conf']] + (row['year']-min_year)//year_blocks\n",
    "    for a in row['name']:\n",
    "        i = name_idx[a]\n",
    "        if row['conf'] != 'CoRR':\n",
    "            X[i,j] += 1/row['numauthors']\n",
    "        auth_years[i,0] = min(auth_years[i,0],paper_year)\n",
    "        auth_years[i,1] = max(auth_years[i,1],paper_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(X,open('x.pkl','wb'))\n",
    "#pickle.dump(conf_idx,open('conf_idx.pkl','wb'))\n",
    "#pickle.dump(name_idx,open('name_idx.pkl','wb'))\n",
    "#X_dup = np.copy(X)\n",
    "#for i in range(5):\n",
    "#    j = year_ind*conf_idx['CoRR'] + (i-min_year)//year_blocks\n",
    "#    X[:,j] = 0\n",
    "\n",
    "settings = [-6,'hinge',15,0]\n",
    "settings = [-6, 'hinge', 20, 0.15]\n",
    "#settings = [-8.548444243014805, 'hinge', 25, 0.8315610452033819]\n",
    "#settings = [-8.053796519336224, 'log', 15, 0.04885118622350815]\n",
    "#settings = [-8.305486025332591, 'hinge', 70, 0.8854278179436874]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(len(unique_names))\n",
    "for i in range(settings[2]): #40?\n",
    "    uni_name = ranks.iloc[i]['uni']\n",
    "    uni_faculty = faculty_affil[faculty_affil.affiliation == uni_name]\n",
    "    uni_names = np.array(uni_faculty.name)\n",
    "    for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "        if name in name_idx:\n",
    "            y[name_idx[name]] = 1\n",
    "        else:\n",
    "            pass\n",
    "            #print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape,y.reshape((-1,))\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(settings[1],verbose=1,tol=1e-5,max_iter=100,alpha=10 ** settings[0],penalty='elasticnet',l1_ratio=settings[3])\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('pairwise_tiers.csv','rt') as csvfile:\n",
    "    filereader = csv.reader(csvfile)\n",
    "    conf_pairs = [[t.strip('\\ufeff') for t in _ if len(t)!=0] for _ in filereader]\n",
    "if False:\n",
    "    best_cost = 1000\n",
    "    best_params = []\n",
    "    for itr in range(1000):\n",
    "        alpha = np.random.uniform(-9,-3)\n",
    "        hinge_log = 'hinge' if np.random.rand() < 0.5 else 'log'\n",
    "        uni_rank = int(round(np.exp(np.random.uniform(np.log(5),np.log(125)))))\n",
    "        l1r = np.random.rand()\n",
    "        \n",
    "        y = np.zeros(len(unique_names))\n",
    "        for i in range(uni_rank): #40?\n",
    "            uni_name = ranks.iloc[i]['uni']\n",
    "            uni_faculty = faculty_affil[faculty_affil.affiliation == uni_name]\n",
    "            uni_names = np.array(uni_faculty.name)\n",
    "            for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "                if name in name_idx:\n",
    "                    y[name_idx[name]] = 1\n",
    "                else:\n",
    "                    pass\n",
    "                    #print(name)\n",
    "        #X.shape,y.reshape((-1,))\n",
    "        \n",
    "        from sklearn.linear_model import SGDClassifier\n",
    "        clf = SGDClassifier(hinge_log,verbose=0,tol=1e-5,max_iter=50,alpha= 10 ** alpha,penalty='elasticnet',l1_ratio=l1r)\n",
    "        clf.fit(X,y)\n",
    "\n",
    "        classifier_cost = 0\n",
    "        conf_ord = np.argsort(np.squeeze(clf.coef_))\n",
    "        conf_rank_dict = {}\n",
    "        for i in range(len(unique_confs)*year_ind):\n",
    "            idx = conf_ord[-(i+1)]\n",
    "            conf_name = unique_confs[idx//year_ind]\n",
    "            conf_score = clf.coef_[0,idx]\n",
    "            if idx%year_ind < 3:\n",
    "                continue\n",
    "            conf_rank_dict[conf_name] = i\n",
    "        pair_len = len(conf_pairs)//2\n",
    "        neg_top = 0\n",
    "        for i in range(pair_len):\n",
    "            better = conf_pairs[2*i]\n",
    "            worse = conf_pairs[2*i+1]\n",
    "            #print(better,worse)\n",
    "            for b in better:\n",
    "                neg_top += clf.coef_[0,conf_idx[b]*year_ind+4] < 0\n",
    "                for w in worse:\n",
    "                    classifier_cost += conf_rank_dict[w] < conf_rank_dict[b]\n",
    "                    #if  conf_rank_dict[w] < conf_rank_dict[b]:\n",
    "                    #    print(w,conf_rank_dict[w],'\\t',b,conf_rank_dict[b])\n",
    "        all_choices = clf.decision_function(X)\n",
    "        frac_correct = (all_choices[y.astype(np.bool)] > 0).sum()\n",
    "        print(classifier_cost,[alpha,hinge_log,uni_rank,l1r],frac_correct/y.sum(),neg_top)\n",
    "        if classifier_cost < best_cost:\n",
    "            best_cost = classifier_cost\n",
    "            best_params = [alpha,hinge_log,uni_rank,l1r]\n",
    "            #print(best_cost,best_params)\n",
    "            #8 [-3.5003506670165976, 'log', 21]\n",
    "            #10 [-3.0421236321136265, 'log', 47]\n",
    "            #11 [-3.954162400006843, 'log', 109]\n",
    "else:\n",
    "    classifier_cost = 0\n",
    "    conf_ord = np.argsort(np.squeeze(clf.coef_))\n",
    "    conf_rank_dict = {}\n",
    "    for i in range(len(unique_confs)*year_ind):\n",
    "        idx = conf_ord[-(i+1)]\n",
    "        conf_name = unique_confs[idx//year_ind]\n",
    "        conf_score = clf.coef_[0,idx]\n",
    "        if idx%year_ind < 3:\n",
    "            continue\n",
    "        conf_rank_dict[conf_name] = i\n",
    "    pair_len = len(conf_pairs)//2\n",
    "    for i in range(pair_len):\n",
    "        better = conf_pairs[2*i]\n",
    "        worse = conf_pairs[2*i+1]\n",
    "        #print(better,worse)\n",
    "        mul = 1\n",
    "        for b in better:\n",
    "            if b == 'Robotics: Science and Systems':\n",
    "                mul = 1\n",
    "            for w in worse:\n",
    "                classifier_cost += mul*(conf_rank_dict[w] < conf_rank_dict[b])\n",
    "                if conf_rank_dict[w] < conf_rank_dict[b]:\n",
    "                    print(w,conf_rank_dict[w],'\\t',b,conf_rank_dict[b])\n",
    "\n",
    "    all_choices = clf.decision_function(X)\n",
    "    frac_correct = (all_choices[y.astype(np.bool)] > 0).sum()\n",
    "    print(classifier_cost,settings,frac_correct/y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_choices > 0).sum(),y.sum(),(all_choices[y.astype(np.bool)] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_choice = ['SIGGRAPH','HRI','ECCV (8)','ECCV (1)','Comput. Graph. Forum','Shape Modeling International','Symposium on Geometry Processing',' Computer Aided Geometric Design','ICLR','NIPS','AAAI','I. J. Robotics Res.','CVPR','International Journal of Computer Vision','Robotics: Science and Systems','ICRA','WACV','ICML','AISTATS','CoRR','SIGGRAPH Asia','ECCV','ICCV','ISER','Humanoids','3DV','IROS','CoRL','Canadian Conference on AI','ACCV ','Graphics Interface','CRV','BMVC']\n",
    "ri_confs = np.zeros(len(unique_confs)*year_ind)\n",
    "print(clf.intercept_)\n",
    "for i in range(len(unique_confs)*year_ind):\n",
    "    idx = conf_ord[-(i+1)]\n",
    "    conf_name = unique_confs[idx//year_ind]\n",
    "    conf_score = clf.coef_[0,idx]\n",
    "    if conf_name in conf_choice:\n",
    "        ri_confs[idx] = 1\n",
    "    if conf_name in conf_choice and (idx%year_ind)==4:\n",
    "    #if 'ICCV' in conf_name and (idx%year_ind)==4:\n",
    "        print('{},{:.3f}'.format(conf_name + '_' + str(((idx%year_ind)+7)*10)[-2:] + 's',conf_score))\n",
    "ri_confs.shape,ri_confs.sum(),X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clf.decision_function(X)\n",
    "years_working = (1+auth_years[:,1]-auth_years[:,0])\n",
    "value_scores = scores -  clf.intercept_[0]\n",
    "norm_scores = (value_scores)/years_working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_filter_mat = scipy.sparse.diags(ri_confs)\n",
    "ri_scores = clf.decision_function(X.dot(ri_filter_mat))-clf.intercept_[0]\n",
    "ri_norm_scores = ri_scores/years_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faculty_affil[faculty_affil.affiliation == 'UCBerkeley']\n",
    "#faculty_affil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    uni_faculty = faculty_affil[faculty_affil.affiliation == 'Carnegie Mellon University'] #Carnegie Mellon University\n",
    "    uni_names = np.array(uni_faculty.name)\n",
    "    uni_names = list(uni_names) + ['Jacob Walker','Lerrel Pinto','Brian Okorn','Leonid Keselman','Siddharth Ancha']\n",
    "    cmu_scores = []\n",
    "    for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "        if name in name_idx:\n",
    "            #if ri_scores[name_idx[name]] < 2.5:\n",
    "            #    continue\n",
    "            score = scores[name_idx[name]]\n",
    "            cmu_scores.append((score,name))\n",
    "        else:\n",
    "            pass\n",
    "            #print(name)\n",
    "    for s,p in sorted(cmu_scores,reverse=True):\n",
    "        print('{:20s}\\t{:.1f}'.format(p,s))\n",
    "    print('\\nvalue based!\\n')\n",
    "    cmu_scores = []\n",
    "    for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "        if name in name_idx:\n",
    "            #print(name,auth_years[name_idx[name]])\n",
    "            score = (scores[name_idx[name]]-clf.intercept_)[0]/(1+auth_years[name_idx[name],1]-auth_years[name_idx[name],0])\n",
    "            #if ri_scores[name_idx[name]] < 2.5:\n",
    "            #    continue \n",
    "            cmu_scores.append((score, value_scores[name_idx[name]] ,name))\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "            #print(name)\n",
    "    for s,rs,p in sorted(cmu_scores,reverse=True):\n",
    "        print('{:20s}\\t{:.1f}\\t{:.1f}'.format(p,rs,s))\n",
    "\n",
    "if True:\n",
    "    print('\\n best overall \\n')\n",
    "    cmu_scores = []\n",
    "\n",
    "    best_scores = np.argsort(norm_scores)[::-1]\n",
    "    #print(best_scores.shape,unique_names[best_scores[0]])\n",
    "    fa_list = list(faculty_affil.name)\n",
    "    fa_a_list = list(faculty_affil.affiliation)\n",
    "    uni_names = [unique_names[i] for i in best_scores[:50000]]\n",
    "    for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "        if name in name_idx:\n",
    "            uni = 'unknown'\n",
    "            if name in fa_list:\n",
    "                uni = fa_a_list[fa_list.index(name)]\n",
    "            if name not in []:#['Jacob Walker','Justin Johnson','Pieter Abbeel','Martial Hebert','Jessica K. Hodgins','Abhinav Gupta','Christopher G. Atkeson','Tom M. Mitchell','Matthew T. Mason']:\n",
    "                if years_working[name_idx[name]] < 3:\n",
    "                    continue\n",
    "                if years_working[name_idx[name]] > 8:\n",
    "                    continue\n",
    "                if ri_scores[name_idx[name]] < 1.4:\n",
    "                    continue\n",
    "                if auth_years[name_idx[name],1] < 2016:\n",
    "                    continue\n",
    "            #if (np.array(X[name_idx[name],:].todense()) * ri_confs).sum() == 0:\n",
    "            #    continue\n",
    "            #print(name,auth_years[name_idx[name]])\n",
    "            score = norm_scores[name_idx[name]]\n",
    "            ri_vscore = ri_norm_scores[name_idx[name]]\n",
    "            vscore = value_scores[name_idx[name]]\n",
    "            cmu_scores.append((score,ri_scores[name_idx[name]],vscore,uni,name,auth_years[name_idx[name]]))\n",
    "        else:\n",
    "            pass\n",
    "            #print(name)\n",
    "    print('{:22s}\\t{:15s}\\t{:5s}\\t{:3s}\\t{:4s}\\t{} {}'.format('name','uni','value','RI-s','score','start','end'))\n",
    "    for s,ris,vs,u,p,yrs in sorted(cmu_scores,reverse=True):\n",
    "        print('{:22s}\\t{:15s}\\t{:.3f}\\t{:.1f}\\t{:.2f}\\t{} {}'.format(p[:22],u[:15],s,ris,vs,int(yrs[0]),int(yrs[1])))\n",
    "\n",
    "if False:\n",
    "    gz = gzip.GzipFile('dblp.xml.gz')\n",
    "    names = set()\n",
    "    places = set()\n",
    "    papers = []\n",
    "    def handle_article(_, article):\n",
    "        try:\n",
    "            if 'author' not in article:\n",
    "                return True\n",
    "            if type(article['author']) != list:\n",
    "                authors = [article['author']]\n",
    "            else:\n",
    "                authors = article['author']\n",
    "\n",
    "            if 'booktitle' in article:\n",
    "                venue = article['booktitle']\n",
    "            elif 'journal' in article:\n",
    "                venue = article['journal']\n",
    "            else:\n",
    "                return True\n",
    "            names = names.union(set(authors))\n",
    "            places.add(venue)\n",
    "        except:\n",
    "            print(sys.exc_info()[0])\n",
    "            failures += 1\n",
    "            raise\n",
    "        return True\n",
    "\n",
    "    xmltodict.parse(gz, item_depth=2, item_callback=handle_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_scores[name_idx['Humphrey Hu']],norm_scores[name_idx['David F. Fouhey']],norm_scores[name_idx['Lerrel Pinto']],norm_scores[name_idx['Justin Johnson']],norm_scores[name_idx['Amir Roshan Zamir']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_scores[name_idx['Humphrey Hu']],value_scores[name_idx['David F. Fouhey']],value_scores[name_idx['Lerrel Pinto']],value_scores[name_idx['Justin Johnson']],value_scores[name_idx['Amir Roshan Zamir']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_scores[name_idx['Humphrey Hu']],ri_scores[name_idx['David F. Fouhey']],ri_scores[name_idx['Lerrel Pinto']],ri_scores[name_idx['Justin Johnson']],ri_scores[name_idx['Amir Roshan Zamir']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_working[name_idx['David F. Fouhey']],years_working[name_idx['Lerrel Pinto']],years_working[name_idx['Justin Johnson']],years_working[name_idx['Amir Roshan Zamir']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Allison SauppÃ©'.encode('utf-8', 'replace'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
