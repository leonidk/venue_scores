{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_confs = ['CVPR',\n",
    " 'ICRA',\n",
    " 'ICCV',\n",
    " 'IROS',\n",
    " 'SIGGRAPH',\n",
    " 'NIPS',\n",
    " 'ECCV',\n",
    " 'I. J. Robotics Res.',\n",
    " 'AAAI',\n",
    " 'Robotics: Science and Systems',\n",
    " 'IEEE Trans. Pattern Anal. Mach. Intell.',\n",
    " 'International Journal of Computer Vision',\n",
    " 'ICML',\n",
    " 'Symposium on Computer Animation',\n",
    " 'WAFR',\n",
    " 'ACM Trans. Graph.',\n",
    " 'AAMAS',\n",
    " 'Auton. Robots',\n",
    " 'Humanoids',\n",
    " 'IEEE Trans. Robotics and Automation',\n",
    " 'ISER',\n",
    " 'ISRR',\n",
    " 'WACV',\n",
    " 'IJCAI',\n",
    " 'AISTATS',\n",
    " 'UAI',\n",
    " 'CHI',\n",
    " 'Comput. Graph. Forum',\n",
    " 'SIGGRAPH Asia',\n",
    " 'FGR',\n",
    " 'BMVC',\n",
    " 'ICAPS',\n",
    " 'CVPR Workshops',\n",
    " 'ACC',\n",
    " 'FSR',\n",
    " 'Commun. ACM',\n",
    " 'HRI',\n",
    " '3DV',\n",
    " 'ICLR',\n",
    " 'MICCAI',\n",
    " 'AI Magazine',\n",
    " 'IEEE Robot. Automat. Mag.',\n",
    " 'Proceedings of the IEEE',\n",
    " 'IEEE Robotics and Automation Letters',\n",
    " 'ICIP',\n",
    " 'IEEE Intelligent Systems',\n",
    " 'IEEE Computer Graphics and Applications',\n",
    " 'ACCV',\n",
    " 'CDC',\n",
    " 'Artif. Intell.',\n",
    " 'ICPR',\n",
    " 'SOCS',\n",
    " 'SMC',\n",
    " 'AAAI Spring Symposia',\n",
    " 'ICCV Workshops',\n",
    " 'SSRR',\n",
    " 'Robotics and Autonomous Systems',\n",
    " 'RO-MAN',\n",
    " 'CHI Extended Abstracts',\n",
    " 'J. Field Robotics',\n",
    " 'AAAI Fall Symposia',\n",
    " 'EMBC',\n",
    " 'Graphics Interface',\n",
    " 'CoRL',\n",
    " 'ECCV Workshops',\n",
    " 'Computer Vision and Image Understanding',\n",
    " 'HICSS',\n",
    " 'ICCP',\n",
    " 'ISBI',\n",
    " 'Conference on Designing Interactive Systems',\n",
    " 'DARS',\n",
    " 'ICME',\n",
    " 'Image Vision Comput.',\n",
    " 'Ann. Math. Artif. Intell.',\n",
    " 'ICWS',\n",
    " 'AVBPA',\n",
    " 'IEEE Trans. Systems, Man, and Cybernetics',\n",
    " 'SAP',\n",
    " 'Advanced Robotics',\n",
    " 'FUSION',\n",
    " 'ITSC',\n",
    " 'CogSci',\n",
    " 'IPMI',\n",
    " 'International Semantic Web Conference',\n",
    " 'IEEE Trans. Biomed. Engineering',\n",
    " 'IAT',\n",
    " 'CASE',\n",
    " 'ROBIO',\n",
    " 'TAP',\n",
    " 'MVA',\n",
    " 'Intelligent Vehicles Symposium',\n",
    " 'IAS',\n",
    " 'DICTA']\n",
    "ri_confs = set(ri_confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import zipfile\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the update to work despite the broken scipy documentation\n",
    "try:\n",
    "    a = scipy.sparse.dok_matrix((10,10))\n",
    "    a.update({(0,0):1.0})\n",
    "    scipy.sparse.dok_matrix.my_update = scipy.sparse.dok_matrix.update\n",
    "except:\n",
    "    a = scipy.sparse.dok_matrix((10,10))\n",
    "    a._update({(0,0):1.0})\n",
    "    scipy.sparse.dok_matrix.my_update = scipy.sparse.dok_matrix._update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('useful_venue_list.pkl.gz','rb') as fp:\n",
    "    all_venues = pickle.load(fp)\n",
    "with gzip.open('useful_authors_list.pkl.gz','rb') as fp:\n",
    "    all_authors = pickle.load(fp)\n",
    "with gzip.open('useful_papers.pkl.gz','rb') as fp:\n",
    "    all_papers = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_idx = {v:i for i,v in enumerate(all_venues)}\n",
    "name_idx = {v:i for i,v in enumerate(all_authors)}\n",
    "n_confs = len(all_venues)\n",
    "n_auths = len(all_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_remove = []\n",
    "for a in all_authors:\n",
    "    if a + ' 0001' in name_idx:\n",
    "        names_to_remove.append(a)\n",
    "for name in names_to_remove:\n",
    "    del name_idx[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_affil = pd.read_csv('faculty-affiliations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg(M,alpha=0.85,tol=1e-6,max_iter=1,verbose=False):\n",
    "    N = M.shape[0]\n",
    "    nodelist = np.arange(N)\n",
    "    S = scipy.array(M.sum(axis=1)).flatten()\n",
    "    S[S != 0] = 1.0 / S[S != 0]\n",
    "    Q = scipy.sparse.spdiags(S.T, 0, *M.shape, format='csr')\n",
    "    M = Q * M\n",
    "\n",
    "    # initial vector\n",
    "    x = scipy.repeat(1.0 / N, N)\n",
    "\n",
    "    # Personalization vector\n",
    "    p = scipy.repeat(1.0 / N, N)\n",
    "\n",
    "    # Dangling nodes\n",
    "    dangling_weights = p\n",
    "    is_dangling = scipy.where(S == 0)[0]\n",
    "\n",
    "    # power iteration: make up to max_iter iterations\n",
    "    for _ in range(max_iter):\n",
    "        xlast = x\n",
    "        x = alpha * (x * M + sum(x[is_dangling]) * dangling_weights) + \\\n",
    "            (1 - alpha) * p\n",
    "        # check convergence, l1 norm\n",
    "        err = scipy.absolute(x - xlast).sum()\n",
    "        if verbose:\n",
    "            print(_,err)\n",
    "        if err < N * tol:\n",
    "            return x\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "gauth_auth = scipy.sparse.dok_matrix((n_auths,n_auths))\n",
    "g_auth = {}\n",
    "\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, conf, pages, startPage,paper_year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    #if conf not in ri_confs:\n",
    "    #    continue\n",
    "    n = len(authors)\n",
    "\n",
    "    #if clf[span_years*conf_idx[conf]:span_years*(conf_idx[conf]+1)].max() > 0:\n",
    "    for a,a2 in itertools.product(authors,authors):\n",
    "        if a in name_idx and a2 in name_idx:\n",
    "            g_auth[(name_idx[a],name_idx[a2])] = 1/n + g_auth.get((name_idx[a],name_idx[a2]),0)\n",
    "gauth_auth.my_update(g_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauth_auth = scipy.sparse.csr_matrix(gauth_auth)\n",
    "pr = pg(gauth_auth,max_iter=100,verbose=True,tol=1e-12)\n",
    "print(gauth_auth.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_s = np.argsort(pr)[::-1]\n",
    "top_k = 100\n",
    "i = 0\n",
    "j = 0 \n",
    "while i < top_k:\n",
    "    j += 1\n",
    "    idx = pr_s[j]\n",
    "    #if(ri_scores[idx]/rs < 20.0):\n",
    "    #    continue\n",
    "    print(all_authors[idx],pr[idx])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curious_names = [\n",
    "    'Aditya Dhawale',\n",
    "    'Tesca Fitzgerald',\n",
    "    'Adam W. Harley',\n",
    "    \"Xiaolong Wang 0004\",\n",
    "    \"Judy Hoffman\",\n",
    "    \"Paris Siminelakis\",\n",
    "    \"Roie Levin\",\n",
    "    \"Leonid Keselman\",\n",
    "    \"Rick Goldstein\",\n",
    "    \"Nicholas Rhinehart\",\n",
    "    \"Vincent Sitzmann\",\n",
    "    \"Siddharth Ancha\",\n",
    "    \"Xingyu Lin\",\n",
    "    \"Humphrey Hu\",\n",
    "    \"David F. Fouhey\",\n",
    "    \"Chelsea Finn\",\n",
    "    \"Dinesh Jayaraman\",\n",
    "    \"Wen Sun 0002\",\n",
    "    \"Lerrel Pinto\",\n",
    "    \"Justin Johnson\",\n",
    "    \"Amir Roshan Zamir\",\n",
    "    \"Dominik Peters\",\n",
    "    \"Jonathan T. Barron\",\n",
    "    \"Dorsa Sadigh\",\n",
    "    \"Derek Hoiem\",\n",
    "    \"Vaggos Chatziafratis\",\n",
    "    \"Brian Okorn\",\n",
    "    \"David Held\"\n",
    "]\n",
    "sorted([(pr[name_idx[n]],n) for n in curious_names if n in name_idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pr,open('new_pagerank_people.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauth_auth = None\n",
    "pr = None\n",
    "g_auth = None\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "auth_confs = defaultdict(set)\n",
    "\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, conf, pages, startPage,paper_year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    n = len(authors)\n",
    "    for a in authors:\n",
    "        if not a in name_idx:\n",
    "            continue\n",
    "        auth_confs[a].add(conf_idx[conf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_confs = {k: list(v) for k,v in auth_confs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "auth_confs_iter = {k: itertools.combinations_with_replacement(v,2) for k,v in auth_confs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "dconf = dict()\n",
    "\n",
    "gconf_conf = scipy.sparse.dok_matrix((n_confs,n_confs))\n",
    "dconf = {}\n",
    "for k,v in auth_confs_iter.items():\n",
    "    for i,j in v:\n",
    "        tmp = 1 + dconf.get((i,j),0)\n",
    "        dconf[(i,j)] = tmp\n",
    "        if i != j:\n",
    "            dconf[(j,i)] = tmp\n",
    "\n",
    "gconf_conf.my_update(dconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gconf_conf = scipy.sparse.csr_matrix(gconf_conf)\n",
    "prc = pg(gconf_conf,max_iter=100,verbose=True,tol=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_s = np.argsort(prc)[::-1]\n",
    "top_k = 100\n",
    "i = 0\n",
    "while i < top_k:\n",
    "    idx = prc_s[i]\n",
    "    print(all_venues[idx],prc[idx])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(prc,open('new_pagerank_conf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
