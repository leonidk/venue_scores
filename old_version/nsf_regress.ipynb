{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import zipfile\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsf data\n",
    "df2 = pd.read_pickle('nsf2.pkl')\n",
    "df = pd.read_pickle('nsf.pkl')\n",
    "Xauth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_confs = pickle.load(open('r1_confs.pkl','rb'))\n",
    "r1_confs_dict = {_:1 for _ in r1_confs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the big paper thing\n",
    "papers = pd.read_hdf('papers.h5','table')\n",
    "unique_names = pickle.load(open('big_names.pkl','rb'))\n",
    "unique_confs = pickle.load(open('confs.pkl','rb'))\n",
    "\n",
    "faculty_affil = pd.read_csv('faculty-affiliations.csv')\n",
    "ranks = pd.read_csv('ranks.csv')\n",
    "def csv2dict_str_str(fname):\n",
    "    with open(fname, mode='r') as infile:\n",
    "        rdr = csv.reader(infile)\n",
    "        d = {rows[0].strip(): rows[1].strip() for rows in rdr}\n",
    "    return d\n",
    "aliasdict = csv2dict_str_str('dblp-aliases.csv')\n",
    "conf_idx = pickle.load(open('conf_idx.pkl','rb'))\n",
    "name_idx = pickle.load(open('name_idx.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# munge the years\n",
    "min_year = df.year.min()\n",
    "max_year = df.year.max()\n",
    "span_years = max_year - min_year\n",
    "year_blocks = 8 #11\n",
    "offset_years = [(i-min_year)//year_blocks for i in range(min_year,max_year+1)]\n",
    "year_ind = max(offset_years)+1\n",
    "print(min_year,max_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsf_paper_n, _ = df2.shape\n",
    "nsf_paper_n\n",
    "offset_years,year_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter,defaultdict\n",
    "# create or load some author data\n",
    "def dd():\n",
    "    return defaultdict(list)\n",
    "if False:\n",
    " \n",
    "    author_papers = defaultdict(dd)\n",
    "\n",
    "    for row in papers.itertuples():\n",
    "        paper_year = row[10]\n",
    "        conf = row[2]\n",
    "        n = row[4]\n",
    "        authors = row[3]\n",
    "        for a in authors:\n",
    "            split_name = a.split(' ')\n",
    "            first_last = split_name[0] +' ' + split_name[-1]\n",
    "            author_papers[first_last][paper_year].append((conf,n))\n",
    "    import pickle\n",
    "    with open('nsf_auth.pkl','wb') as fp:\n",
    "        pickle.dump(author_papers,fp)\n",
    "else:\n",
    "    pass\n",
    "    with open('nsf_auth.pkl','rb') as fp:\n",
    "        author_papers = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddn():\n",
    "    return defaultdict(int)\n",
    "author_amounts = defaultdict(ddn)\n",
    "for i,row in enumerate(df2.itertuples()):\n",
    "    authors, year, amount = row[3],row[4],row[5]\n",
    "    # some infinite amounts exist! bad!\n",
    "    if not np.isfinite(amount):\n",
    "        continue\n",
    "    for a in authors:\n",
    "        split_name = a.split(' ')\n",
    "        first_last = split_name[0] +' ' + split_name[-1]\n",
    "        for yr in range(int(year),2020):\n",
    "            author_amounts[first_last][yr] += amount/len(a)#min(amount/len(a),1e6)\n",
    "\n",
    "y = np.zeros(nsf_paper_n,dtype=np.float32)\n",
    "for i,row in enumerate(df2.itertuples()):\n",
    "    authors, year, amount = row[3],row[4],row[5]\n",
    "    # some infinite amounts exist! bad!\n",
    "    \n",
    "    #if not np.isfinite(amount):\n",
    "    #    continue\n",
    "\n",
    "    #if amount < 1000: #50000\n",
    "    #    continue\n",
    "    # giant grants are msileading?\n",
    "    #if amount >= 1e9: #5e7\n",
    "    #    continue\n",
    "    if len(authors)  <= 0.5*sum([(a in author_papers) for a in authors]):\n",
    "        y[i] = amount#sum([author_amounts[first_last][year] for first_last in authors]) #or amount!?\n",
    "\n",
    "y_orig = np.copy(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    y = np.zeros(nsf_paper_n,dtype=np.float32)\n",
    "    for i,row in enumerate(df2.itertuples()):\n",
    "        authors, year, amount = row[3],row[4],row[5]\n",
    "        # some infinite amounts exist! bad!\n",
    "        if not np.isfinite(amount):\n",
    "            continue\n",
    "\n",
    "        if amount < 1000: #50000\n",
    "            continue\n",
    "        # giant grants are msileading?\n",
    "        if amount >= 1e8: #5e7\n",
    "            continue\n",
    "        if len(authors) < 1:\n",
    "            continue\n",
    "        if len(authors)*0.5  <= sum([(a in author_papers) for a in authors]):\n",
    "            y[i] = amount/len(authors)#sum([author_amounts[first_last][year] for first_last in authors]) #or amount!?\n",
    "import matplotlib.pyplot as plt\n",
    "y_orig = np.copy(y)\n",
    "_ = plt.hist(y,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create design mattrix\n",
    "X = scipy.sparse.dok_matrix((nsf_paper_n,year_ind*unique_confs.shape[0]))\n",
    "xdict = {}\n",
    "y = np.zeros(nsf_paper_n,dtype=np.float32)\n",
    "for i,row in enumerate(df2.itertuples()):\n",
    "    authors, year, amount = row[3],row[4],row[5]\n",
    "    # some infinite amounts exist! bad!\n",
    "    if not np.isfinite(amount):\n",
    "        continue\n",
    "    # maybe the old years are misleading!?\n",
    "    #if year < 2002:\n",
    "    #    continue\n",
    "    # small grants are misleading? 150000\n",
    "    if amount < 50000:\n",
    "        continue\n",
    "    # giant grants are msileading?\n",
    "    if amount >= 5e7:\n",
    "        continue\n",
    "    #print(len(authors),sum([(a in author_papers) for a in authors]))\n",
    "    #print(a)\n",
    "    if len(authors)*0.5 <= sum([(a in author_papers) for a in authors]):\n",
    "        y[i] = amount\n",
    "        for a in authors:\n",
    "            for year_a,conf_list in author_papers[a].items():\n",
    "                if year_a <= year:\n",
    "                    for paper in conf_list:\n",
    "                        #if paper[0] in noisey_crap:\n",
    "                        #    continue\n",
    "                        if paper[0] == 'CoRR':\n",
    "                            continue\n",
    "                        if paper[0] not in r1_confs_dict:\n",
    "                            continue\n",
    "                        j = year_ind*conf_idx[paper[0]] + (year_a-min_year)//year_blocks\n",
    "                        xdict[(i,j)] = 1/paper[1]\n",
    "X._update(xdict)\n",
    "y_orig = np.copy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    X = scipy.sparse.lil_matrix(X.T)\n",
    "    for i in range(len(unique_confs)):\n",
    "        if unique_confs[i] not in r1_confs_dict:\n",
    "            X[i,:] = 0\n",
    "    X = scipy.sparse.csr_matrix(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_orig = np.copy(y)\n",
    "print(y_orig.min(),y_orig.max())\n",
    "print((y_orig > 0).sum())\n",
    "y = np.copy(np.log(1+y_orig))\n",
    "#y = np.copy(y_orig)\n",
    "#y[y > 1e6] = 1e6\n",
    "y[y == np.log(1)] = y[y != np.log(1)].mean()\n",
    "#y[y == 0] = y[y != 0].mean()\n",
    "\n",
    "from matplotlib.pyplot import figure,hist\n",
    "hist((y-y.mean())/y.std(),100)\n",
    "figure()\n",
    "_ = hist(y,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X = scipy.sparse.csr_matrix(X)\n",
    "clf = SGDRegressor('huber',tol=1e-9,max_iter=100,verbose=0,penalty='l2',alpha=1e-7,epsilon=0.01,average=True)\n",
    "#clf = SGDRegressor('huber',tol=1e-9,max_iter=100,verbose=1,penalty='l1',alpha=1e-7)\n",
    "\n",
    "clf.fit(X,(y-y.mean())/y.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_ord = np.argsort(np.squeeze(clf.coef_))\n",
    "conf_choice = ['SIGGRAPH','HRI','ECCV (8)','ECCV (1)','Comput. Graph. Forum','Shape Modeling International','Symposium on Geometry Processing','Computer Aided Geometric Design','I. J. Robotics Res.','CVPR','International Journal of Computer Vision','Robotics: Science and Systems','ICRA','WACV','ICML','AISTATS','CoRR','SIGGRAPH Asia','ECCV','ICCV','ISER','Humanoids','3DV','IROS','CoRL','Canadian Conference on AI','ACCV','Graphics Interface','CRV','BMVC']\n",
    "ri_confs = np.zeros(len(unique_confs)*year_ind)\n",
    "print(clf.intercept_)\n",
    "ms = clf.coef_.mean()\n",
    "ss = clf.coef_.std()\n",
    "for i in range(len(unique_confs)*year_ind):\n",
    "    idx = conf_ord[-(i+1)]\n",
    "    conf_name = unique_confs[idx//year_ind]\n",
    "    conf_score = clf.coef_[idx]\n",
    "    if conf_name in conf_choice:\n",
    "        ri_confs[idx] = 1\n",
    "    if conf_name in conf_choice and (idx%year_ind)==5:\n",
    "    #if 'ICCV' in conf_name and (idx%year_ind)==4:\n",
    "        start_year = offset_years.index(idx%year_ind) + 1970\n",
    "        end_year = len(offset_years) - 1 - offset_years[::-1].index(idx%year_ind) + 1970\n",
    "        print_name =conf_name + '_' + str(start_year)[-2:] +'t' + str(end_year)[-2:]\n",
    "        print('{:20s}\\t{:.3f}\\t{:.1f}'.format(print_name[:20],100*conf_score,(conf_score-ms)/ss))\n",
    "ri_confs.shape,ri_confs.sum(),X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 50\n",
    "for i in range(top_k):\n",
    "    idx = conf_ord[-(i+1)]\n",
    "    conf_name = unique_confs[idx//year_ind]\n",
    "    conf_score = clf.coef_[idx]\n",
    "    start_year = offset_years.index(idx%year_ind) + 1970\n",
    "    end_year = len(offset_years) - 1 - offset_years[::-1].index(idx%year_ind) + 1970\n",
    "    print_name = conf_name[:10] + '_' + str(start_year)[-2:] +'t' + str(end_year)[-2:]\n",
    "    print('{:20s}\\t\\t\\t\\t{:.3f}\\t{:.2f}'.format(print_name,100*conf_score,(conf_score-ms)/ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(clf.coef_,70)\n",
    "print((clf.coef_ > 0.15).sum())\n",
    "noisey_crap2 = set([unique_confs[i//year_ind] for i,_ in enumerate(clf.coef_ > 0.15) if _])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = X.T.sum(1)\n",
    "noisey_crap2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noisey_crap = noisey_crap.union(noisey_crap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noisey_crap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: #or Xauth is None or (Xauth.shape[1] != year_ind*unique_confs.shape[0]):  \n",
    "    Xauth = scipy.sparse.dok_matrix((len(unique_names),year_ind*unique_confs.shape[0]))\n",
    "    xdict = {}\n",
    "    auth_years = np.ones((len(unique_names),2)) * np.array([3000,1000]) \n",
    "    for row in papers.itertuples():\n",
    "        paper_year = row[10]\n",
    "        #if row['year'] < 2005:\n",
    "        #    continue\n",
    "        #print(row)\n",
    "        #if row['conf'] == 'CoRR':\n",
    "        #    continue\n",
    "        conf = row[2]\n",
    "        n = row[4]\n",
    "        authors = row[3]\n",
    "        j = year_ind*conf_idx[conf] + (paper_year-min_year)//year_blocks\n",
    "        for a in authors:\n",
    "            i = name_idx[a]\n",
    "            xdict[(i,j)] = 1/n + xdict.get((i,j),0)\n",
    "            auth_years[i,0] = min(auth_years[i,0],paper_year)\n",
    "            auth_years[i,1] = max(auth_years[i,1],paper_year)\n",
    "    Xauth._update(xdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clf.predict(Xauth) - np.squeeze(clf.intercept_)\n",
    "years_working = (1+auth_years[:,1]-auth_years[:,0])\n",
    "value_scores = scores\n",
    "norm_scores = (value_scores)/years_working\n",
    "ri_filter_mat = scipy.sparse.diags(ri_confs)\n",
    "ri_scores = clf.predict(Xauth.dot(ri_filter_mat))-np.squeeze(clf.intercept_)\n",
    "ri_norm_scores = ri_scores/years_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_cand = ['Pulkit Agrawal',\n",
    " 'Joydeep Biswas',\n",
    " 'Katherine L. Bouman',\n",
    " 'David Braun',\n",
    " 'Jia Deng',\n",
    " 'Naomi T. Fitter',\n",
    " 'David F. Fouhey',\n",
    " 'Saurabh Gupta',\n",
    " 'Judy Hoffman',\n",
    " 'Hanbyul Joo',\n",
    " 'Honglak Lee',\n",
    " 'Changliu Liu',\n",
    " 'Petter Nilsson',\n",
    " \"Matthew O'Toole\",\n",
    " 'Alessandro Roncone',\n",
    " 'Alanson P. Sample',\n",
    " 'Manolis Savva',\n",
    " 'Adriana Schulz',\n",
    " 'Amy Tabb',\n",
    " 'Fatma Zeynep Temel',\n",
    " 'Long Wang',\n",
    " 'Cathy Wu',\n",
    " 'Ling-Qi Yan']\n",
    "print('{:20s}\\t{:4s}\\t{:4s}\\t{:4s}\\t{}'.format('name','rate','total','ri','years'))\n",
    "for ns, name in sorted([(value_scores[name_idx[ni]],ni) for ni in prev_cand],reverse=True):\n",
    "    ni = name_idx[name]\n",
    "    print('{:20s}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.0f}'.format(name,100*norm_scores[ni],100*value_scores[ni],100*ri_scores[ni],years_working[ni]))\n",
    "print('')\n",
    "curious_names = ['Xiaolong Wang 0004','Judy Hoffman','Paris Siminelakis',\n",
    "                 'Nicholas Rhinehart',\n",
    "                 'Humphrey Hu',\n",
    "                 'David F. Fouhey',\n",
    "                 'Lerrel Pinto',\n",
    "                 'Justin Johnson',\n",
    "                 'Amir Roshan Zamir',\n",
    "                 'Brian Okorn','David Held']\n",
    "print('{:20s}\\t{:4s}\\t{:4s}\\t{:4s}\\t{}'.format('name','rate','total','ri','years'))\n",
    "for _,name in sorted([(value_scores[name_idx[_]],_) for _ in curious_names],reverse=True):\n",
    "    ni = name_idx[name]\n",
    "    print('{:20s}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.0f}'.format(name,100*norm_scores[ni],100*value_scores[ni],100*ri_scores[ni],years_working[ni]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n best overall \\n')\n",
    "cmu_scores = []\n",
    "\n",
    "best_scores = np.argsort(value_scores)[::-1]\n",
    "#print(best_scores.shape,unique_names[best_scores[0]])\n",
    "fa_list = list(faculty_affil.name)\n",
    "fa_a_list = list(faculty_affil.affiliation)\n",
    "uni_names = [unique_names[i] for i in best_scores[:38000]]\n",
    "for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "    if name in name_idx:\n",
    "        uni = 'unknown'\n",
    "        if name in fa_list:\n",
    "            uni = fa_a_list[fa_list.index(name)]\n",
    "        if name not in []:#['Jacob Walker','Justin Johnson','Pieter Abbeel','Martial Hebert','Jessica K. Hodgins','Abhinav Gupta','Christopher G. Atkeson','Tom M. Mitchell','Matthew T. Mason']:\n",
    "            if years_working[name_idx[name]] < 3:\n",
    "                continue\n",
    "            if years_working[name_idx[name]] > 8:\n",
    "                continue\n",
    "            if ri_scores[name_idx[name]] < 0.008:\n",
    "                continue\n",
    "            if auth_years[name_idx[name],1] < 2016:\n",
    "                continue\n",
    "        #if (np.array(X[name_idx[name],:].todense()) * ri_confs).sum() == 0:\n",
    "        #    continue\n",
    "        #print(name,auth_years[name_idx[name]])\n",
    "        score = norm_scores[name_idx[name]]\n",
    "        ri_vscore = ri_norm_scores[name_idx[name]]\n",
    "        vscore = value_scores[name_idx[name]]\n",
    "        cmu_scores.append((vscore,ri_scores[name_idx[name]],score,uni,name,auth_years[name_idx[name]],ri_vscore))\n",
    "    else:\n",
    "        pass\n",
    "        #print(name)\n",
    "        ri_norm_scores\n",
    "print('{:22s}\\t{:15s}\\t{:5s}\\t{:3s}\\t{:4s}\\t{:4s}\\t{} {}'.format('name','uni','rate','RI-t','total','RI-r','start','end'))\n",
    "for vs,ris,s,u,p,yrs,rir in sorted(cmu_scores,reverse=True):\n",
    "    print('{:22s}\\t{:15s}\\t{:.3f}\\t{:.1f}\\t{:.2f}\\t{:.2f}\\t{} {}'.format(p[:22],u[:15],s*100,ris*100,vs*100,rir*100,int(yrs[0]),int(yrs[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_faculty = faculty_affil[faculty_affil.affiliation == 'Carnegie Mellon University'] #Carnegie Mellon University\n",
    "uni_names = np.array(uni_faculty.name)\n",
    "uni_names = list(uni_names) + ['Nicholas Rhinehart','Jacob Walker','Lerrel Pinto','Brian Okorn','Leonid Keselman','Siddharth Ancha','Humphrey Hu']\n",
    "cmu_scores = []\n",
    "#uni_names = [unique_names[i] for i in (np.argsort(scores)[::-1])[:150]]\n",
    "for name in set([aliasdict.get(n, n) for n in uni_names]):\n",
    "    if name in name_idx:\n",
    "        #if ri_scores[name_idx[name]] < 2.5:\n",
    "        #    continue\n",
    "        score = scores[name_idx[name]]\n",
    "        cmu_scores.append((score,name))\n",
    "    else:\n",
    "        pass\n",
    "        #print(name)\n",
    "for s,p in sorted(cmu_scores,reverse=True):\n",
    "    print('{:30s}\\t\\t{:.3f}'.format(p,s*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf.coef_,open('clf_nsf_ind_log_r1.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Xauth,open('xauth.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du -h *.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
