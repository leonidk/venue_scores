{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import csv\n",
    "import scipy.sparse\n",
    "Xauth = None\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the update to work despite the broken scipy documentation\n",
    "try:\n",
    "    a = scipy.sparse.dok_matrix((10,10))\n",
    "    a.update({(0,0):1.0})\n",
    "    scipy.sparse.dok_matrix.my_update = scipy.sparse.dok_matrix.update\n",
    "except:\n",
    "    a = scipy.sparse.dok_matrix((10,10))\n",
    "    a._update({(0,0):1.0})\n",
    "    scipy.sparse.dok_matrix.my_update = scipy.sparse.dok_matrix._update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('useful_venue_list.pkl.gz','rb') as fp:\n",
    "    all_venues = pickle.load(fp)\n",
    "with gzip.open('useful_authors_list.pkl.gz','rb') as fp:\n",
    "    all_authors = pickle.load(fp)\n",
    "with gzip.open('useful_papers.pkl.gz','rb') as fp:\n",
    "    all_papers = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = all_papers[0][6]\n",
    "max_year = all_papers[-1][6]\n",
    "span_years = max_year - min_year + 1\n",
    "print(min_year,max_year,span_years)\n",
    "conf_idx = {v:i for i,v in enumerate(all_venues)}\n",
    "name_idx = {v:i for i,v in enumerate(all_authors)}\n",
    "n_confs = len(all_venues)\n",
    "n_auths = len(all_authors)\n",
    "n_papers = len(all_papers)\n",
    "print(n_confs,n_auths,n_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =  np.load('clf_gold.pkl.npy')\n",
    "years_per_conf = clf.shape[0]//n_confs\n",
    "\n",
    "YEAR_BLOCKS = span_years//years_per_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import gc\n",
    "if Xauth is None:\n",
    "    valid_ns = set()\n",
    "    for paper in all_papers:\n",
    "        tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "        n = len(authors)\n",
    "        valid_ns.add(n)\n",
    "    \n",
    "    per_author_val = {}\n",
    "    for n in valid_ns:\n",
    "        author_scores = np.ones(n)#1/(np.arange(n)+1)\n",
    "        #author_score_sum = author_scores.sum()\n",
    "        per_author_val[n] = author_scores#/author_scores.sum()\n",
    "        \n",
    "    count_vecs = {}\n",
    "    paper_vecs = []\n",
    "    for paper in all_papers:\n",
    "        tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "        n = len(authors)\n",
    "        j = years_per_conf*conf_idx[venue] + (year-min_year)//YEAR_BLOCKS\n",
    "\n",
    "        author_scores = per_author_val[n]\n",
    "        paper_vecs.append([(name_idx[a],j,v) for a,v in zip(authors,author_scores)])\n",
    "        \n",
    "    Xauth = scipy.sparse.dok_matrix((n_auths,years_per_conf*n_confs))\n",
    "    xdict = {}\n",
    "  \n",
    "    for paper_vec in paper_vecs:\n",
    "        for i,j,v in paper_vec:\n",
    "            xdict[(i,j)] = v + xdict.get((i,j),0)\n",
    "\n",
    "    Xauth.my_update(xdict)\n",
    "            \n",
    "    Xauth = scipy.sparse.csr_matrix(Xauth)\n",
    "    paper_vec = []\n",
    "    xdict = {}\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_uni = pd.read_csv('other_ranks/cmu_faculty.csv')\n",
    "cmu_uni = cmu_uni.fillna('Other')\n",
    "cmu_uni = cmu_uni[cmu_uni.dept == 'RI']\n",
    "#uni_names = ['Andrea Tagliasacchi','Paul G. Kry']#['Xuemin Shen','H. Vincent Poor','Kang G. Shin','Mohamed-Slim Alouini','Lajos Hanzo']#list(cmu_uni.name)\n",
    "#uni_names = list(faculty_affil[faculty_affil.affiliation == 'Johns Hopkins University'].name)\n",
    "uni_names = list(cmu_uni.name)\n",
    "print(len(uni_names))\n",
    "conf_counts = {}\n",
    "conf_counts_value = {}\n",
    "\n",
    "for paper in all_papers:\n",
    "    tag,title, authors, venue, pages, startPage,year,volume,number,url,publtype,eb_toofew,eb_skip = paper\n",
    "    n = len(authors)\n",
    "    for a in authors:\n",
    "        if a in uni_names:\n",
    "            conf_counts[venue] = 1/n + conf_counts.get(venue,0)\n",
    "            conf_counts_value[venue] = clf[years_per_conf*(conf_idx[venue]) + (year-min_year)//YEAR_BLOCKS]/n + conf_counts_value.get(venue,0)\n",
    "conf_counts_value = {k: v/conf_counts[k] for k,v in conf_counts_value.items()}\n",
    "ri_fav_confs = [(conf_counts[_[1]]*conf_counts_value[_[1]],_[1],conf_counts[_[1]],conf_counts_value[_[1]]) for _ in sorted([(v,k) for k,v in conf_counts.items() if v > 0],reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confs_to_filter = [_[1] for _ in sorted(ri_fav_confs,reverse=True) if _[-2] >= 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_after = 2000\n",
    "start_year_idx = max(0,only_after-min_year)//YEAR_BLOCKS\n",
    "\n",
    "year_filter = np.zeros_like(clf).reshape((-1,years_per_conf))\n",
    "\n",
    "if False: # filter confs\n",
    "    for conf in confs_to_filter:\n",
    "        year_filter[conf_idx[conf],start_year_idx:] = 1\n",
    "else:\n",
    "    year_filter[:,start_year_idx:] = 1\n",
    "\n",
    "total_scores = Xauth.dot(clf * year_filter.reshape((-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argsort(total_scores)[::-1]\n",
    "for k in range(10):\n",
    "    idx = best_idx[k]\n",
    "    print('{:30s}\\t{:.2f}'.format(all_authors[idx],total_scores[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_affil = pd.read_csv('csrankings.csv')\n",
    "faculty_affil = faculty_affil[faculty_affil.name.isin(name_idx)]\n",
    "faculty_affil['score'] = [total_scores[name_idx[name]] for name in faculty_affil.name]\n",
    "faculty_affil['count'] = [(1 if total_scores[name_idx[name]] > 0 else 0) for name in faculty_affil.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_sum = faculty_affil.groupby('affiliation').sum().sort_values('score',0,False)\n",
    "\n",
    "scores_log = scores_sum.copy()\n",
    "scores_log.score = scores_log.score/np.log(scores_log['count']+1)\n",
    "scores_log = scores_log.sort_values('score',0,False)\n",
    "\n",
    "scores_mean = scores_sum.copy()\n",
    "scores_mean.score = scores_mean.score/scores_mean['count']\n",
    "scores_mean = scores_mean.sort_values('score',0,False)\n",
    "\n",
    "scores_median = faculty_affil.groupby('affiliation').median().sort_values('score',0,False)\n",
    "print(scores_sum['count'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lbl,scores in zip(['sum','log','mean','median'],[scores_sum,scores_log,scores_mean,scores_median]):\n",
    "    scores = scores.drop(['count'],1)\n",
    "    print('\\n{}'.format(lbl))\n",
    "    print(scores.head(10))\n",
    "    plt.figure()\n",
    "    plt.hist(scores.score,100)\n",
    "    plt.title(lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University rankings by sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "SAMPLE_N = 20\n",
    "TRIAL_N = 100\n",
    "\n",
    "uni_scores = defaultdict(list)\n",
    "uni_ranks = defaultdict(list)\n",
    "\n",
    "for ti in range(TRIAL_N):\n",
    "    unis = []\n",
    "    for uni in faculty_affil.affiliation.unique():\n",
    "        faculty = faculty_affil[faculty_affil.affiliation == uni]\n",
    "        uni_score = faculty.score.sum()\n",
    "        \n",
    "        p_vec = np.array(faculty.score/uni_score)\n",
    "        \n",
    "        if SAMPLE_N < (p_vec > 0).sum():\n",
    "            #p_vec += 1.0/np.ones_like(p_vec)\n",
    "            #p_vec /= p_vec.sum()\n",
    "            choices = np.random.choice(faculty.name,SAMPLE_N,False,p_vec)\n",
    "        else:\n",
    "            choices = list(faculty.name)\n",
    "        sample_score = sum([total_scores[name_idx[name]] for name in choices])\n",
    "        uni_scores[uni].append(sample_score)\n",
    "        unis.append((sample_score,uni))\n",
    "    ranks = sorted(unis,reverse=True)\n",
    "    for ri,s in enumerate(ranks):\n",
    "        uni_ranks[s[1]].append(ri+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_means = sorted([(np.mean(l),np.std(l),np.min(l),np.max(l),sorted(l)[int(0.4*TRIAL_N)],sorted(l)[int(0.6*TRIAL_N)],k) for k,l in uni_ranks.items()],reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_means = sorted([(np.mean(l),np.std(l),np.min(l),np.max(l),k) for k,l in uni_scores.items()],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_mean_scores = np.array([_[0] for _ in uni_means])\n",
    "uni_std_scores = np.array([_[1] for _ in uni_means])\n",
    "\n",
    "STD = 1\n",
    "uni_dist_scores = []\n",
    "for m,s in zip(uni_mean_scores,uni_std_scores):\n",
    "    ub = (uni_mean_scores > m+STD*s).sum() + 1\n",
    "    lb = (uni_mean_scores > m-STD*s).sum() + 1\n",
    "    uni_dist_scores.append((ub,lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for um,bs in zip(uni_means,uni_dist_scores):\n",
    "    print(um[-1],bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University rankings by DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "TRIAL_N = 100\n",
    "\n",
    "uni_scores = defaultdict(list)\n",
    "uni_ranks = defaultdict(list)\n",
    "\n",
    "for ti in range(TRIAL_N):\n",
    "    unis = []\n",
    "    for uni in faculty_affil.affiliation.unique():\n",
    "        faculty = faculty_affil[faculty_affil.affiliation == uni]\n",
    "        \n",
    "        choices = [name for name in faculty.name if np.random.rand() > 0.5]\n",
    "\n",
    "        sample_score = sum([total_scores[name_idx[name]] for name in choices])\n",
    "        uni_scores[uni].append(sample_score)\n",
    "        unis.append((sample_score,uni))\n",
    "    ranks = sorted(unis,reverse=True)\n",
    "    for ri,s in enumerate(ranks):\n",
    "        uni_ranks[s[1]].append(ri+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_means = sorted([(np.mean(l),np.std(l),np.min(l),np.max(l),sorted(l)[int(0.4*TRIAL_N)],sorted(l)[int(0.6*TRIAL_N)],k) for k,l in uni_ranks.items()],reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_means = sorted([(np.mean(l),np.std(l),np.min(l),np.max(l),k) for k,l in uni_scores.items()],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_mean_scores = np.array([_[0] for _ in uni_means])\n",
    "uni_std_scores = np.array([_[1] for _ in uni_means])\n",
    "\n",
    "STD = 1\n",
    "uni_dist_scores = []\n",
    "for m,s in zip(uni_mean_scores,uni_std_scores):\n",
    "    ub = (uni_mean_scores > m+STD*s).sum() + 1\n",
    "    lb = (uni_mean_scores > m-STD*s).sum() + 1\n",
    "    uni_dist_scores.append((ub,lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for um,bs in zip(uni_means,uni_dist_scores):\n",
    "    print(um[-1],bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University Rankings by LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS = total_scores[best_idx[0]]\n",
    "eps = 0.1\n",
    "lv = GS/(eps) \n",
    "GS,lv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this seems really rough, I don't think I can do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University Rankings by random conf subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "TRIAL_N = 100\n",
    "\n",
    "uni_scores = defaultdict(list)\n",
    "uni_ranks = defaultdict(list)\n",
    "\n",
    "for ti in range(TRIAL_N):\n",
    "    filter_year = np.ones_like(clf).reshape((-1,years_per_conf))\n",
    "    filter_year *= np.random.randint(2,size=(n_confs,1)).astype(np.float)\n",
    "    total_scores = Xauth.dot(clf * filter_year.ravel())\n",
    "    faculty_affil['score'] = [total_scores[name_idx[name]] for name in faculty_affil.name]\n",
    "    for ri,row in enumerate(faculty_affil.groupby('affiliation').sum().sort_values('score',0,False).itertuples()):\n",
    "        uni = row[0]\n",
    "        sample_score = row[1]\n",
    "\n",
    "        uni_scores[uni].append(sample_score)\n",
    "        uni_ranks[uni].append(ri+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_means = sorted([(np.mean(l),np.std(l),np.min(l),np.max(l),sorted(l)[int(0.4*TRIAL_N)],sorted(l)[int(0.6*TRIAL_N)],k) for k,l in uni_ranks.items()],reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_means = sorted([(np.mean(l),np.std(l),np.min(l),np.max(l),k) for k,l in uni_scores.items()],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_mean_scores = np.array([_[0] for _ in uni_means])\n",
    "uni_std_scores = np.array([_[1] for _ in uni_means])\n",
    "\n",
    "STD = 2\n",
    "uni_dist_scores = []\n",
    "for m,s in zip(uni_mean_scores,uni_std_scores):\n",
    "    ub = (uni_mean_scores > m+STD*s).sum() + 1\n",
    "    lb = (uni_mean_scores > m-STD*s).sum() + 1\n",
    "    uni_dist_scores.append((ub,lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for um,bs in zip(uni_means,uni_dist_scores):\n",
    "    print(um[-1],bs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
